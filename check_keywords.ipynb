{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e796058",
   "metadata": {},
   "source": [
    "Evaluate earning transcipts for signals of financial distress\n",
    "\n",
    "Code by Geoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbfd3df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (1.1.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from python-docx) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in e:\\anaconda\\lib\\site-packages (from python-docx) (4.11.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: torch in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in e:\\anaconda\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (3.1.4)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\hijik\\appdata\\roaming\\python\\python312\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "install_flag = True\n",
    "if install_flag:\n",
    "  !pip install python-docx\n",
    "  !pip install transformers\n",
    "  !pip install torch\n",
    "  !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b58e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, json, os, re\n",
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, Any, Optional\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import openai\n",
    "import requests\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a0d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AnalysisResult:\n",
    "    \"\"\"Data structure to hold analysis results\"\"\"\n",
    "    prompt_name: str\n",
    "    category: str\n",
    "    keywords_found: List[str]\n",
    "    context_matches: List[str]\n",
    "    confidence_score: float\n",
    "    reasoning: str\n",
    "    source_file: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dedaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMProvider(ABC):\n",
    "    \"\"\"Abstract base class for LLM providers\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def analyze_text(self, prompt: str, text: str) -> str:\n",
    "        \"\"\"Analyze text using the specific LLM\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_provider_name(self) -> str:\n",
    "        \"\"\"Return the name of the LLM provider\"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab9b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChatGPTProvider(LLMProvider):\n",
    "    \"\"\"ChatGPT implementation of LLM provider\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, model: str = \"gpt-4\"):\n",
    "        self.client = openai.OpenAI(api_key=api_key)\n",
    "        self.model = model\n",
    "    \n",
    "    def analyze_text(self, prompt: str, text: str) -> str:\n",
    "        \"\"\"Analyze text using ChatGPT\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a financial analyst expert in detecting signs of financial distress in banking institutions.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"{prompt}\\n\\nText to analyze:\\n{text}\"}\n",
    "                ],\n",
    "                max_tokens=1000,\n",
    "                temperature=0.1\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            return f\"Error analyzing with ChatGPT: {str(e)}\"\n",
    "    \n",
    "    def get_provider_name(self) -> str:\n",
    "        return \"ChatGPT\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dffdf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Phi4Provider(LLMProvider):\n",
    "    \"\"\"Phi4 implementation of LLM provider\"\"\"\n",
    "    \n",
    "    def __init__(self, method, model_name, device: Optional[str] = None):\n",
    "                # Setup device\n",
    "        if device is None:\n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        else:\n",
    "            self.device = device\n",
    "            \n",
    "        self.method = method\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "        # Load model with appropriate settings\n",
    "        model_kwargs = {\n",
    "            \"trust_remote_code\": True,\n",
    "            \"torch_dtype\": torch.float16 if self.device == \"cuda\" else torch.float32,\n",
    "            \"device_map\": \"auto\" if self.device == \"cuda\" else None,\n",
    "            }\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.MODEL_NAME,\n",
    "            **model_kwargs\n",
    "        )\n",
    "        print(f\"Loaded Phi4 model: {model_name}\")\n",
    "\n",
    "    def analyze_text(self, prompt: str, text: str) -> str:\n",
    "        \"\"\"Analyze text using Phi4\"\"\"\n",
    "        full_prompt = f\"{prompt}\\n\\nText to analyze:\\n{text}\"\n",
    "        \"\"\"Analyze using Hugging Face transformers\"\"\"\n",
    "        inputs = self.tokenizer.encode(full_prompt, return_tensors=\"pt\", max_length=2048, truncation=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                inputs,\n",
    "                max_new_tokens=500,\n",
    "                temperature=0.1,\n",
    "                do_sample=True,\n",
    "                pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        # Remove the original prompt from the response\n",
    "        return response[len(prompt):].strip()\n",
    "    \n",
    "    def get_provider_name(self) -> str:\n",
    "        return f\"Phi4 ({self.method})\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84c9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class FinancialDistressAnalyzer:\n",
    "    \"\"\"Main analyzer class that processes files and detects financial distress signals\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_provider: LLMProvider):\n",
    "        self.llm_provider = llm_provider\n",
    "        self.prompts = []\n",
    "        self.results = []\n",
    "    \n",
    "    def load_prompts(self, prompts_file_path: str):\n",
    "        \"\"\"Load interrogation prompts from JSON file\"\"\"\n",
    "        try:\n",
    "            with open(prompts_file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                self.prompts = data.get('prompts', [])\n",
    "            print(f\"Loaded {len(self.prompts)} prompts successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading prompts: {str(e)}\")\n",
    "    \n",
    "    def create_analysis_prompt(self, prompt_data: Dict[str, Any]) -> str:\n",
    "        \"\"\"Create a structured prompt for LLM analysis\"\"\"\n",
    "        prompt_template = f\"\"\"\n",
    "You are analyzing financial documents for signs of distress. Focus on the following financial distress indicator:\n",
    "\n",
    "**Category**: {prompt_data['category']}\n",
    "**Indicator**: {prompt_data['name']}\n",
    "\n",
    "**Keywords to look for**: {', '.join(prompt_data['keywords'])}\n",
    "\n",
    "**Context**: {prompt_data.get('context', 'General financial distress indicator')}\n",
    "\n",
    "**Instructions**:\n",
    "1. Carefully search the provided text for any of the specified keywords or related concepts\n",
    "2. Identify specific phrases, sentences, or passages that suggest this type of financial distress\n",
    "3. Provide a confidence score (0-100) indicating how strongly the text suggests this distress indicator\n",
    "4. Explain your reasoning, citing specific text passages as evidence\n",
    "5. If no clear evidence is found, state this explicitly\n",
    "\n",
    "**Required Response Format**:\n",
    "- KEYWORDS_FOUND: [list any keywords found]\n",
    "- CONFIDENCE_SCORE: [0-100]\n",
    "- EVIDENCE: [specific text passages that support your assessment]\n",
    "- REASONING: [detailed explanation of your analysis]\n",
    "- CONCLUSION: [summary of whether this distress indicator is present]\n",
    "\"\"\"\n",
    "        return prompt_template\n",
    "    \n",
    "    def analyze_text_file(self, file_path: str) -> List[AnalysisResult]:\n",
    "        \"\"\"Analyze a text file for financial distress indicators\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                text_content = f.read()\n",
    "            \n",
    "            results = []\n",
    "            \n",
    "            for i, prompt_data in enumerate(self.prompts):\n",
    "                print(f\"Processing prompt {i+1}/{len(self.prompts)}: {prompt_data['name']}\")\n",
    "                \n",
    "                analysis_prompt = self.create_analysis_prompt(prompt_data)\n",
    "                llm_response = self.llm_provider.analyze_text(analysis_prompt, text_content)\n",
    "                \n",
    "                # Parse LLM response\n",
    "                result = self._parse_llm_response(llm_response, prompt_data, file_path)\n",
    "                results.append(result)\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing text file: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def analyze_excel_file(self, file_path: str) -> List[AnalysisResult]:\n",
    "        \"\"\"Analyze an Excel file for financial distress indicators\"\"\"\n",
    "        try:\n",
    "            # Read all sheets from Excel file\n",
    "            excel_data = pd.read_excel(file_path)\n",
    "\n",
    "            combined_text = excel_data.to_string(index=False, header=False)\n",
    "            results = []\n",
    "            \n",
    "            for i, prompt_data in enumerate(self.prompts):\n",
    "                print(f\"Processing Excel prompt {i+1}/{len(self.prompts)}: {prompt_data['name']}\")\n",
    "                \n",
    "                analysis_prompt = self.create_analysis_prompt(prompt_data)\n",
    "                llm_response = self.llm_provider.analyze_text(analysis_prompt, combined_text)\n",
    "                \n",
    "                # Parse LLM response\n",
    "                result = self._parse_llm_response(llm_response, prompt_data, file_path)\n",
    "                results.append(result)\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing Excel file: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def _parse_llm_response(self, response: str, prompt_data: Dict[str, Any], source_file: str) -> AnalysisResult:\n",
    "        \"\"\"Parse LLM response into structured result\"\"\"\n",
    "        try:\n",
    "            # Extract information using regex patterns\n",
    "            keywords_found = self._extract_list_from_response(response, \"KEYWORDS_FOUND\")\n",
    "            confidence_score = self._extract_confidence_score(response)\n",
    "            reasoning = self._extract_section_from_response(response, \"REASONING\")\n",
    "            \n",
    "            # Find context matches in the response\n",
    "            context_matches = []\n",
    "            for keyword in prompt_data['keywords']:\n",
    "                if keyword.lower() in response.lower():\n",
    "                    context_matches.append(keyword)\n",
    "            \n",
    "            return AnalysisResult(\n",
    "                prompt_name=prompt_data['name'],\n",
    "                category=prompt_data['category'],\n",
    "                keywords_found=keywords_found,\n",
    "                context_matches=context_matches,\n",
    "                confidence_score=confidence_score,\n",
    "                reasoning=reasoning,\n",
    "                source_file=source_file\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            return AnalysisResult(\n",
    "                prompt_name=prompt_data['name'],\n",
    "                category=prompt_data['category'],\n",
    "                keywords_found=[],\n",
    "                context_matches=[],\n",
    "                confidence_score=0.0,\n",
    "                reasoning=f\"Error parsing response: {str(e)}\",\n",
    "                source_file=source_file\n",
    "            )\n",
    "    \n",
    "    def _extract_list_from_response(self, response: str, section_name: str) -> List[str]:\n",
    "        \"\"\"Extract list items from LLM response\"\"\"\n",
    "        pattern = f\"{section_name}:\\\\s*(.*?)(?=\\\\n[A-Z_]+:|$)\"\n",
    "        match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            items_text = match.group(1).strip()\n",
    "            # Parse list items\n",
    "            items = [item.strip().strip('[]') for item in items_text.split(',')]\n",
    "            return [item for item in items if item and item != 'None']\n",
    "        return []\n",
    "    \n",
    "    def _extract_confidence_score(self, response: str) -> float:\n",
    "        \"\"\"Extract confidence score from LLM response\"\"\"\n",
    "        pattern = r\"CONFIDENCE_SCORE:\\s*(\\d+(?:\\.\\d+)?)\"\n",
    "        match = re.search(pattern, response, re.IGNORECASE)\n",
    "        if match:\n",
    "            return float(match.group(1))\n",
    "        return 0.0\n",
    "    \n",
    "    def _extract_section_from_response(self, response: str, section_name: str) -> str:\n",
    "        \"\"\"Extract a specific section from LLM response\"\"\"\n",
    "        pattern = f\"{section_name}:\\\\s*(.*?)(?=\\\\n[A-Z_]+:|$)\"\n",
    "        match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        return \"\"\n",
    "    \n",
    "    def generate_report(self, results: List[AnalysisResult], output_file: str = \"financial_distress_report.txt\"):\n",
    "        \"\"\"Generate a comprehensive analysis report\"\"\"\n",
    "        high_risk_indicators = [r for r in results if r.confidence_score >= 70]\n",
    "        medium_risk_indicators = [r for r in results if 30 <= r.confidence_score < 70]\n",
    "        \n",
    "        report = f\"\"\"\n",
    "=== FINANCIAL DISTRESS ANALYSIS REPORT ===\n",
    "LLM Provider: {self.llm_provider.get_provider_name()}\n",
    "Total Indicators Analyzed: {len(results)}\n",
    "\n",
    "=== EXECUTIVE SUMMARY ===\n",
    "High Risk Indicators (70-100): {len(high_risk_indicators)}\n",
    "Medium Risk Indicators (30-69): {len(medium_risk_indicators)}\n",
    "Low Risk Indicators (0-29): {len(results) - len(high_risk_indicators) - len(medium_risk_indicators)}\n",
    "\n",
    "=== HIGH RISK INDICATORS ===\n",
    "\"\"\"\n",
    "        \n",
    "        for result in high_risk_indicators:\n",
    "            report += f\"\"\"\n",
    "Indicator: {result.prompt_name}\n",
    "Category: {result.category}\n",
    "Confidence Score: {result.confidence_score}\n",
    "Source: {result.source_file}\n",
    "Keywords Found: {', '.join(result.keywords_found) if result.keywords_found else 'None'}\n",
    "Reasoning: {result.reasoning}\n",
    "---\n",
    "\"\"\"\n",
    "        \n",
    "        report += \"\\n=== MEDIUM RISK INDICATORS ===\\n\"\n",
    "        \n",
    "        for result in medium_risk_indicators:\n",
    "            report += f\"\"\"\n",
    "Indicator: {result.prompt_name}\n",
    "Category: {result.category}\n",
    "Confidence Score: {result.confidence_score}\n",
    "Source: {result.source_file}\n",
    "Keywords Found: {', '.join(result.keywords_found) if result.keywords_found else 'None'}\n",
    "---\n",
    "\"\"\"\n",
    "        \n",
    "        # Save report to file\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        print(f\"Report saved to {output_file}\")\n",
    "        return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab54e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    print(\"=== Financial Distress Analysis Tool ===\")\n",
    "    \n",
    "    # Choose LLM provider\n",
    "    print(\"\\nAvailable LLM Providers:\")\n",
    "    print(\"1. ChatGPT\")\n",
    "    print(\"2. Phi4\")\n",
    "    \n",
    "    choice = input(\"Select LLM provider (1 or 2): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        api_key = os.environ.get(\"OPENAI_API_KEY\")  # Use environment variable if available\n",
    "        model = \"gpt-4\"\n",
    "        llm_provider = ChatGPTProvider(api_key, model)\n",
    "    elif choice == \"2\":\n",
    "        model_name = \"microsoft/Phi-4\"\n",
    "        method = \"transformers\"       \n",
    "        llm_provider = Phi4Provider(model_name, method)\n",
    "    else:\n",
    "        print(\"Invalid choice. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = FinancialDistressAnalyzer(llm_provider)\n",
    "    \n",
    "    # Load prompts\n",
    "    prompts_file = input(\"Enter path to prompts JSON file: \").strip()\n",
    "    analyzer.load_prompts(prompts_file)\n",
    "    \n",
    "    if not analyzer.prompts:\n",
    "        print(\"No prompts loaded. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Analyze files\n",
    "    all_results = []\n",
    "    \n",
    "    # Analyze text file\n",
    "    text_file = input(\"Enter path to text file (JPM presentation): \").strip()\n",
    "    if text_file:\n",
    "        print(f\"\\nAnalyzing text file: {text_file}\")\n",
    "        text_results = analyzer.analyze_text_file(text_file)\n",
    "        all_results.extend(text_results)\n",
    "    \n",
    "    # Analyze Excel file\n",
    "    excel_file = input(\"Enter path to Excel file (JPM Q&A data): \").strip()\n",
    "    if excel_file:\n",
    "        print(f\"\\nAnalyzing Excel file: {excel_file}\")\n",
    "        excel_results = analyzer.analyze_excel_file(excel_file)\n",
    "        all_results.extend(excel_results)\n",
    "    \n",
    "    # Generate report\n",
    "    if all_results:\n",
    "        print(f\"\\nGenerating analysis report...\")\n",
    "        report = analyzer.generate_report(all_results)\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ANALYSIS COMPLETE\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Total indicators analyzed: {len(all_results)}\")\n",
    "        print(f\"High risk indicators found: {len([r for r in all_results if r.confidence_score >= 70])}\")\n",
    "        print(\"Report saved to: financial_distress_report.txt\")\n",
    "    else:\n",
    "        print(\"No results to analyze.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f363324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
