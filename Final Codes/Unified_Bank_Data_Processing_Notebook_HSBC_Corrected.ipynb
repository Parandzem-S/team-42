{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f223aa",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154c5041",
   "metadata": {},
   "source": [
    "!pip install pdfplumber \\\n",
    "!pip install openai-whisper \\\n",
    "!sudo apt update && sudo apt install ffmpeg \\\n",
    "!pip install pdfplumber openai pandas tiktoken \n",
    "\n",
    "!pip install spacy \\\n",
    "!pip install bertopic \n",
    "\n",
    "!pip install openpyxl \\\n",
    "!pip install transformers \\\n",
    "!pip install tqdm \\\n",
    "pip install accelerate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47750ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# --- Standard Library ---\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "\n",
    "# --- Third-Party Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "import pdfplumber\n",
    "import torch\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- NLP Libraries ---\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "# --- Hugging Face Transformers ---\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "# --- Sentence Transformers & BERTopic ---\n",
    "# from sentence_transformers import SentenceTransformer, util\n",
    "# from bertopic import BERTopic\n",
    "\n",
    "# --- Clustering & Dimensionality Reduction ---\n",
    "# from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# --- Google Colab / Google Drive ---\n",
    "# from google.colab import drive\n",
    "import gdown\n",
    "\n",
    "# --- Setup ---\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "# --- NLTK Downloads ---\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "# --- spaCy Model Loading ---\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    os.system(\"python -m spacy download en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afc3a96",
   "metadata": {},
   "source": [
    "# üè¢ HSBC - Presentation and Q&A Extraction\n",
    "This section processes and extracts Presentation and Q&A data using BERT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753e61a4",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal titles pattern (dynamic, fully general)\n",
    "internal_title_pattern = re.compile(\n",
    "    r\"(Group|Chief|Officer|CEO|CFO|Treasurer|Head|Director|Vice President|Finance|Investor Relations|Chairman|Chair|IR)\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Fully improved internal speaker detection:\n",
    "def is_internal_speaker(institution):\n",
    "    if not institution or institution.strip() == \"\":\n",
    "        return True\n",
    "    if re.search(r\"hsbc\", institution, re.IGNORECASE):\n",
    "        return True\n",
    "    return bool(internal_title_pattern.search(institution))\n",
    "\n",
    "def is_external_speaker(institution):\n",
    "    return not is_internal_speaker(institution)\n",
    "\n",
    "def extract_qa_from_pdf(pdf_path, file_label=None):\n",
    "    qa_data = []\n",
    "    current_speaker = \"\"\n",
    "    current_institution = \"\"\n",
    "    current_text = []\n",
    "\n",
    "    speaker_institutions = {}\n",
    "    question_number = -1\n",
    "    current_question_owner = None\n",
    "    in_qa_section = False\n",
    "\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            first_page_text = pdf.pages[0].extract_text()\n",
    "\n",
    "            # YEAR DETECTION\n",
    "            year = None\n",
    "            year_match = re.search(r\"\\b(20[1-3][0-9])\\b\", first_page_text)\n",
    "            if year_match:\n",
    "                year = int(year_match.group(1))\n",
    "\n",
    "            # QUARTER DETECTION (fully robust)\n",
    "            quarter = \"Unknown\"\n",
    "            quarter_text = first_page_text.lower()\n",
    "\n",
    "            post_results_match = re.search(r\"post-results\\s+([A-Za-z\\s\\-]+)\", first_page_text, re.IGNORECASE)\n",
    "            if post_results_match:\n",
    "                quarter = \"Post-Results \" + post_results_match.group(1).strip()\n",
    "            elif re.search(r\"\\bq\\s*4\\b\", quarter_text):\n",
    "                quarter = 4\n",
    "            elif re.search(r\"\\bq\\s*3\\b\", quarter_text):\n",
    "                quarter = 3\n",
    "            elif re.search(r\"\\bq\\s*2\\b\", quarter_text):\n",
    "                quarter = 2\n",
    "            elif re.search(r\"\\bq\\s*1\\b\", quarter_text):\n",
    "                quarter = 1\n",
    "            elif re.search(r\"interim\", quarter_text) and re.search(r\"\\bh[\\s\\-]*1\\b\", quarter_text):\n",
    "                quarter = \"Interim/H1\"\n",
    "            elif re.search(r\"interim\", quarter_text):\n",
    "                quarter = \"Interim\"\n",
    "            elif re.search(r\"\\bh[\\s\\-]*1\\b\", quarter_text):\n",
    "                quarter = \"H1\"\n",
    "            elif re.search(r\"\\bannual\\b|\\bfull\\s*year\\b\", quarter_text):\n",
    "                quarter = \"Annual\"\n",
    "\n",
    "            for page in pdf.pages:\n",
    "                text = page.extract_text()\n",
    "                if not text:\n",
    "                    continue\n",
    "                lines = text.split(\"\\n\")\n",
    "\n",
    "                for line in lines:\n",
    "                    # Q&A section detection\n",
    "                    line_clean = re.sub(r\"[\\W_]+\", \"\", line.lower())\n",
    "                    if not in_qa_section and re.search(r\"(qa|questionsandanswers|questions)\", line_clean):\n",
    "                        in_qa_section = True\n",
    "                        continue\n",
    "\n",
    "                    # Flexible speaker matching\n",
    "                    match_full = re.match(r\"^([A-Z\\s\\.]+),\\s*([A-Za-z\\s&]+):\\s*(.*)\", line)\n",
    "                    if match_full:\n",
    "                        speaker = match_full.group(1).title()\n",
    "                        institution = match_full.group(2).title()\n",
    "                        remainder = match_full.group(3).strip()\n",
    "                    else:\n",
    "                        match_short = re.match(r\"^([A-Z\\s\\.]+):\\s*(.*)\", line)\n",
    "                        if match_short:\n",
    "                            speaker = match_short.group(1).title()\n",
    "                            institution = speaker_institutions.get(speaker, \"\")  # Use previous institution if known\n",
    "                            remainder = match_short.group(2).strip()\n",
    "                        else:\n",
    "                            if line.strip():\n",
    "                                current_text.append(line.strip())\n",
    "                            continue\n",
    "\n",
    "                    # Save previous block\n",
    "                    if current_text:\n",
    "                        flag_question = (\n",
    "                            in_qa_section and current_speaker == current_question_owner\n",
    "                        )\n",
    "                        presentation = 1 if question_number in [None, -1] else 0\n",
    "\n",
    "                        qa_data.append({\n",
    "                            \"File\": file_label or os.path.basename(pdf_path),\n",
    "                            \"Bank Name\": \"HSBC\",\n",
    "                            \"Year\": year,\n",
    "                            \"Quarter\": quarter,\n",
    "                            \"Speaker name\": current_speaker,\n",
    "                            \"Institution\": current_institution,\n",
    "                            \"Speaker text\": \" \".join(current_text),\n",
    "                            \"flag_question\": flag_question,\n",
    "                            \"Question No\": question_number if in_qa_section else None,\n",
    "                            \"presentation\": presentation\n",
    "                        })\n",
    "                        current_text = []\n",
    "\n",
    "                    # Update current speaker\n",
    "                    current_speaker = speaker\n",
    "                    current_institution = institution\n",
    "                    speaker_institutions[current_speaker] = current_institution\n",
    "\n",
    "                    # Dynamically switch to Q&A when first external detected\n",
    "                    if not in_qa_section and is_external_speaker(current_institution):\n",
    "                        in_qa_section = True\n",
    "\n",
    "                    # FULLY FIXED QUESTION NUMBERING LOGIC \n",
    "                    if in_qa_section:\n",
    "                        if is_external_speaker(current_institution):\n",
    "                            if current_question_owner != current_speaker:\n",
    "                                question_number += 1\n",
    "                                current_question_owner = current_speaker\n",
    "\n",
    "                    if remainder:\n",
    "                        current_text.append(remainder)\n",
    "\n",
    "            # Save final block\n",
    "            if current_text:\n",
    "                flag_question = (\n",
    "                    in_qa_section and current_speaker == current_question_owner\n",
    "                )\n",
    "                presentation = 1 if question_number in [None, -1] else 0\n",
    "\n",
    "                qa_data.append({\n",
    "                    \"File\": file_label or os.path.basename(pdf_path),\n",
    "                    \"Bank Name\": \"HSBC\",\n",
    "                    \"Year\": year,\n",
    "                    \"Quarter\": quarter,\n",
    "                    \"Speaker name\": current_speaker,\n",
    "                    \"Institution\": current_institution,\n",
    "                    \"Speaker text\": \" \".join(current_text),\n",
    "                    \"flag_question\": flag_question,\n",
    "                    \"Question No\": question_number if in_qa_section else None,\n",
    "                    \"presentation\": presentation\n",
    "                })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")\n",
    "\n",
    "    return qa_data\n",
    "\n",
    "def process_all_pdfs(root_dir):\n",
    "    all_results = []\n",
    "\n",
    "    for root, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".pdf\"):\n",
    "                full_path = os.path.join(root, file)\n",
    "                rel_path = os.path.relpath(full_path, root_dir)\n",
    "                print(f\"Processing: {rel_path}\")\n",
    "                qa_rows = extract_qa_from_pdf(full_path, file_label=rel_path)\n",
    "                all_results.extend(qa_rows)\n",
    "\n",
    "    df_all = pd.DataFrame(all_results)\n",
    "    df_all = df_all[df_all['Speaker name'].str.strip() != \"\"]\n",
    "    df_all.to_csv(\"combined_all_qas.csv\", index=False)\n",
    "    return df_all\n",
    "\n",
    "# # USAGE\n",
    "# df = process_all_pdfs(r\"C:\\Users\\User\\Desktop\\CAM_BoE_GitHub\\team-42\\HSBC\\HSBC Presentation texts\")\n",
    "\n",
    "#reading files from drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950de181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2021\\210427-1q-2021-presentation-to-investors-and-analysts-transcript.pdf\n",
      "Processing: Presentation Transcripts\\2021\\210803-interim-results-2021-presentation-to-investors-and-analysts-transcript.pdf\n",
      "Processing: Presentation Transcripts\\2021\\210810-fixed-income-call-transcript interim.pdf\n",
      "Processing: Presentation Transcripts\\2021\\211025-3q-2021-presentation-to-investors-and-analysts-transcript.pdf\n",
      "Processing: Presentation Transcripts\\2021\\220224-hsbc-fixed-income-call-2021-annual-results-22-02-20-final.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2021\\220228-fy-2021-equity-analyst-meeting-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2022\\220223-annual-results-2022-fixed-income-investor-presentation-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2022\\220802-interim-results-2022-presentation-to-investors-and-analysts-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2022\\220808-interim-results-2022-presentation-to-fixed-income-investors-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2022\\220902-h1-2022-equity-analyst-meeting-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2022\\221026-3q-2022-presentation-to-investors-and-analysts-transcript.pdf\n",
      "Processing: Presentation Transcripts\\2022\\230221-annual-results-2022-presentation-to-investors-and-analysts-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2022\\230228-annual-results-2022-fy-2022-equity-analysts-meeting-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2023\\230502-1q-2023-hsbc-presentation-to-investors-and-analysts-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2023\\230802-interim-results-2023-presentation-to-investors-and-analysts-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2023\\230908-interim-results-2023-fixed-income-investors-conference-call-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2023\\231030-3q-2023-presentation-to-investors-and-analysts-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2023\\240222-annual-results-2023-presentation-to-investors-and-analysts-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2023\\240229-fy-2023-equity-analysts-meeting-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2024\\240502-1q-2024-hsbc-presentation-to-investors-and-analysts-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2024\\240801-interim-results-2024-presentation-to-fixed-income-investors-transcript.pdf\n",
      "Processing: Presentation Transcripts\\2024\\240801-interim-results-2024-presentation-to-investors-and-analysts-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2024\\240806-interim-results-2024-equity-analysts-meeting-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2024\\241029-q3-results-to-investors-and-analysts-transcript.pdf\n",
      "Processing: Presentation Transcripts\\2024\\250220-annual-results-to-investors-and-analysts-transcript.pdf\n",
      "Processing: Presentation Transcripts\\2024\\250221-fy-2024-fixed-income-investor-call-transcript.pdf\n",
      "Processing: Presentation Transcripts\\2024\\250228-fy-2024-equity-analysts-meeting-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Presentation Transcripts\\2025\\250429-1q-2025-earnings-release-investors-and-analysts-call-transcript.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Download the entire folder recursively using gdown\n",
    "folder_url = \"https://drive.google.com/drive/folders/1K-LnQdiKCxkzjQOjXcfhEjCM0McaDBuT\"\n",
    "local_dir = \"./hsbc_pdfs\"\n",
    "\n",
    "# Only download if not already done\n",
    "if not os.path.exists(local_dir):\n",
    "    gdown.download_folder(url=folder_url, output=local_dir, quiet=False, use_cookies=False)\n",
    "\n",
    "# Step 2: Your existing PDF processing logic\n",
    "def is_internal_speaker(institution):\n",
    "    if not institution or institution.strip() == \"\":\n",
    "        return True\n",
    "    if re.search(r\"hsbc\", institution, re.IGNORECASE):\n",
    "        return True\n",
    "    return bool(re.search(r\"(Group|Chief|Officer|CEO|CFO|Treasurer|Head|Director|Vice President|Finance|Investor Relations|Chairman|Chair|IR)\", institution, re.IGNORECASE))\n",
    "\n",
    "def is_external_speaker(institution):\n",
    "    return not is_internal_speaker(institution)\n",
    "\n",
    "# (Paste your full extract_qa_from_pdf function here unchanged)\n",
    "\n",
    "# Step 3: Walk through downloaded folder recursively\n",
    "def process_all_pdfs(root_dir):\n",
    "    all_results = []\n",
    "\n",
    "    for root, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".pdf\"):\n",
    "                full_path = os.path.join(root, file)\n",
    "                rel_path = os.path.relpath(full_path, root_dir)\n",
    "                print(f\"Processing: {rel_path}\")\n",
    "                qa_rows = extract_qa_from_pdf(full_path, file_label=rel_path)\n",
    "                all_results.extend(qa_rows)\n",
    "\n",
    "    df_all = pd.DataFrame(all_results)\n",
    "    df_all = df_all[df_all['Speaker name'].str.strip() != \"\"]\n",
    "    df_all.to_csv(\"combined_all_qas.csv\", index=False)\n",
    "    return df_all\n",
    "\n",
    "# Run the whole pipeline\n",
    "df = process_all_pdfs(local_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6211aa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Bank Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Speaker name</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Speaker text</th>\n",
       "      <th>flag_question</th>\n",
       "      <th>Question No</th>\n",
       "      <th>presentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Presentation Transcripts\\2021\\210427-1q-2021-p...</td>\n",
       "      <td>HSBC</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>Noel Quinn</td>\n",
       "      <td>Group Chief Executive</td>\n",
       "      <td>Good morning in London and good afternoon in H...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Presentation Transcripts\\2021\\210427-1q-2021-p...</td>\n",
       "      <td>HSBC</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>Ewen Stevenson</td>\n",
       "      <td>Group Chief Financial Officer</td>\n",
       "      <td>Thanks, Noel, and good morning or afternoon, a...</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Presentation Transcripts\\2021\\210427-1q-2021-p...</td>\n",
       "      <td>HSBC</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>Ed Firth</td>\n",
       "      <td>Kbw</td>\n",
       "      <td>Good morning, everybody. I just had two questi...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Presentation Transcripts\\2021\\210427-1q-2021-p...</td>\n",
       "      <td>HSBC</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>Ewen Stevenson</td>\n",
       "      <td>Group Chief Financial Officer</td>\n",
       "      <td>On restructuring charges, we‚Äôre not changing o...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Presentation Transcripts\\2021\\210427-1q-2021-p...</td>\n",
       "      <td>HSBC</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>Ed Firth</td>\n",
       "      <td>Kbw</td>\n",
       "      <td>Based on what we can see, the bulk of those so...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                File Bank Name  Year Quarter  \\\n",
       "1  Presentation Transcripts\\2021\\210427-1q-2021-p...      HSBC  2021       1   \n",
       "2  Presentation Transcripts\\2021\\210427-1q-2021-p...      HSBC  2021       1   \n",
       "3  Presentation Transcripts\\2021\\210427-1q-2021-p...      HSBC  2021       1   \n",
       "4  Presentation Transcripts\\2021\\210427-1q-2021-p...      HSBC  2021       1   \n",
       "5  Presentation Transcripts\\2021\\210427-1q-2021-p...      HSBC  2021       1   \n",
       "\n",
       "     Speaker name                    Institution  \\\n",
       "1      Noel Quinn          Group Chief Executive   \n",
       "2  Ewen Stevenson  Group Chief Financial Officer   \n",
       "3        Ed Firth                            Kbw   \n",
       "4  Ewen Stevenson  Group Chief Financial Officer   \n",
       "5        Ed Firth                            Kbw   \n",
       "\n",
       "                                        Speaker text  flag_question  \\\n",
       "1  Good morning in London and good afternoon in H...          False   \n",
       "2  Thanks, Noel, and good morning or afternoon, a...          False   \n",
       "3  Good morning, everybody. I just had two questi...           True   \n",
       "4  On restructuring charges, we‚Äôre not changing o...          False   \n",
       "5  Based on what we can see, the bulk of those so...           True   \n",
       "\n",
       "   Question No  presentation  \n",
       "1          NaN             1  \n",
       "2         -1.0             1  \n",
       "3          0.0             0  \n",
       "4          0.0             0  \n",
       "5          0.0             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c97c8b",
   "metadata": {},
   "source": [
    "## BERT and FinBert Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "969b6a2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SentenceTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 91\u001b[39m\n\u001b[32m     88\u001b[39m device = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m device_index = \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device == \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m -\u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m embedding_model = \u001b[43mSentenceTransformer\u001b[49m(\u001b[33m'\u001b[39m\u001b[33msentence-transformers/all-mpnet-base-v2\u001b[39m\u001b[33m'\u001b[39m, device=device)\n\u001b[32m     92\u001b[39m embeddings = embedding_model.encode(df_qa[\u001b[33m'\u001b[39m\u001b[33mSpeaker text cleaned\u001b[39m\u001b[33m'\u001b[39m].tolist(), show_progress_bar=\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size=\u001b[32m32\u001b[39m)\n\u001b[32m     94\u001b[39m umap_model = UMAP(n_neighbors=\u001b[32m10\u001b[39m, n_components=\u001b[32m5\u001b[39m, min_dist=\u001b[32m0.1\u001b[39m, metric=\u001b[33m'\u001b[39m\u001b[33mcosine\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'SentenceTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Q&A filler phrases ---\n",
    "qa_filler_phrases = [\n",
    "    \"thanks\", \"thank you\", \"appreciate\", \"question\", \"questions\", \"ask\", \"asking\", \"follow-up\", \n",
    "    \"couple of questions\", \"good morning\", \"good afternoon\", \"hello\", \"thanks for taking my question\",\n",
    "    \"thanks for the call\", \"thank you for your time\", \"joining us\", \"line is open\", \"line\", \n",
    "    \"hand over\", \"presentation\", \"prepared remarks\", \"pick up with ir team\", \"management remarks\", \n",
    "    \"closing remarks\", \"just wondering\", \"can you talk a bit more about\", \"could you elaborate\", \n",
    "    \"as you mentioned\", \"as you said\", \"i guess\", \"i wonder if\", \"may i ask\", \"i was going to ask\",\n",
    "    \"one more question\", \"a quick clarification\", \"sorry to go on\", \"very helpful\", \"hope that makes sense\",\n",
    "    \"buyback\", \"payout ratio\", \"dividend policy\", \"progressive dividend\", \"distribution policy\", \n",
    "    \"capital management\", \"common equity tier one\", \"cet1\", \"surplus capital\", \"capital efficiency\",\n",
    "    \"loan growth\", \"lending volume\", \"mortgage growth\", \"unsecured lending\", \"credit card balances\",\n",
    "    \"loan demand\", \"pipeline growth\", \"mortgage book\", \"consumer lending\", \"personal banking\",\n",
    "    \"variable pay\", \"compensation pool\", \"performance-related pay\", \"transformation cost savings\",\n",
    "    \"management focus on costs\", \"broadly flat cost\", \"cost inflation\", \"hiring plans\", \"competitive pressures\",\n",
    "    \"t&e\", \"travel expense\", \"operating expenses\", \"uk\", \"hong kong\", \"asia\", \"us\", \"europe\", \n",
    "    \"mainland china\", \"greater bay area\"\n",
    "]\n",
    "\n",
    "# --- Hedge words ---\n",
    "hedge_verbs = [\n",
    "    \"think\", \"know\", \"see\", \"believe\", \"wonder\", \"expect\", \"assume\", \"guess\", \n",
    "    \"probably\", \"maybe\", \"feel\", \"suppose\", \"suggest\", \"consider\", \"estimate\", \n",
    "    \"intend\", \"anticipate\", \"imagine\", \"hope\", \"trying\", \"might\", \"would\", \"could\", \"should\"\n",
    "]\n",
    "\n",
    "# --- Financial stopwords ---\n",
    "financial_stopwords = [\n",
    "    \"basis\", \"points\", \"million\", \"billion\", \"percent\", \"percentage\", \"cost\", \"costs\", \"capital\", \n",
    "    \"equity\", \"return\", \"dividend\", \"buyback\", \"allocation\", \"guidance\", \"expenditure\", \"earnings\", \n",
    "    \"profit\", \"margin\", \"revenue\", \"interest\", \"hedging\", \"hedge\", \"swap\", \"currency\", \"fx\", \n",
    "    \"sensitivity\", \"structural\", \"stack\", \"tier\", \"rwas\", \"provisions\", \"charges\", \"impairment\", \n",
    "    \"grandfathering\", \"issuance\", \"liquidity\", \"loan\", \"loans\", \"mortgage\", \"deposit\", \"assets\", \n",
    "    \"lending\", \"borrowers\", \"defaults\", \"exposure\", \"collateral\", \"refinancing\", \"provisioning\", \n",
    "    \"counterparty\", \"wealth\", \"insurance\", \"private\", \"trade\", \"transaction\", \"client\", \"portfolio\", \n",
    "    \"invested\", \"funding\", \"treasury\", \"surplus\", \"liabilities\", \"compliance\", \"legacy\", \n",
    "    \"volatility\", \"ratios\", \"metrics\", \"leverage\", \"valuation\", \"scenario\", \"assumptions\", \n",
    "    \"calculations\", \"underlying\", \"sovereign\", \"macroeconomic\"\n",
    "]\n",
    "\n",
    "# --- Function words ---\n",
    "function_stopwords = [\n",
    "    \"we\", \"have\", \"has\", \"had\", \"were\", \"was\", \"are\", \"is\", \"it's\", \"its\", \"being\", \"been\", \n",
    "    \"do\", \"does\", \"doing\", \"did\", \"can\", \"may\", \"might\", \"come\", \"comes\", \"going\"\n",
    "]\n",
    "\n",
    "# ==========================\n",
    "# BUILD FINAL STOPWORDS LIST\n",
    "# ==========================\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "base_stopwords = set(stopwords.words(\"english\"))\n",
    "domain_stopwords = set(qa_filler_phrases + hedge_verbs + financial_stopwords + function_stopwords)\n",
    "all_stopwords = base_stopwords.union(domain_stopwords)\n",
    "\n",
    "# Load speaker names dynamically and add\n",
    "speaker_names = df['Speaker name'].dropna().unique().tolist()\n",
    "speaker_parts = set()\n",
    "for name in speaker_names:\n",
    "    for part in name.split():\n",
    "        speaker_parts.add(part.lower())\n",
    "\n",
    "all_stopwords = all_stopwords.union(speaker_parts)\n",
    "\n",
    "# ==========================\n",
    "# CLEANING FUNCTION\n",
    "# ==========================\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in text.split() if w not in all_stopwords and len(w) > 2]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# ==========================\n",
    "# FILTER Q&A (presentation == 0)\n",
    "# ==========================\n",
    "\n",
    "df_qa = df[df['presentation'] == 0].copy()\n",
    "df_qa['Speaker text cleaned'] = df_qa['Speaker text'].astype(str).apply(clean_text)\n",
    "df_qa = df_qa[df_qa['Speaker text cleaned'].str.split().apply(len) >= 5]\n",
    "\n",
    "# ==========================\n",
    "# EMBEDDING & TOPIC MODELING\n",
    "# ==========================\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_index = 0 if device == \"cuda\" else -1\n",
    "\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "embeddings = embedding_model.encode(df_qa['Speaker text cleaned'].tolist(), show_progress_bar=True, batch_size=32)\n",
    "\n",
    "umap_model = UMAP(n_neighbors=10, n_components=5, min_dist=0.1, metric='cosine')\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=5, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    top_n_words=15,\n",
    "    calculate_probabilities=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(df_qa['Speaker text cleaned'].tolist(), embeddings=embeddings)\n",
    "df_qa['Topic'] = [0 if t == -1 else t for t in topics]\n",
    "df_qa['Top_15_Words'] = [\", \".join([w for w, _ in topic_model.get_topic(topic)[:15]]) for topic in topics]\n",
    "\n",
    "# ==========================\n",
    "# VISUALIZATION\n",
    "# ==========================\n",
    "\n",
    "fig_bar = topic_model.visualize_barchart(top_n_topics=10)\n",
    "fig_bar.show()\n",
    "\n",
    "try:\n",
    "    fig_topics = topic_model.visualize_topics()\n",
    "    fig_topics.show()\n",
    "except Exception as e:\n",
    "    print(f\"BERTopic topic map error: {e}\")\n",
    "\n",
    "# ==========================\n",
    "# FINBERT SENTIMENT\n",
    "# ==========================\n",
    "\n",
    "finbert_tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "finbert_model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\n",
    "finbert_pipeline = pipeline(\"sentiment-analysis\", model=finbert_model, tokenizer=finbert_tokenizer, device=device_index)\n",
    "\n",
    "sentiments = []\n",
    "BATCH_SIZE = 32\n",
    "for i in tqdm(range(0, len(df_qa), BATCH_SIZE)):\n",
    "    batch = df_qa['Speaker text cleaned'].iloc[i:i+BATCH_SIZE].tolist()\n",
    "    batch_sentiments = finbert_pipeline(batch, truncation=True, max_length=512, padding=True)\n",
    "    sentiments.extend(batch_sentiments)\n",
    "\n",
    "df_qa['FinBERT_Sentiment'] = [x['label'] for x in sentiments]\n",
    "df_qa['FinBERT_Score'] = [x['score'] for x in sentiments]\n",
    "\n",
    "# ==========================\n",
    "# FINAL OUTPUT\n",
    "# ==========================\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df_qa[['Speaker text', 'Speaker text cleaned', 'Topic', 'Top_15_Words', 'FinBERT_Sentiment', 'FinBERT_Score']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72eec51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     0.774468\n",
       "positive    0.175532\n",
       "negative    0.050000\n",
       "Name: FinBERT_Sentiment, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qa.FinBERT_Sentiment.value_counts()/df_qa.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912c907",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_qa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- Fully unstack-free, pivot-free, bulletproof aggregation ---\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Build the counts\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m sentiment_counts = \u001b[43mdf_qa\u001b[49m.groupby([\u001b[33m'\u001b[39m\u001b[33mTopic\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mFinBERT_Sentiment\u001b[39m\u001b[33m'\u001b[39m]).size().reset_index(name=\u001b[33m'\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Initialize full dataframe of all Topics\u001b[39;00m\n\u001b[32m      7\u001b[39m all_topics = pd.DataFrame({\u001b[33m'\u001b[39m\u001b[33mTopic\u001b[39m\u001b[33m'\u001b[39m: df_qa[\u001b[33m'\u001b[39m\u001b[33mTopic\u001b[39m\u001b[33m'\u001b[39m].unique()}).sort_values(\u001b[33m'\u001b[39m\u001b[33mTopic\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_qa' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Fully unstack-free, pivot-free, bulletproof aggregation ---\n",
    "\n",
    "# Build the counts\n",
    "sentiment_counts = df_qa.groupby(['Topic', 'FinBERT_Sentiment']).size().reset_index(name='count')\n",
    "\n",
    "# Initialize full dataframe of all Topics\n",
    "all_topics = pd.DataFrame({'Topic': df_qa['Topic'].unique()}).sort_values('Topic')\n",
    "\n",
    "# Merge manually per sentiment\n",
    "for sentiment in ['positive', 'neutral', 'negative']:\n",
    "    temp = sentiment_counts[sentiment_counts['FinBERT_Sentiment'] == sentiment][['Topic', 'count']].rename(columns={'count': sentiment})\n",
    "    all_topics = all_topics.merge(temp, on='Topic', how='left')\n",
    "\n",
    "# Replace any missing counts with 0\n",
    "all_topics = all_topics.fillna(0).astype({'positive': 'int', 'neutral': 'int', 'negative': 'int'})\n",
    "\n",
    "# Totals for safe division\n",
    "total_pos = all_topics['positive'].sum()\n",
    "total_neu = all_topics['neutral'].sum()\n",
    "total_neg = all_topics['negative'].sum()\n",
    "\n",
    "# Calculate percentages\n",
    "all_topics['%_positive'] = (all_topics['positive'] / total_pos * 100).round(2) if total_pos else 0\n",
    "all_topics['%_neutral']  = (all_topics['neutral']  / total_neu * 100).round(2) if total_neu else 0\n",
    "all_topics['%_negative'] = (all_topics['negative'] / total_neg * 100).round(2) if total_neg else 0\n",
    "\n",
    "# Attach BERTopic words\n",
    "all_topics['Top_15_Words'] = df_qa.groupby('Topic')['Top_15_Words'].first().reindex(all_topics['Topic'].values).values\n",
    "\n",
    "# Reorder\n",
    "cols = [\n",
    "    'Top_15_Words',\n",
    "    'positive', '%_positive',\n",
    "    'neutral', '%_neutral',\n",
    "    'negative', '%_negative'\n",
    "]\n",
    "final_table = all_topics[cols].reset_index(drop=True)\n",
    "\n",
    "# Display\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "\n",
    "final_table.to_csv(\"hsbc_final_sentiment_analysis.csv\", index=False)\n",
    "final_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618651f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"hsbc_qa_analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e2481",
   "metadata": {},
   "source": [
    "## Phi-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "857f5d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.60s/it]\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Q&A pairs based on Year, Quarter, Question No grouping (Q&A session only)...\n",
      "Found 219 Q&A pairs from Q&A session only (presentation==0)\n",
      "\n",
      "Filtered to Q&A session: 1065 rows from 1141 total rows\n",
      "First few Q&A pairs:\n",
      "  Pair 1: Year=2021, Quarter=1, Q_No=0.0\n",
      "    Questions: 2 rows, Answers: 2 rows\n",
      "    Question preview: Good morning, everybody. I just had two questions. The first was on capital. I was surprised that th...\n",
      "    Answer preview: On restructuring charges, we‚Äôre not changing our full-year guidance we gave at full-year results. Yo...\n",
      "\n",
      "  Pair 2: Year=2021, Quarter=1, Q_No=1.0\n",
      "    Questions: 1 rows, Answers: 1 rows\n",
      "    Question preview: Morning. Just a couple of questions. The first one is on margins. You gave colour on this, Ewen, dur...\n",
      "    Answer preview: On NIM, it was, I think, almost exclusively driven by the shift in yield curves. We‚Äôve broadly repri...\n",
      "\n",
      "  Pair 3: Year=2021, Quarter=1, Q_No=2.0\n",
      "    Questions: 3 rows, Answers: 4 rows\n",
      "    Question preview: Good morning. Thank you for the questions. My question is that, with the Wealth and Personal Banking...\n",
      "    Answer preview: Omar, thank you. As you know, our primary focus in the WPB business is to grow our Wealth part of th...\n",
      "\n",
      "Created 219 prompts for processing\n",
      "Processing batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  21%|‚ñà‚ñà‚ñè       | 3/14 [11:16<41:19, 225.42s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 162\u001b[39m\n\u001b[32m    159\u001b[39m batch = prompts[i:i + batch_size]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     outputs = \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     batch_outputs = []\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m outputs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\text_generation.py:302\u001b[39m, in \u001b[36mTextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, text_inputs, **kwargs)\u001b[39m\n\u001b[32m    300\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    301\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(chats), **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\base.py:1412\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1408\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[32m   1409\u001b[39m     final_iterator = \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   1410\u001b[39m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[32m   1411\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1412\u001b[39m     outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[32m   1414\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m item = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator)\n\u001b[32m    125\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m    124\u001b[39m item = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    128\u001b[39m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\base.py:1338\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1336\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1337\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1340\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\text_generation.py:400\u001b[39m, in \u001b[36mTextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    398\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[32m    403\u001b[39m     generated_sequence = output.sequences\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\generation\\utils.py:2597\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2589\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2590\u001b[39m         input_ids=input_ids,\n\u001b[32m   2591\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2592\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2593\u001b[39m         **model_kwargs,\n\u001b[32m   2594\u001b[39m     )\n\u001b[32m   2596\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2597\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2608\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2609\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2610\u001b[39m         input_ids=input_ids,\n\u001b[32m   2611\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2612\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2613\u001b[39m         **model_kwargs,\n\u001b[32m   2614\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\generation\\utils.py:3560\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3558\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3560\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3562\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3563\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3564\u001b[39m     outputs,\n\u001b[32m   3565\u001b[39m     model_kwargs,\n\u001b[32m   3566\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3567\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-4-mini-instruct\\5a149550068a1eb93398160d8953f5f56c3603e9\\modeling_phi3.py:913\u001b[39m, in \u001b[36mPhi3ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    910\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m    912\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m913\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    927\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    928\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-4-mini-instruct\\5a149550068a1eb93398160d8953f5f56c3603e9\\modeling_phi3.py:636\u001b[39m, in \u001b[36mPhi3Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    624\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    625\u001b[39m         decoder_layer.\u001b[34m__call__\u001b[39m,\n\u001b[32m    626\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    633\u001b[39m         position_embeddings,\n\u001b[32m    634\u001b[39m     )\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    648\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-4-mini-instruct\\5a149550068a1eb93398160d8953f5f56c3603e9\\modeling_phi3.py:296\u001b[39m, in \u001b[36mPhi3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    293\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    295\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m hidden_states, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m hidden_states = residual + \u001b[38;5;28mself\u001b[39m.resid_attn_dropout(hidden_states)  \u001b[38;5;66;03m# main diff with Llama\u001b[39;00m\n\u001b[32m    309\u001b[39m residual = hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-4-mini-instruct\\5a149550068a1eb93398160d8953f5f56c3603e9\\modeling_phi3.py:191\u001b[39m, in \u001b[36mPhi3Attention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m value_states = value_states.view(hidden_shape).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    190\u001b[39m cos, sin = position_embeddings\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m query_states, key_states = \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    194\u001b[39m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[32m    195\u001b[39m     cache_kwargs = {\u001b[33m\"\u001b[39m\u001b[33msin\u001b[39m\u001b[33m\"\u001b[39m: sin, \u001b[33m\"\u001b[39m\u001b[33mcos\u001b[39m\u001b[33m\"\u001b[39m: cos, \u001b[33m\"\u001b[39m\u001b[33mcache_position\u001b[39m\u001b[33m\"\u001b[39m: cache_position}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-4-mini-instruct\\5a149550068a1eb93398160d8953f5f56c3603e9\\modeling_phi3.py:145\u001b[39m, in \u001b[36mapply_rotary_pos_emb\u001b[39m\u001b[34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[39m\n\u001b[32m    142\u001b[39m q_rot, q_pass = q[..., :rotary_dim], q[..., rotary_dim:]\n\u001b[32m    143\u001b[39m k_rot, k_pass = k[..., :rotary_dim], k[..., rotary_dim:]\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m q_embed = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_rot\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mrotate_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_rot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_pass\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m k_embed = torch.cat([(k_rot * cos) + (rotate_half(k_rot) * sin), k_pass], dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import re\n",
    "\n",
    "# Setup\n",
    "torch.backends.cudnn.benchmark = True\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Loading model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-4-mini-instruct\", trust_remote_code=True)\n",
    "tokenizer.padding_side = 'left'\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"microsoft/Phi-4-mini-instruct\",\n",
    "        torch_dtype=torch.float16,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"cuda\",\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected, using CPU (slow)\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"microsoft/Phi-4-mini-instruct\",\n",
    "        torch_dtype=torch.float32,\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 120,  # Increased to allow complete sentences\n",
    "    \"return_full_text\": False,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.3,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"use_cache\": True\n",
    "}\n",
    "\n",
    "batch_size = 16 if torch.cuda.is_available() else 2\n",
    "\n",
    "# Load your DataFrame\n",
    "# df = pd.read_csv(\"your_file.csv\")\n",
    "\n",
    "# FIXED: Proper Q&A Pair Extraction based on Year, Quarter, Question No, and presentation==0\n",
    "print(\"Extracting Q&A pairs based on Year, Quarter, Question No grouping (Q&A session only)...\")\n",
    "\n",
    "# First, clean and prepare the data\n",
    "df['Question No'] = pd.to_numeric(df['Question No'], errors='coerce')\n",
    "\n",
    "# Filter for Q&A session only (presentation==0) and valid Question No\n",
    "qa_session_data = df[(df['presentation'] == 0) & (df['Question No'].notna())]\n",
    "\n",
    "# Group by Year, Quarter, Question No to get proper Q&A pairs\n",
    "qa_pairs = []\n",
    "\n",
    "# Get unique question groups from Q&A session only\n",
    "question_groups = qa_session_data.groupby(['Year', 'Quarter', 'Question No'])\n",
    "\n",
    "for (year, quarter, q_no), group in question_groups:\n",
    "    # Sort by index to maintain order within each question group\n",
    "    group_sorted = group.sort_index()\n",
    "    \n",
    "    # Separate questions and answers\n",
    "    questions = group_sorted[group_sorted['flag_question'] == True]\n",
    "    answers = group_sorted[group_sorted['flag_question'] == False]\n",
    "    \n",
    "    # Skip if no questions or answers\n",
    "    if len(questions) == 0 or len(answers) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Combine all questions in this group\n",
    "    combined_questions = \" \".join(questions['Speaker text'].astype(str))\n",
    "    question_indices = questions.index.tolist()\n",
    "    \n",
    "    # Combine all answers in this group  \n",
    "    combined_answers = \" \".join(answers['Speaker text'].astype(str))\n",
    "    answer_indices = answers.index.tolist()\n",
    "    \n",
    "    # Create Q&A pair\n",
    "    qa_pairs.append({\n",
    "        \"questions\": combined_questions,\n",
    "        \"answer\": combined_answers,\n",
    "        \"question_indices\": question_indices,\n",
    "        \"answer_indices\": answer_indices,\n",
    "        \"year\": year,\n",
    "        \"quarter\": quarter,\n",
    "        \"question_no\": q_no\n",
    "    })\n",
    "\n",
    "print(f\"Found {len(qa_pairs)} Q&A pairs from Q&A session only (presentation==0)\")\n",
    "\n",
    "# Debug: Show some examples of the grouping\n",
    "if len(qa_pairs) > 0:\n",
    "    print(f\"\\nFiltered to Q&A session: {len(qa_session_data)} rows from {len(df)} total rows\")\n",
    "    print(\"First few Q&A pairs:\")\n",
    "    for i, pair in enumerate(qa_pairs[:3]):\n",
    "        print(f\"  Pair {i+1}: Year={pair['year']}, Quarter={pair['quarter']}, Q_No={pair['question_no']}\")\n",
    "        print(f\"    Questions: {len(pair['question_indices'])} rows, Answers: {len(pair['answer_indices'])} rows\")\n",
    "        print(f\"    Question preview: {pair['questions'][:100]}...\")\n",
    "        print(f\"    Answer preview: {pair['answer'][:100]}...\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No Q&A pairs found! Check if presentation==0 filter is correct.\")\n",
    "    print(f\"Presentation values in data: {sorted(df['presentation'].unique())}\")\n",
    "    print(f\"Rows with presentation==0: {len(df[df['presentation'] == 0])}\")\n",
    "    print(f\"Rows with valid Question No: {len(df[df['Question No'].notna()])}\")\n",
    "    print(f\"Rows with both conditions: {len(qa_session_data)}\")\n",
    "\n",
    "# FIXED: Better Prompt Design for Complete Sentences\n",
    "def create_prompt(question_text, answer_text):\n",
    "    # Truncate to reasonable lengths\n",
    "    q_truncated = question_text[:400] if len(question_text) > 400 else question_text\n",
    "    a_truncated = answer_text[:500] if len(answer_text) > 500 else answer_text\n",
    "    \n",
    "    prompt = f\"\"\"Analyze this Q&A exchange and provide exactly the following format:\n",
    "\n",
    "INSIGHT: [summarizing key insight from the answer - what was revealed, decided, or explained]. [keep short and complete sentence].\n",
    "RISK: [Yes/No/Unclear]  \n",
    "ANSWERED: [Complete/Partial/None]\n",
    "\n",
    "Question: {q_truncated}\n",
    "\n",
    "Answer: {a_truncated}\n",
    "\n",
    "Analysis:\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Build prompts\n",
    "prompts = []\n",
    "for pair in qa_pairs:\n",
    "    prompt = create_prompt(pair[\"questions\"], pair[\"answer\"])\n",
    "    prompts.append(prompt)\n",
    "\n",
    "print(f\"Created {len(prompts)} prompts for processing\")\n",
    "\n",
    "# FIXED: Better batch processing with error handling\n",
    "print(\"Processing batches...\")\n",
    "outputs_all = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(prompts), batch_size), desc=\"Processing batches\"):\n",
    "        batch = prompts[i:i + batch_size]\n",
    "        \n",
    "        try:\n",
    "            outputs = pipe(batch, **generation_args)\n",
    "            batch_outputs = []\n",
    "            \n",
    "            for out in outputs:\n",
    "                if isinstance(out, list) and len(out) > 0:\n",
    "                    batch_outputs.append(out[0]['generated_text'].strip())\n",
    "                else:\n",
    "                    batch_outputs.append(\"Processing failed\")\n",
    "                    \n",
    "            outputs_all.extend(batch_outputs)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Batch {i//batch_size} failed: {e}\")\n",
    "            # Process individually on failure\n",
    "            for prompt in batch:\n",
    "                try:\n",
    "                    output = pipe(prompt, **generation_args)\n",
    "                    if isinstance(output, list) and len(output) > 0:\n",
    "                        outputs_all.append(output[0]['generated_text'].strip())\n",
    "                    else:\n",
    "                        outputs_all.append(\"Processing failed\")\n",
    "                except Exception as e2:\n",
    "                    print(f\"Individual prompt failed: {e2}\")\n",
    "                    outputs_all.append(\"Processing failed\")\n",
    "\n",
    "        # Memory cleanup\n",
    "        if i % (batch_size * 4) == 0 and torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# FIXED: Better parsing functions\n",
    "def extract_summary(text):\n",
    "    \"\"\"Extract key insight from LLM output\"\"\"\n",
    "    # Look for INSIGHT: pattern\n",
    "    patterns = [\n",
    "        r\"INSIGHT:\\s*([^\\n]+)\",\n",
    "        r\"Insight:\\s*([^\\n]+)\", \n",
    "        r\"insight:\\s*([^\\n]+)\",\n",
    "        r\"SUMMARY:\\s*([^\\n]+)\",\n",
    "        r\"Summary:\\s*([^\\n]+)\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            insight = match.group(1).strip()\n",
    "            # Remove any trailing punctuation artifacts and clean up\n",
    "            insight = re.sub(r'\\s+', ' ', insight)  # Clean multiple spaces\n",
    "            insight = insight.rstrip('.,;:')  # Remove trailing punctuation\n",
    "            \n",
    "            # Ensure it's a reasonable length (not too long, not too short)\n",
    "            words = insight.split()\n",
    "            if len(words) > 20:  # If too long, truncate but keep complete thought\n",
    "                insight = \" \".join(words[:20])\n",
    "            elif len(words) < 3:  # If too short, try fallback\n",
    "                break\n",
    "            \n",
    "            return insight.strip()\n",
    "    \n",
    "    # Fallback: extract first meaningful line that forms a complete thought\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    for line in lines:\n",
    "        if not any(keyword in line.lower() for keyword in ['risk', 'answer', 'complete', 'partial', 'analysis']):\n",
    "            # Clean the line\n",
    "            line = re.sub(r'\\s+', ' ', line)\n",
    "            words = line.split()\n",
    "            if len(words) >= 5:  # Ensure meaningful length\n",
    "                # Take up to 20 words but try to end at sentence boundary\n",
    "                if len(words) <= 20:\n",
    "                    return line.rstrip('.,;:')\n",
    "                else:\n",
    "                    truncated = \" \".join(words[:20])\n",
    "                    # Try to end at a natural break\n",
    "                    if '.' in truncated:\n",
    "                        return truncated.split('.')[0] + '.'\n",
    "                    return truncated\n",
    "    \n",
    "    return \"No clear insight extracted\"\n",
    "\n",
    "def extract_risk(text):\n",
    "    \"\"\"Extract risk assessment from LLM output only\"\"\"\n",
    "    # Look for RISK: pattern from LLM response\n",
    "    patterns = [\n",
    "        r\"RISK:\\s*(Yes|No|Unclear)\",\n",
    "        r\"Risk:\\s*(Yes|No|Unclear)\",\n",
    "        r\"risk:\\s*(yes|no|unclear)\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).capitalize()\n",
    "    \n",
    "    # If no clear pattern found, return what the LLM likely intended\n",
    "    # Look for Yes/No in the text without keyword assumptions\n",
    "    if re.search(r'\\byes\\b', text, re.IGNORECASE):\n",
    "        return \"Yes\"\n",
    "    elif re.search(r'\\bno\\b', text, re.IGNORECASE):\n",
    "        return \"No\"\n",
    "    \n",
    "    return \"Unclear\"\n",
    "\n",
    "def extract_coverage(text):\n",
    "    \"\"\"Extract answer completeness from LLM output only\"\"\"\n",
    "    # Look for ANSWERED: pattern from LLM response\n",
    "    patterns = [\n",
    "        r\"ANSWERED:\\s*(Complete|Partial|None)\",\n",
    "        r\"Answered:\\s*(Complete|Partial|None)\",\n",
    "        r\"answered:\\s*(complete|partial|none)\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            result = match.group(1).capitalize()\n",
    "            return \"Fully answered\" if result == \"Complete\" else f\"{result}ly answered\" if result == \"Partial\" else \"Not answered\"\n",
    "    \n",
    "    # If no clear pattern found, look for the exact terms the LLM might use\n",
    "    if re.search(r'\\bcomplete\\b', text, re.IGNORECASE):\n",
    "        return \"Fully answered\"\n",
    "    elif re.search(r'\\bpartial\\b', text, re.IGNORECASE):\n",
    "        return \"Partially answered\"\n",
    "    elif re.search(r'\\bnone\\b', text, re.IGNORECASE):\n",
    "        return \"Not answered\"\n",
    "    \n",
    "    return \"Unclear\"\n",
    "\n",
    "# Initialize all columns with empty values - let LLM decide everything\n",
    "print(\"Initializing result columns...\")\n",
    "df[\"key_findings\"] = \"\"\n",
    "df[\"risk_or_distress\"] = \"\"\n",
    "df[\"answer_coverage\"] = \"\"\n",
    "\n",
    "# OPTIMIZED: Single loop for mapping and counting\n",
    "print(\"Mapping results to dataframe...\")\n",
    "risk_detected_pairs = 0\n",
    "fully_answered_pairs = 0\n",
    "valid_insight_pairs = 0\n",
    "\n",
    "for i, (pair, llm_output) in enumerate(zip(qa_pairs, outputs_all)):\n",
    "    if llm_output == \"Processing failed\":\n",
    "        continue\n",
    "        \n",
    "    # Extract insights ONCE\n",
    "    summary = extract_summary(llm_output)\n",
    "    risk = extract_risk(llm_output)\n",
    "    coverage = extract_coverage(llm_output)\n",
    "    \n",
    "    # Count pair statistics\n",
    "    if risk == \"Yes\":\n",
    "        risk_detected_pairs += 1\n",
    "    if coverage == \"Fully answered\":\n",
    "        fully_answered_pairs += 1\n",
    "    if len(summary.split()) >= 3 and summary not in [\"\", \"No clear insight extracted\", \"Processing failed\"]:\n",
    "        valid_insight_pairs += 1\n",
    "    \n",
    "    # Apply to ALL question rows in this group\n",
    "    for q_idx in pair[\"question_indices\"]:\n",
    "        if q_idx < len(df):\n",
    "            df.loc[q_idx, \"key_findings\"] = summary\n",
    "            df.loc[q_idx, \"risk_or_distress\"] = risk\n",
    "            df.loc[q_idx, \"answer_coverage\"] = coverage\n",
    "    \n",
    "    # Apply to ALL answer rows in this group\n",
    "    for a_idx in pair[\"answer_indices\"]:\n",
    "        if a_idx < len(df):\n",
    "            df.loc[a_idx, \"key_findings\"] = summary\n",
    "            df.loc[a_idx, \"risk_or_distress\"] = risk\n",
    "            df.loc[a_idx, \"answer_coverage\"] = coverage\n",
    "\n",
    "# Add validity flag\n",
    "df[\"valid_summary\"] = df[\"key_findings\"].apply(\n",
    "    lambda x: len(str(x).split()) >= 3 and \n",
    "             str(x) not in [\"\", \"No clear insight extracted\", \"Processing failed\"] and\n",
    "             not str(x).lower().startswith(('analysis', 'the ', 'this '))\n",
    ")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n=== PROCESSING SUMMARY ===\")\n",
    "print(f\"Total Q&A pairs processed: {len(qa_pairs)}\")\n",
    "successful_analyses = len([o for o in outputs_all if o != 'Processing failed'])\n",
    "print(f\"Successful analyses: {successful_analyses}\")\n",
    "print(f\"Pairs with valid insights: {valid_insight_pairs}\")\n",
    "print(f\"Risk detected in: {risk_detected_pairs} pairs\")\n",
    "print(f\"Fully answered: {fully_answered_pairs} pairs\")\n",
    "\n",
    "# Cleanup model to free memory before JSON processing\n",
    "del model, pipe\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# JSON OUTPUT CREATION (AFTER model cleanup to avoid memory issues)\n",
    "print(\"\\nCreating JSON output...\")\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def safe_convert(obj):\n",
    "    \"\"\"Convert all data types to JSON-safe types\"\"\"\n",
    "    if pd.isna(obj) or obj is None:\n",
    "        return None\n",
    "    elif isinstance(obj, (int, float, str, bool)):\n",
    "        return obj\n",
    "    elif hasattr(obj, 'item'):  # numpy types\n",
    "        return obj.item()\n",
    "    elif hasattr(obj, 'tolist'):  # numpy arrays\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return str(obj)\n",
    "\n",
    "# Create JSON structure\n",
    "json_output = {\n",
    "    \"metadata\": {\n",
    "        \"processing_date\": datetime.now().isoformat(),\n",
    "        \"model_used\": \"microsoft/Phi-4-mini-instruct\",\n",
    "        \"total_qa_pairs\": len(qa_pairs),\n",
    "        \"successful_analyses\": successful_analyses,\n",
    "        \"processing_summary\": {\n",
    "            \"pairs_with_valid_insights\": valid_insight_pairs,\n",
    "            \"risk_detected_pairs\": risk_detected_pairs,\n",
    "            \"fully_answered_pairs\": fully_answered_pairs\n",
    "        }\n",
    "    },\n",
    "    \"qa_analyses\": []\n",
    "}\n",
    "\n",
    "# Add each Q&A pair analysis\n",
    "for i, (pair, llm_output) in enumerate(zip(qa_pairs, outputs_all)):\n",
    "    qa_analysis = {\n",
    "        \"qa_pair_id\": i + 1,\n",
    "        \"grouping_info\": {\n",
    "            \"year\": safe_convert(pair[\"year\"]),\n",
    "            \"quarter\": safe_convert(pair[\"quarter\"]),\n",
    "            \"question_no\": safe_convert(pair[\"question_no\"])\n",
    "        },\n",
    "        \"question_text\": str(pair[\"questions\"]),\n",
    "        \"answer_text\": str(pair[\"answer\"]),\n",
    "        \"raw_llm_output\": str(llm_output),\n",
    "        \"extracted_results\": {\n",
    "            \"key_findings\": str(extract_summary(llm_output) if llm_output != \"Processing failed\" else \"\"),\n",
    "            \"risk_or_distress\": str(extract_risk(llm_output) if llm_output != \"Processing failed\" else \"\"),\n",
    "            \"answer_coverage\": str(extract_coverage(llm_output) if llm_output != \"Processing failed\" else \"\")\n",
    "        },\n",
    "        \"processing_status\": \"success\" if llm_output != \"Processing failed\" else \"failed\",\n",
    "        \"question_indices\": [safe_convert(idx) for idx in pair[\"question_indices\"]],\n",
    "        \"answer_indices\": [safe_convert(idx) for idx in pair[\"answer_indices\"]]\n",
    "    }\n",
    "    json_output[\"qa_analyses\"].append(qa_analysis)\n",
    "\n",
    "# Save JSON file\n",
    "json_filename = f\"qa_analysis_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "\n",
    "with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_output, f, indent=2, ensure_ascii=False, default=safe_convert)\n",
    "\n",
    "print(f\"JSON output saved to: {json_filename}\")\n",
    "\n",
    "print(\"\\nProcessing complete. Files created:\")\n",
    "print(\"1. Updated CSV with columns: key_findings, risk_or_distress, answer_coverage, valid_summary\")\n",
    "print(f\"2. JSON analysis file: {json_filename}\")\n",
    "\n",
    "# Optional: Save updated CSV\n",
    "# df.to_csv(\"improved_qa_analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d5f19254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"hsbc_final_qa_analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d077c1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d9541087",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"hsbc_final_qa_analysis_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664981ad",
   "metadata": {},
   "source": [
    "# üè¶ Deutsche Bank - Data Processing\n",
    "This section focuses on Deutsche Bank's data processing pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c47df31",
   "metadata": {},
   "source": [
    "## Downloading PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6460528",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33870,
     "status": "ok",
     "timestamp": 1749924966775,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "LwkxYXFo3TaI",
    "outputId": "872f475f-b1a0-497f-c404-24e62203ddfc"
   },
   "outputs": [],
   "source": [
    "# URL to your Drive folder\n",
    "folder_url = \"https://drive.google.com/drive/folders/1rqP0g6AFk0Uu6gprstKnxXLo6XKXnIUM\"\n",
    "\n",
    "# 1. Download all files from the folder URL\n",
    "# gdown.download_folder with just the URL downloads files to a temp dir and returns a list of file paths.\n",
    "downloaded_files = gdown.download_folder(url=folder_url, quiet=False, use_cookies=False)\n",
    "\n",
    "# 2. Move the downloaded files from their temporary location to the current working directory\n",
    "# downloaded_files is a list of paths to the downloaded files in a temporary directory.\n",
    "if downloaded_files:\n",
    "    # Assuming all files are downloaded to the same parent temporary directory\n",
    "    # We can get the parent directory from the first downloaded file path\n",
    "    temp_output_folder = os.path.dirname(downloaded_files[0]) if downloaded_files else None\n",
    "\n",
    "    if temp_output_folder and os.path.exists(temp_output_folder):\n",
    "        for filename in os.listdir(temp_output_folder):\n",
    "            src = os.path.join(temp_output_folder, filename)\n",
    "            dst = os.path.join(\".\", filename)\n",
    "            if os.path.isfile(src):\n",
    "                shutil.move(src, dst)\n",
    "        # Clean up the temporary directory after moving files\n",
    "        try:\n",
    "            os.rmdir(temp_output_folder)\n",
    "            print(f\"Removed temporary directory: {temp_output_folder}\")\n",
    "        except OSError as e:\n",
    "            print(f\"Could not remove temporary directory {temp_output_folder}: {e}\")\n",
    "    elif not downloaded_files:\n",
    "        print(\"No files were downloaded from the folder.\")\n",
    "    else:\n",
    "        print(f\"Temporary download directory not found: {temp_output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50fc83b",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1749924979991,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "4PB-suGoHT_O"
   },
   "outputs": [],
   "source": [
    "# Constant config\n",
    "bank_name = \"Deutsche Bank\"\n",
    "output_excel_presentations = \"presentation_slides_with_titles.xlsx\"\n",
    "output_excel_qa = \"qa_speaker_blocks_final.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7e4b6a",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749924981239,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "SMNDI18Y5lQ-"
   },
   "outputs": [],
   "source": [
    "deutsche_bank_speakers = {\"Christian Sewing\", \"Ioana Patriniche\", \"James von Moltke\", \"Silke-Nicole Szypa\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d24ed9e",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1749924982860,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "_qr7mIbBHEx6"
   },
   "outputs": [],
   "source": [
    "# Step 1: Extract text from PDF, skipping first page\n",
    "def extract_text(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            page_text = page.extract_text(layout=True)\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b919068",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1749924984674,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "voQuUdUsHEvk"
   },
   "outputs": [],
   "source": [
    "# Step 2: Cut before Q&A\n",
    "def extract_presentation_section(text):\n",
    "    split = re.split(r\"Questions? & Answers?\", text, flags=re.IGNORECASE)\n",
    "    return split[0].strip() if split else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d7f40",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1749924985857,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "BbnG1i-uHEs5"
   },
   "outputs": [],
   "source": [
    "# Step 3: Parse slides with titles and create data frame for presentation\n",
    "def extract_slides_with_titles(text):\n",
    "    slide_pattern = re.compile(r\"(Slide\\s\\d+\\s[‚Äì-]\\s.+)\")\n",
    "    slides = []\n",
    "    parts = slide_pattern.split(text)\n",
    "    for i in range(1, len(parts), 2):\n",
    "        title = parts[i].strip()\n",
    "        body = parts[i + 1].strip() if i + 1 < len(parts) else \"\"\n",
    "\n",
    "        # Remove empty lines and page numbers\n",
    "        lines = body.splitlines()\n",
    "        cleaned = [line.strip() for line in lines if line.strip() and not re.match(r\"^\\d{1,3}$\", line.strip())]\n",
    "\n",
    "        # Combine to single string for bullet logic\n",
    "        combined = \" \".join(cleaned)\n",
    "\n",
    "        # Insert line breaks before each bullet-style phrase: \"- Capital...\"\n",
    "        # But ensure we keep the very first `-` if it's already there\n",
    "        combined = re.sub(r\"\\s*-\\s+(?=[A-Z])\", r\"\\n- \", combined)\n",
    "\n",
    "        # Remove accidental double bullets\n",
    "        combined = re.sub(r\"^- -\", r\"-\", combined, flags=re.MULTILINE)\n",
    "\n",
    "        slides.append((title, combined.strip()))\n",
    "\n",
    "    return slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baefb916",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1749927493151,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "5GjdCet_HEoL"
   },
   "outputs": [],
   "source": [
    "# Step 4: Build DataFrame\n",
    "def build_slide_df(slides, year, quarter, filename):\n",
    "    return pd.DataFrame([{\n",
    "        \"File\": filename,\n",
    "        \"Bank Name\": bank_name,\n",
    "        \"Year\": year,\n",
    "        \"Quarter\": quarter,\n",
    "        \"Slide_title\": title,\n",
    "        \"Text\": text\n",
    "    } for title, text in slides])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca6c595",
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1749927494849,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "QAb3nBKlHElW"
   },
   "outputs": [],
   "source": [
    "# Step 5: Extract Year/Quarter from filename\n",
    "def extract_year_quarter(filename):\n",
    "    match = re.search(r\"(Q[1-4])[-_](\\d{4})\", filename)\n",
    "    if match:\n",
    "        quarter_str, year = match.group(1), int(match.group(2))\n",
    "        quarter = int(quarter_str[1])  # Convert 'Q1' ‚Üí 1\n",
    "        return year, quarter\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d0c717",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1749927496117,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "7RQvCdekI-_g"
   },
   "outputs": [],
   "source": [
    "# Step 6: Isolate Q&A section\n",
    "def extract_qa_section(text):\n",
    "    match = re.search(r\"(Questions? & Answers?.*)\", text, re.IGNORECASE | re.DOTALL)\n",
    "    return match.group(1) if match else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b96a28",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1749924992208,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "AfiCdusGI-1x"
   },
   "outputs": [],
   "source": [
    "# Step 7: Create the Q&A part\n",
    "# 7.1. Parse speaker blocks (speaker name + speaker text)\n",
    "def parse_speaker_blocks(text):\n",
    "    lines = text.splitlines()\n",
    "    speaker_blocks = []\n",
    "    current_speaker = None\n",
    "    current_text = \"\"\n",
    "\n",
    "    speaker_line_pattern = re.compile(r\"^\\s{2,}([A-Z][a-z]+(?: [A-Z][a-z]+)+)\\s{2,}(.+)?$\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.rstrip()\n",
    "        if not line.strip():\n",
    "            continue\n",
    "\n",
    "        match = speaker_line_pattern.match(line)\n",
    "        if match:\n",
    "            if current_speaker and current_text:\n",
    "                speaker_blocks.append((current_speaker.strip(), current_text.strip()))\n",
    "                current_text = \"\"\n",
    "            current_speaker = match.group(1)\n",
    "            first_line = match.group(2) or \"\"\n",
    "            current_text = first_line.strip()\n",
    "        else:\n",
    "            current_text += \" \" + line.strip()\n",
    "\n",
    "    if current_speaker and current_text:\n",
    "        speaker_blocks.append((current_speaker.strip(), current_text.strip()))\n",
    "\n",
    "    return speaker_blocks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0274e851",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1749927499116,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "3ccXtaekziWu"
   },
   "outputs": [],
   "source": [
    "############################################\n",
    "import re\n",
    "\n",
    "def parse_speaker_blocks(text):\n",
    "    lines = text.splitlines()\n",
    "    speaker_blocks = []\n",
    "    current_speaker = None\n",
    "    current_text = []\n",
    "\n",
    "    # This pattern matches lines like \"Chris Hallam (Goldman Sachs)\"\n",
    "    speaker_line_pattern = re.compile(r\"^([A-Z][a-z]+(?: [A-Z][a-z]+)+(?: \\([^)]+\\))?)\\s+(.*)?$\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        match = speaker_line_pattern.match(line)\n",
    "        if match:\n",
    "            # Save the current speaker block before starting a new one\n",
    "            if current_speaker and current_text:\n",
    "                speaker_blocks.append((current_speaker, \" \".join(current_text).strip()))\n",
    "            current_speaker = match.group(1)\n",
    "            first_line = match.group(2) or \"\"\n",
    "            current_text = [first_line.strip()]\n",
    "        else:\n",
    "            if current_text is not None:\n",
    "                current_text.append(line)\n",
    "\n",
    "    # Append the last speaker block\n",
    "    if current_speaker and current_text:\n",
    "        speaker_blocks.append((current_speaker, \" \".join(current_text).strip()))\n",
    "\n",
    "    return speaker_blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb3e76",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1749928040180,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "1uCKBWOR1p0M"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_speaker_blocks(text):\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r\"\\n+\", \"\\n\", text)\n",
    "\n",
    "    # Define a regex to match speaker labels (e.g., \"Christian Sewing\", \"James von Moltke\")\n",
    "    speaker_pattern = re.compile(r\"\\b([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)+)\\b\\s*:\")\n",
    "\n",
    "    # Split text on speaker labels\n",
    "    speaker_blocks = []\n",
    "    current_speaker = None\n",
    "    current_text = []\n",
    "\n",
    "    for line in text.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        match = speaker_pattern.match(line)\n",
    "        if match:\n",
    "            # Store previous block\n",
    "            if current_speaker and current_text:\n",
    "                speaker_blocks.append((current_speaker, \" \".join(current_text)))\n",
    "            current_speaker = match.group(1)\n",
    "            current_text = [line[len(match.group(0)):].strip()]\n",
    "        else:\n",
    "            if current_speaker:\n",
    "                current_text.append(line)\n",
    "\n",
    "    # Append last speaker block\n",
    "    if current_speaker and current_text:\n",
    "        speaker_blocks.append((current_speaker, \" \".join(current_text)))\n",
    "\n",
    "    return speaker_blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3939e9",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1749928043198,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "cK1Yk2LbJJMY"
   },
   "outputs": [],
   "source": [
    "# 7.2 First pass: collect institution map from known mentions\n",
    "def build_institution_map(blocks):\n",
    "    institution_map = {}\n",
    "    for speaker, text in blocks:\n",
    "        match = re.search(r\"\\(([^)]+)\\)\", text)\n",
    "        if match:\n",
    "            institution_map[speaker] = match.group(1)\n",
    "    return institution_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce03239",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1749928044592,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "imYetbQDJJJR"
   },
   "outputs": [],
   "source": [
    "def build_speaker_df(blocks, institution_map, year, quarter, filename):\n",
    "    rows = []\n",
    "    question_counter = 1\n",
    "\n",
    "    for speaker, text in blocks:\n",
    "        match = re.search(r\"\\(([^)]+)\\)\", text)\n",
    "        if match:\n",
    "            institution = match.group(1)\n",
    "            text_clean = re.sub(r\"\\([^)]+\\)\", \"\", text).strip()\n",
    "            institution_map[speaker] = institution\n",
    "        else:\n",
    "            institution = institution_map.get(speaker)\n",
    "            if not institution and speaker in deutsche_bank_speakers:\n",
    "                institution = \"Deutsche Bank\"\n",
    "            text_clean = text.strip()\n",
    "\n",
    "        has_question = \"?\" in text_clean\n",
    "        question_number = question_counter if has_question else None\n",
    "        if has_question:\n",
    "            question_counter += 1\n",
    "\n",
    "        rows.append({\n",
    "            \"File\": filename,\n",
    "            \"Bank Name\": bank_name,\n",
    "            \"Year\": year,\n",
    "            \"Quarter\": quarter,\n",
    "            \"Speaker name\": speaker,\n",
    "            \"Institution\": institution,\n",
    "            \"Question Number\": question_number,\n",
    "            \"Text\": text_clean,\n",
    "            \"flag_question\": int(has_question)\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"Question Number\"] = df[\"Question Number\"].ffill().astype(\"Int64\")  # fill down\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d90eb4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32262,
     "status": "ok",
     "timestamp": 1749928083598,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "P--Zz1tPJyjH",
    "outputId": "34347d58-0c51-4233-f278-e8b950419c53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Q4-2024-Analyst-Call-Transcript.pdf (4 2024)\n",
      "Failed to process Q4-2024-Analyst-Call-Transcript.pdf: 'Question Number'\n",
      "Processing Q4-2023-Analyst-Call-Transcript.pdf (4 2023)\n",
      "Failed to process Q4-2023-Analyst-Call-Transcript.pdf: 'Question Number'\n",
      "Processing Q3-2024-Analyst-Call-Transcript.pdf (3 2024)\n",
      "Failed to process Q3-2024-Analyst-Call-Transcript.pdf: 'Question Number'\n",
      "Processing Q3-2023-Analyst-Call-Transcript.pdf (3 2023)\n",
      "Failed to process Q3-2023-Analyst-Call-Transcript.pdf: 'Question Number'\n",
      "Processing Q2-2024-Analyst-Call-Transcript.pdf (2 2024)\n",
      "Failed to process Q2-2024-Analyst-Call-Transcript.pdf: 'Question Number'\n",
      "Processing Q2-2023-Analyst-Call-Transcript.pdf (2 2023)\n",
      "Failed to process Q2-2023-Analyst-Call-Transcript.pdf: 'Question Number'\n",
      "Processing Q1-2025-Analyst-Call-Transcript.pdf (1 2025)\n",
      "Failed to process Q1-2025-Analyst-Call-Transcript.pdf: 'Question Number'\n",
      "Processing Q1-2024-Analyst-Call-Transcript.pdf (1 2024)\n",
      "Failed to process Q1-2024-Analyst-Call-Transcript.pdf: 'Question Number'\n",
      "Processing Q1-2023-Analyst-Call-Transcript.pdf (1 2023)\n",
      "Failed to process Q1-2023-Analyst-Call-Transcript.pdf: 'Question Number'\n",
      "\n",
      " Saved to presentation_slides_with_titles.xlsx with 166 slides.\n",
      " No QA extracted.\n"
     ]
    }
   ],
   "source": [
    "# === MAIN LOOP ===\n",
    "all_files = glob(\"Q*-Analyst-Call-Transcript*.pdf\")\n",
    "all_present_dfs = []\n",
    "\n",
    "all_qa_dfs = []\n",
    "\n",
    "for pdf_path in sorted(all_files, reverse=True):  # optional: newest first\n",
    "    year, quarter = extract_year_quarter(pdf_path)\n",
    "    if not year:\n",
    "        print(f\"Skipping {pdf_path} ‚Äî quarter/year not found.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {pdf_path} ({quarter} {year})\")\n",
    "    try:\n",
    "        text = extract_text(pdf_path)\n",
    "        presentation_text = extract_presentation_section(text)\n",
    "        slides = extract_slides_with_titles(presentation_text)\n",
    "        df = build_slide_df(slides, year, quarter, os.path.basename(pdf_path))\n",
    "        all_present_dfs.append(df)\n",
    "\n",
    "        qa_text = extract_qa_section(text)\n",
    "        speaker_blocks = parse_speaker_blocks(qa_text)\n",
    "        institution_map = build_institution_map(speaker_blocks)\n",
    "        df_qa = build_speaker_df(speaker_blocks, institution_map, year, quarter, os.path.basename(pdf_path))\n",
    "        all_qa_dfs.append(df_qa)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {pdf_path}: {e}\")\n",
    "\n",
    "# Combine and export\n",
    "if all_present_dfs:\n",
    "    final_df = pd.concat(all_present_dfs, ignore_index=True)\n",
    "    final_df.to_excel(output_excel_presentations, index=False)\n",
    "    json_output_presentations = output_excel_presentations.replace(\".xlsx\", \".json\")\n",
    "    final_df.to_json(json_output_presentations, orient=\"records\", indent=2, force_ascii=False)\n",
    "\n",
    "    print(f\"\\n Saved to {output_excel_presentations} with {len(final_df)} slides.\")\n",
    "else:\n",
    "    print(\" No slides extracted.\")\n",
    "\n",
    "if all_qa_dfs:\n",
    "    final_df_qa = pd.concat(all_qa_dfs, ignore_index=True)\n",
    "    final_df_qa.to_excel(output_excel_qa, index=False)\n",
    "    print(f\"\\n Saved to {output_excel_qa} with {len(final_df_qa)} slides.\")\n",
    "    json_output_qa = output_excel_qa.replace(\".xlsx\", \".json\")\n",
    "    final_df_qa.to_json(json_output_qa, orient=\"records\", indent=2, force_ascii=False)\n",
    "else:\n",
    "    print(\" No QA extracted.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278262d3",
   "metadata": {
    "id": "wvtNqPLPM2nN"
   },
   "source": [
    "## FINBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207390bd",
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1749927571823,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "R4i2-GRQ3yxC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd2318b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2153,
     "status": "ok",
     "timestamp": 1749927576004,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "J4foX65U3724",
    "outputId": "6756b06a-724a-4e94-e70d-0f7ca300d6b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load FinBERT for sentiment analysis\n",
    "model_name = \"yiyanghkust/finbert-tone\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217ef350",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2090,
     "status": "ok",
     "timestamp": 1749925145840,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "y9pR29Ev4L1n",
    "outputId": "e3536612-9690-400d-9929-36901562864a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy for topic extraction\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4148c7ce",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1749925159603,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "tiJjW20A4vOB"
   },
   "outputs": [],
   "source": [
    "# Helper: Extract top noun chunks or named entities\n",
    "def extract_topics(text):\n",
    "    doc = nlp(text)\n",
    "    topics = set()\n",
    "\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if len(chunk.text) > 3:\n",
    "            topics.add(chunk.text.strip())\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in {\"ORG\", \"MONEY\", \"GPE\", \"PRODUCT\", \"EVENT\"}:\n",
    "            topics.add(ent.text.strip())\n",
    "\n",
    "    return \", \".join(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f853c01",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1749925162088,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "FgNKfdi57kPH"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "removal_phrases = [\"Q&A\", \"thank you\", \"thanks\", \"good morning\", \"hello\",\n",
    "        \"hi\", \"good afternoon\", \"good evening\",\"i appreciate it\",\n",
    "        \"thank you very much\", \"thank you for taking my question\",\n",
    "        \"cheers\",\"many thanks\",\"which\", \"sorry\"]\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"\\n\", \" \").strip()\n",
    "\n",
    "    # Remove predefined phrases (case-insensitive)\n",
    "    for phrase in removal_phrases:\n",
    "        text = re.sub(rf\"\\b{re.escape(phrase)}\\b[,.\\s]*\", \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove phrases like \"Thank you,\" \"Thanks,\" \"Good morning,\" at the start\n",
    "    text = re.sub(r\"^(thank you|thanks|good morning|hello|hi)[,.\\s]*\", \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove question-related filler phrases\n",
    "    text = re.sub(r\"\\b(the question|first question|second question|two questions|a quick question|just one question)\\b[,.\\s]*\", \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove name after greeting (e.g., \"James von Moltke,\")\n",
    "    text = re.sub(r\"^[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*[,.\\s]+\", \"\", text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94efa54f",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1749925170123,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "CdFEZRuDT4wC"
   },
   "outputs": [],
   "source": [
    "def add_sentiment_and_topic(df):\n",
    "    sentiments = []\n",
    "    topics = []\n",
    "    scores = []\n",
    "\n",
    "    for text in df[\"Text\"]:\n",
    "        cleaned = clean_text(text)\n",
    "        if len(cleaned.split()) < 10:\n",
    "            sentiments.append(None)\n",
    "            topics.append(None)\n",
    "            scores.append(None)\n",
    "        else:\n",
    "            result = sentiment_pipeline(cleaned[:512])[0]\n",
    "            sentiments.append(result[\"label\"].lower())\n",
    "            topics.append(extract_topics(cleaned))\n",
    "            scores.append(round(result[\"score\"], 4))\n",
    "\n",
    "    # Add to DataFrame\n",
    "    df[\"Sentiment\"] = sentiments\n",
    "    df[\"Score\"] = scores\n",
    "    df[\"Topics\"] = topics\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914668b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 788
    },
    "executionInfo": {
     "elapsed": 55572,
     "status": "ok",
     "timestamp": 1749925228851,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "LgeD5kY2UcCl",
    "outputId": "fae96750-7197-459c-8482-6a968c553d11"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"final_df_qa\",\n  \"rows\": 234,\n  \"fields\": [\n    {\n      \"column\": \"File\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Q4-2023-Analyst-Call-Transcript.pdf\",\n          \"Q2-2023-Analyst-Call-Transcript.pdf\",\n          \"Q4-2024-Analyst-Call-Transcript.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bank Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Deutsche Bank\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2023,\n        \"max\": 2025,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quarter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Speaker name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"Matthew Clark\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Institution\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"Autonomous\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question Number\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 219,\n        \"samples\": [\n          \"Yes. Hi, Christian, James, Thanks for taking my         questions. First question is regarding the comment around FIC slowdown. Can you just put that in context? In April, you mentioned that, I think, on Bloomberg and Christian, you just mentioned that as well. Could you just put it in context of what timeframe you're comparing? And secondly, in that context, just tell me what subsegments of FIC are weaker than credit. Is it 18 rates? Maybe even by geography, if possible, just so we get an idea. And if this is just an immediate reaction of what happened in the markets, post tariffs, or is this an ongoing issue that we should think about in our modelling. And then the second question is regarding your outlook, GDP, US assumption 1.7, China, four and a half. Just wondering if these numbers, what would happen if they would be significantly lower? Because they look a bit on the higher end of what market consensus expectation or forward curves are assuming. If you could discuss that relative to your 10% RoTE plus target and issues around that, if we should think about if it could have a negative impact, so to say. James von Moltke   Sure. Thanks. And I'll start on the guidance that we'd given or commentary about the market. Look, I think one important thing is to say is that the second half of April, and it isn't precisely in halves, but I think the easiest way to think about it is second half of April, resumed a pattern that looked very much like what you see in the disclosure on daily trading results in the FIC business for much of the first quarter. So, to your question about ongoing, it isn't a concern for us at the moment at all. In fact, I think we're well positioned to recapture the foregone revenues from the first half of April as in the balance of the quarter. In fairness, we're actually up year on year still in April. So we look at this with a relaxed view. Naturally, in markets that are as turbulent as the ones we experienced in the first couple of weeks of April, you're going to see some correlations breakdown, some impact on the books. But we were reasonably happy. So there was, of course, a slowdown a few weak days, but we were happy with how the desks performed in that environment. The way we were able to stand in, to provide liquidity for clients, pricing, what have you. In terms of the products, it was a little varied around the world. But to your point, credit struggled more, and there were elements in the Rates and FX complexes 19 where, again, correlations moving created some disturbance. What's interesting is how quickly and almost fully the markets have recovered over the course of April. Again, going to your question about, is it an ongoing concern? As we sit here today, really, it's not. And actually, I've been positively impressed by the way in which investors have continued to be engaged in the environment that we have, which is reasonably fast moving. In terms of the outlook, lots of our assumptions are driven by macroeconomic variables. And I'll focus on revenues and expenses. And naturally, we look at downside scenarios. And that was the principal driver, of course, of the overlay that we took in provisions in Q1. We think that overlay was prudent and appropriate and actually reflects how the macroeconomic consensus has moved since the end of March. So we feel quite comfortable with how, if you like, first quarter reporting reflects our outlook, as well as the consensus environment today. The other thing, just more broadly to the question you asked and really Christian\\u2019s response to Chris's question. We see a lot of what I'll call portfolio effects in our businesses. So businesses that are maybe negatively affected by certain elements of the macro environment will be offset by others that are benefited. And so it isn't at all linear. And we feel like the balance of risks and opportunities that we see in the market really underscores our outlook, as Christian just mentioned. And hence, we're feeling pretty good about the overall macro environment, even as it's changed since the beginning of the year when we last spoke.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flag_question\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12216254995858825,\n        \"min\": 0.4816,\n        \"max\": 1.0,\n        \"num_unique_values\": 115,\n        \"samples\": [\n          0.5549\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 174,\n        \"samples\": [\n          \"that book, provisions, the stage, James von Moltke   Stock, the 1.6 billion euro, total, probably 50 million euro, the stock\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "final_df_qa"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-d5020318-488f-4ea9-935a-5b359c830757\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Bank Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Speaker name</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Question Number</th>\n",
       "      <th>Text</th>\n",
       "      <th>flag_question</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "      <th>Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Nicolas Payen</td>\n",
       "      <td>Kepler Cheuvreux</td>\n",
       "      <td>1</td>\n",
       "      <td>Good morning. I have two questions, please. Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>the year, a share buyback annual growth, ‚Ç¨ 750...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Christian Sewing</td>\n",
       "      <td>EU</td>\n",
       "      <td>2</td>\n",
       "      <td>Thank you, Nicolas, it's Christian. Let me let...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>US, a chance, those years, the discussions, ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Anke Reingen</td>\n",
       "      <td>RBC</td>\n",
       "      <td>3</td>\n",
       "      <td>Thank you very much for taking my question. I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>FX, technology, the divisional level, a great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Christian Sewing</td>\n",
       "      <td>EU</td>\n",
       "      <td>3</td>\n",
       "      <td>Anke, I 100% support what James is saying. Jus...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9887</td>\n",
       "      <td>our prepared remarks, that, Rebecca, the outco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Kian Abouhoussein</td>\n",
       "      <td>JP Morgan</td>\n",
       "      <td>4</td>\n",
       "      <td>Thanks for taking my questions. I just wanted ...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>the expense side, the opportunity, FX, risk-we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Q1-2023-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrew Lim</td>\n",
       "      <td>Societe Generale</td>\n",
       "      <td>17</td>\n",
       "      <td>Hi. Thanks for taking my question. I just have...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>Group NII, the coming quarters, a 40 to 60 bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Q1-2023-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrew Lim</td>\n",
       "      <td>Societe Generale</td>\n",
       "      <td>17</td>\n",
       "      <td>It's the total Group deposit base, but I can c...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>that, the total Group deposit base, that ratio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Q1-2023-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrew Lim</td>\n",
       "      <td>Societe Generale</td>\n",
       "      <td>17</td>\n",
       "      <td>Great, thanks. James von Moltke   Thanks, Andrew.</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Q1-2023-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrew Lim</td>\n",
       "      <td>Societe Generale</td>\n",
       "      <td>17</td>\n",
       "      <td>Sorry, lastly, on the impacts due to internal ...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>LGDs, the Investment Bank, either the Investme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Q1-2023-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrew Lim</td>\n",
       "      <td>EU</td>\n",
       "      <td>17</td>\n",
       "      <td>That‚Äôs great, thank you very much. James von M...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9884</td>\n",
       "      <td>Article, the U.S. Securities and Exchange Comm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows √ó 12 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5020318-488f-4ea9-935a-5b359c830757')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d5020318-488f-4ea9-935a-5b359c830757 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d5020318-488f-4ea9-935a-5b359c830757');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-ad52c072-e3c5-4ca4-9f09-4c566a05db74\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad52c072-e3c5-4ca4-9f09-4c566a05db74')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-ad52c072-e3c5-4ca4-9f09-4c566a05db74 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_f9c7e18a-2970-4297-95ee-90a323f870a5\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('final_df_qa')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_f9c7e18a-2970-4297-95ee-90a323f870a5 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('final_df_qa');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                    File      Bank Name  Year  Quarter  \\\n",
       "0    Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "1    Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "2    Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "3    Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "4    Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "..                                   ...            ...   ...      ...   \n",
       "229  Q1-2023-Analyst-Call-Transcript.pdf  Deutsche Bank  2023        1   \n",
       "230  Q1-2023-Analyst-Call-Transcript.pdf  Deutsche Bank  2023        1   \n",
       "231  Q1-2023-Analyst-Call-Transcript.pdf  Deutsche Bank  2023        1   \n",
       "232  Q1-2023-Analyst-Call-Transcript.pdf  Deutsche Bank  2023        1   \n",
       "233  Q1-2023-Analyst-Call-Transcript.pdf  Deutsche Bank  2023        1   \n",
       "\n",
       "          Speaker name       Institution  Question Number  \\\n",
       "0        Nicolas Payen  Kepler Cheuvreux                1   \n",
       "1     Christian Sewing                EU                2   \n",
       "2         Anke Reingen               RBC                3   \n",
       "3     Christian Sewing                EU                3   \n",
       "4    Kian Abouhoussein         JP Morgan                4   \n",
       "..                 ...               ...              ...   \n",
       "229         Andrew Lim  Societe Generale               17   \n",
       "230         Andrew Lim  Societe Generale               17   \n",
       "231         Andrew Lim  Societe Generale               17   \n",
       "232         Andrew Lim  Societe Generale               17   \n",
       "233         Andrew Lim                EU               17   \n",
       "\n",
       "                                                  Text  flag_question  \\\n",
       "0    Good morning. I have two questions, please. Th...              1   \n",
       "1    Thank you, Nicolas, it's Christian. Let me let...              1   \n",
       "2    Thank you very much for taking my question. I ...              1   \n",
       "3    Anke, I 100% support what James is saying. Jus...              0   \n",
       "4    Thanks for taking my questions. I just wanted ...              1   \n",
       "..                                                 ...            ...   \n",
       "229  Hi. Thanks for taking my question. I just have...              1   \n",
       "230  It's the total Group deposit base, but I can c...              0   \n",
       "231  Great, thanks. James von Moltke   Thanks, Andrew.              0   \n",
       "232  Sorry, lastly, on the impacts due to internal ...              0   \n",
       "233  That‚Äôs great, thank you very much. James von M...              0   \n",
       "\n",
       "    Sentiment   Score                                             Topics  \n",
       "0     neutral  0.9994  the year, a share buyback annual growth, ‚Ç¨ 750...  \n",
       "1    positive  1.0000  US, a chance, those years, the discussions, ou...  \n",
       "2     neutral  0.9983  FX, technology, the divisional level, a great ...  \n",
       "3     neutral  0.9887  our prepared remarks, that, Rebecca, the outco...  \n",
       "4     neutral  0.9986  the expense side, the opportunity, FX, risk-we...  \n",
       "..        ...     ...                                                ...  \n",
       "229   neutral  0.9945  Group NII, the coming quarters, a 40 to 60 bas...  \n",
       "230   neutral  1.0000  that, the total Group deposit base, that ratio...  \n",
       "231      None     NaN                                               None  \n",
       "232   neutral  0.9950  LGDs, the Investment Bank, either the Investme...  \n",
       "233   neutral  0.9884  Article, the U.S. Securities and Exchange Comm...  \n",
       "\n",
       "[234 rows x 12 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_sentiment_and_topic(final_df_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d3287",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "executionInfo": {
     "elapsed": 46673,
     "status": "ok",
     "timestamp": 1749925668759,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "0W29uFmiVags",
    "outputId": "438bfb51-e109-48cc-8213-81cbcf1f474f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"final_df\",\n  \"rows\": 166,\n  \"fields\": [\n    {\n      \"column\": \"File\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Q1-2024-Analyst-Call-Transcript.pdf\",\n          \"Q4-2023-Analyst-Call-Transcript.pdf\",\n          \"Q2-2023-Analyst-Call-Transcript.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bank Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Deutsche Bank\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2023,\n        \"max\": 2025,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quarter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Slide_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 131,\n        \"samples\": [\n          \"Slide 1 \\u2013 Business momentum reflecting strategy execution\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 166,\n        \"samples\": [\n          \"- We  aim to accelerate delivery on three dimensions: operational efficiency, capital efficiency, and revenue growth, where we aim to outperform our original targets. We have already made progress in all of these\\n- Turning first to operational efficiencies:\\n- We raised our ambition for incremental efficiencies from 2 billion euros to 2.5 billion euros, as we said\\n- We have already delivered more than 600 million euros, through a range of measures such as branch closures in the Private Bank, standardizing loan processing in the Corporate Bank and Investment Bank and simplifying our technology infrastructure\\n- We anticipate 300 million euros of savings by 2025 from the successfully completed migration of 12 million Postbank clients onto the Deutsche Bank technology platform\\n- And we  expect more than 100 million euros from the announced redundancies in senior non-client facing roles as more than 80% of affected staff have either been informed or left the platform\\n- In other words, a total of around 1 billion euros in savings are either already achieved, or are expected from measures now implemented\\n- We have a series of other measures in flight- for example, streamlining our mortgage business and further branch closures in the Private Bank; re-engineering more front-to-back processes in the Corporate Bank and Investment Bank; further application de-commissioning; and additional workforce measures\\n- These are some examples of a wider programme of initiatives underway. Based on our progress on these, and realized achievements so far, we reaffirm our 2.5-billion-euro goal\\n- In respect of capital efficiencies: as you know, our aim is to reduce risk weighted assets by 15-20 billion euros by 2025 relative to our baseline assumptions with a modest revenue impact\\n- In the second quarter we accelerated securitisation transactions which delivered RWA relief of around 3 billion euros\\n- In addition, credit risk RWAs were reduced as part of the Trade Finance and Lending optimization efforts\\n- Overall, we proved our revenue strength with the business delivering revenue growth while our FX adjusted RWAs decreased by 5 billion euros compared to the prior year quarter\\n- We have further optimization measures in preparation for the second half of 2023 including securitisation of consumer finance loans and reductions in sub-hurdle lending\\n- All this gives us confidence that we will deliver on our capital optimisation goals\\n- Turning finally to revenue growth: we are fully on track to outperform on our revenue growth targets, of 3.5 to 4.5% compound annual growth against 2021 levels\\n- On a last-twelve-month basis, we delivered compound annual revenue growth versus 2021 of 7.5%, well ahead of that target, with revenue growth of 8% in the first half of this year\\n- We expect the interest rate environment to continue to drive sustainable performance in our stable businesses\\n- We  anticipate added momentum from our organic and inorganic investments, including the Numis acquisition or the new partnership with Lufthansa and Miles & More, and from hiring of some 50 senior O&A bankers. This enables us to take advantage of an expected pickup in corporate finance activity \\u2013 we are already seeing signs of this in our backlog. We have also hired around 30 wealth managers\\n- And we expect the growth in our assets under management, and net asset inflows, to drive fee income in future quarters\\n- To sum up:\\n- We are delivering revenue and business growth off a strong franchise; our well-balanced, complementary business mix enables us to drive continued revenue momentum; we are increasing our earnings power year by year, and we see a clear path to achieving our 2025 profitability targets, amongst others an RoTE of larger than 10% in 2025\\n- And we are delivering on two key promises: distributing 8 billion euros to shareholders, and accelerating execution of our Global Hausbank strategy\\n- With that: let me hand over to James JAMES VON MOLTKE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10176992838493962,\n        \"min\": 0.5019,\n        \"max\": 1.0,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          0.9963\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 166,\n        \"samples\": [\n          \"our ambition, a total, the Corporate Bank and Investment Bank, a series, more than 600 million euros, These, track, FX, advantage, consumer finance loans, others, quarter, our original targets, added momentum, loan processing, Numis, management, 3.5 to 4.5% compound annual growth, confidence, compound annual revenue growth, our assets, measures, our well-balanced, complementary business mix, capital efficiency, our Global Hausbank strategy, the Trade Finance, 7.5%, an RoTE, risk, sustainable performance, other measures, a range, securitisation, back, 8 billion euros, flight-, sub-hurdle lending, our capital optimisation goals, fee income, around 3 billion euros, net asset inflows, revenue and business growth, the growth, our aim, our revenue strength, larger than 10%, that target, the first half, our mortgage business, Lufthansa, further branch closures, a modest revenue impact, three dimensions, savings, 2 billion euros, the Deutsche Bank technology platform, our baseline assumptions, the business, around 1 billion, RoTE, Investment Bank, the announced redundancies, execution, example, our progress, 2.5 billion euros, our earnings power year, RWA relief, corporate finance activity, more than 80%, delivery, some 50 senior O&A bankers, a strong franchise, 2021 levels, operational efficiency, our 2025 profitability targets, initiatives, James JAMES VON, our technology infrastructure, two key promises, year, a last-twelve-month basis, This, more than 100 million euros, further application, incremental efficiencies, reductions, 12 million Postbank clients, capital efficiencies, our organic and inorganic investments, affected staff, the prior year, revenue growth, Miles, this year, the Private Bank, respect, relative, around 30 wealth managers, 5 billion euros, the interest rate environment, achievements, further optimization measures, future quarters, some examples, our backlog, our revenue growth targets, our stable businesses, a clear path, the successfully completed migration, preparation, these, progress, addition, Deutsche Bank, around 1 billion euros, our FX adjusted RWAs, operational efficiencies, credit risk RWAs, the Numis acquisition, the new partnership, other words, signs, the Trade Finance and Lending optimization efforts, assets, part, the second quarter, that, 2.5-billion-euro, the Corporate Bank, a wider programme, an expected pickup, All this, senior non-client facing roles, continued revenue momentum, this, Miles & More, our 2.5-billion-euro goal, O&A, 15-20 billion, 15-20 billion euros, the second half, shareholders, 300 million euros, around 3 billion euros -, the platform, securitisation transactions, branch closures\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "final_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-fdea00f9-3bbb-4086-8425-4d282c8bccce\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Bank Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Slide_title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "      <th>Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Slide 2 ‚Äì Actions taken in 2024 position Deuts...</td>\n",
       "      <td>target in 2025 and beyond\\n- Thank you Ioana, ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>2 billion euros year, capital returns, a total...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Slide 3 ‚Äì Resilient full-year results reflecti...</td>\n",
       "      <td>performance\\n- We increased 2024 pre-provision...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>our efficiency program, FX, the Postbank takeo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Slide 4 ‚Äì Clear traction across divisions set ...</td>\n",
       "      <td>higher profitability\\n- At our investor day in...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>March, the commercial focus, substantially bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Slide 5 ‚Äì Strong execution and positioning und...</td>\n",
       "      <td>trajectory\\n- Since 2021, we have delivered a ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>US, these trends, FX, this substantial growth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Slide 6 ‚Äì Significantly lower expenses in 2025...</td>\n",
       "      <td>execution of efficiency measures\\n- In 2025, o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>our initially-planned mandatory and strategic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Q1-2023-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Slide 20 ‚Äì Investment Bank</td>\n",
       "      <td>- Revenues for the first quarter were 19% lowe...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>improvements, A slight increase, March - Rates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Q1-2023-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Slide 21 ‚Äì Private Bank</td>\n",
       "      <td>- Private Bank revenues were 2.4 billion euros...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Wealth Management, inflation impacts, the sale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Q1-2023-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Slide 22 ‚Äì Asset Management</td>\n",
       "      <td>- Let me continue with Asset Management on sli...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>115 million euros, Passive, management fees, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Q1-2023-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Slide 23 ‚Äì Corporate &amp; Other</td>\n",
       "      <td>- A reminder that Corporate &amp; Other now includ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>a significant improvement, timing, bank levies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Q1-2023-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Slide 24 ‚Äì Outlook</td>\n",
       "      <td>- We remain focused on delivering positive ope...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>a range, our commitment, the monthly run-rate,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows √ó 9 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdea00f9-3bbb-4086-8425-4d282c8bccce')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-fdea00f9-3bbb-4086-8425-4d282c8bccce button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-fdea00f9-3bbb-4086-8425-4d282c8bccce');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-367a4d8f-7bec-481c-9f4c-b37a9ab0c29e\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-367a4d8f-7bec-481c-9f4c-b37a9ab0c29e')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-367a4d8f-7bec-481c-9f4c-b37a9ab0c29e button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_4bf6f7ce-76d3-4aa1-904c-d64f11e01257\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('final_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_4bf6f7ce-76d3-4aa1-904c-d64f11e01257 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('final_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                    File      Bank Name  Year  Quarter  \\\n",
       "0    Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "1    Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "2    Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "3    Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "4    Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "..                                   ...            ...   ...      ...   \n",
       "161  Q1-2023-Analyst-Call-Transcript.pdf  Deutsche Bank  2023        1   \n",
       "162  Q1-2023-Analyst-Call-Transcript.pdf  Deutsche Bank  2023        1   \n",
       "163  Q1-2023-Analyst-Call-Transcript.pdf  Deutsche Bank  2023        1   \n",
       "164  Q1-2023-Analyst-Call-Transcript.pdf  Deutsche Bank  2023        1   \n",
       "165  Q1-2023-Analyst-Call-Transcript.pdf  Deutsche Bank  2023        1   \n",
       "\n",
       "                                           Slide_title  \\\n",
       "0    Slide 2 ‚Äì Actions taken in 2024 position Deuts...   \n",
       "1    Slide 3 ‚Äì Resilient full-year results reflecti...   \n",
       "2    Slide 4 ‚Äì Clear traction across divisions set ...   \n",
       "3    Slide 5 ‚Äì Strong execution and positioning und...   \n",
       "4    Slide 6 ‚Äì Significantly lower expenses in 2025...   \n",
       "..                                                 ...   \n",
       "161                         Slide 20 ‚Äì Investment Bank   \n",
       "162                            Slide 21 ‚Äì Private Bank   \n",
       "163                        Slide 22 ‚Äì Asset Management   \n",
       "164                       Slide 23 ‚Äì Corporate & Other   \n",
       "165                                 Slide 24 ‚Äì Outlook   \n",
       "\n",
       "                                                  Text Sentiment   Score  \\\n",
       "0    target in 2025 and beyond\\n- Thank you Ioana, ...  negative  0.9975   \n",
       "1    performance\\n- We increased 2024 pre-provision...  positive  0.9999   \n",
       "2    higher profitability\\n- At our investor day in...  positive  1.0000   \n",
       "3    trajectory\\n- Since 2021, we have delivered a ...  positive  1.0000   \n",
       "4    execution of efficiency measures\\n- In 2025, o...  positive  0.8964   \n",
       "..                                                 ...       ...     ...   \n",
       "161  - Revenues for the first quarter were 19% lowe...  positive  1.0000   \n",
       "162  - Private Bank revenues were 2.4 billion euros...  positive  1.0000   \n",
       "163  - Let me continue with Asset Management on sli...  negative  0.9996   \n",
       "164  - A reminder that Corporate & Other now includ...  positive  1.0000   \n",
       "165  - We remain focused on delivering positive ope...  positive  1.0000   \n",
       "\n",
       "                                                Topics  \n",
       "0    2 billion euros year, capital returns, a total...  \n",
       "1    our efficiency program, FX, the Postbank takeo...  \n",
       "2    March, the commercial focus, substantially bet...  \n",
       "3    US, these trends, FX, this substantial growth,...  \n",
       "4    our initially-planned mandatory and strategic ...  \n",
       "..                                                 ...  \n",
       "161  improvements, A slight increase, March - Rates...  \n",
       "162  Wealth Management, inflation impacts, the sale...  \n",
       "163  115 million euros, Passive, management fees, 1...  \n",
       "164  a significant improvement, timing, bank levies...  \n",
       "165  a range, our commitment, the monthly run-rate,...  \n",
       "\n",
       "[166 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_sentiment_and_topic(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c842a60",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1749925674308,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "yEDp63f_48qW"
   },
   "outputs": [],
   "source": [
    "# Define financial metrics with possible aliases\n",
    "FINANCIAL_METRICS = {\n",
    "    \"revenue\": [\"revenue\", \"revenue target\"],\n",
    "    \"expense\": [\"expense\"],\n",
    "    \"income\": [\"income\", \"net income\", \"operating income\", \"earnings\"],\n",
    "    \"margin\": [\"margin\"],\n",
    "    \"profit\": [\"profit\", \"net profit\"],\n",
    "    \"loss\": [\"loss\", \"LGD\", \"loss given default\"],\n",
    "    \"ebitda\": [\"ebitda\"],\n",
    "    \"ebit\": [\"ebit\"],\n",
    "    \"share buyback\": [\"share buyback\"],\n",
    "    \"distribution\": [\"distribution\"],\n",
    "    \"capital ratio\": [\"capital ratio\", \"tier 1 ratio\", \"capital\", \"CET1\", \"CET2\"],\n",
    "    \"expenses\": [\"expenses\", \"opex\"],\n",
    "    \"capex\": [\"capex\"],\n",
    "    \"ROE\": [\"ROE\", \"return on equity\", \"return on tangible equity\"],\n",
    "    \"cost-income ratio\": [\"cost-income ratio\", \"cost/income ratio\"],\n",
    "    \"dividend\": [\"dividend\"],\n",
    "    \"aum\": [\"assets under management\", \"aum\"],\n",
    "    \"net interest income\": [\"NII\", \"net interest income\",\"interest income\"],\n",
    "    \"market share\": [\"market share\"],\n",
    "    \"cash flow\": [\"cash flow\"],\n",
    "    \"net margin\": [\"net margin\"],\n",
    "    \"EPS\": [\"EPS\", \"earnings per share\"],\n",
    "    \"RWA\": [\"RWA\", \"risk-weighted assets\", \"risk weighted assets\"]\n",
    "}\n",
    "\n",
    "# Build a reverse mapping from alias to canonical metric name\n",
    "alias_to_canonical = {}\n",
    "all_metric_aliases = []\n",
    "for canonical, aliases in FINANCIAL_METRICS.items():\n",
    "    for alias in aliases:\n",
    "        alias_lower = alias.lower()\n",
    "        alias_to_canonical[alias_lower] = canonical\n",
    "        all_metric_aliases.append(alias_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18743bd1",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1749925676542,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "AKOeWZv25FYY"
   },
   "outputs": [],
   "source": [
    "def build_metric_pattern(aliases):\n",
    "    # Create regex pattern that matches any of the aliases as whole words (with spaces accounted for)\n",
    "    return \"|\".join(\n",
    "        [r\"\\b\" + re.sub(r\"\\s+\", r\"\\\\s+\", re.escape(alias)) + r\"\\b\" for alias in aliases]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e862cd2",
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1749925678575,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "fhY08dBT7Cdo"
   },
   "outputs": [],
   "source": [
    "def extract_financial_metrics(text):\n",
    "    text = text.replace(\"\\n\", \" \").strip()\n",
    "    results = []\n",
    "\n",
    "    metric_pattern = build_metric_pattern(all_metric_aliases)\n",
    "    value_pattern = r\"(‚Ç¨\\s?\\d+(?:\\.\\d+)?\\s*(?:million|billion|thousand|bn|m|k)?)\"\n",
    "    percent_pattern = r\"(\\d{1,3}(?:\\.\\d+)?\\s*%)\"\n",
    "\n",
    "    # Pattern 1: currency value followed by metric\n",
    "    value_first = re.findall(\n",
    "        rf\"{value_pattern}\\s+(?:of\\s+)?({metric_pattern})\",\n",
    "        text,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # Pattern 2: metric followed by currency value (up to 50 chars away)\n",
    "    metric_first = re.findall(\n",
    "        rf\"({metric_pattern})[^\\.]{{0,50}}?{value_pattern}\",\n",
    "        text,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # Pattern 3: metric followed by percentage (up to 50 chars away)\n",
    "    percent_matches = re.findall(\n",
    "        rf\"({metric_pattern})[^\\.]{{0,50}}?{percent_pattern}\",\n",
    "        text,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # Normalize and collect results\n",
    "    for value, metric in value_first:\n",
    "        canonical = alias_to_canonical.get(metric.lower().strip(), metric.lower().strip())\n",
    "        results.append({'metric': canonical, 'value': value.strip()})\n",
    "\n",
    "    for metric, value in metric_first:\n",
    "        canonical = alias_to_canonical.get(metric.lower().strip(), metric.lower().strip())\n",
    "        results.append({'metric': canonical, 'value': value.strip()})\n",
    "\n",
    "    for metric, value in percent_matches:\n",
    "        canonical = alias_to_canonical.get(metric.lower().strip(), metric.lower().strip())\n",
    "        results.append({'metric': canonical, 'value': value.strip()})\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fff471",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1749925681494,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "rWZkteU1-Ihl"
   },
   "outputs": [],
   "source": [
    "def extract_to_columns(row):\n",
    "    metrics = extract_financial_metrics(row[\"Text\"])\n",
    "    # Return a Series of dictionaries or empty strings\n",
    "    return pd.Series({f\"metric{i+1}\": metric for i, metric in enumerate(metrics)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d2612",
   "metadata": {
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1749925682713,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "SCRGaxOc-OFE"
   },
   "outputs": [],
   "source": [
    "# Apply extraction and expand into new columns\n",
    "metrics_df_qa = final_df_qa.apply(extract_to_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80627461",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1749925683845,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "mUlOEGE--Wgv"
   },
   "outputs": [],
   "source": [
    "# Concatenate with the original DataFrame\n",
    "cols_to_fill_str = metrics_df_qa.columns.tolist()\n",
    "final_df_qa_expanded = pd.concat([final_df_qa, metrics_df_qa], axis=1)\n",
    "final_df_qa_expanded[cols_to_fill_str] = final_df_qa_expanded[cols_to_fill_str].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aedbca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1749925685024,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "RQFSBB2T-fam",
    "outputId": "151066c5-ddc3-43dd-e33d-ae4536902f7d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"final_df_qa_expanded\",\n  \"rows\": 234,\n  \"fields\": [\n    {\n      \"column\": \"File\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Q4-2023-Analyst-Call-Transcript.pdf\",\n          \"Q2-2023-Analyst-Call-Transcript.pdf\",\n          \"Q4-2024-Analyst-Call-Transcript.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bank Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Deutsche Bank\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2023,\n        \"max\": 2025,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quarter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Speaker name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"Matthew Clark\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Institution\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"Autonomous\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question Number\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 219,\n        \"samples\": [\n          \"Yes. Hi, Christian, James, Thanks for taking my         questions. First question is regarding the comment around FIC slowdown. Can you just put that in context? In April, you mentioned that, I think, on Bloomberg and Christian, you just mentioned that as well. Could you just put it in context of what timeframe you're comparing? And secondly, in that context, just tell me what subsegments of FIC are weaker than credit. Is it 18 rates? Maybe even by geography, if possible, just so we get an idea. And if this is just an immediate reaction of what happened in the markets, post tariffs, or is this an ongoing issue that we should think about in our modelling. And then the second question is regarding your outlook, GDP, US assumption 1.7, China, four and a half. Just wondering if these numbers, what would happen if they would be significantly lower? Because they look a bit on the higher end of what market consensus expectation or forward curves are assuming. If you could discuss that relative to your 10% RoTE plus target and issues around that, if we should think about if it could have a negative impact, so to say. James von Moltke   Sure. Thanks. And I'll start on the guidance that we'd given or commentary about the market. Look, I think one important thing is to say is that the second half of April, and it isn't precisely in halves, but I think the easiest way to think about it is second half of April, resumed a pattern that looked very much like what you see in the disclosure on daily trading results in the FIC business for much of the first quarter. So, to your question about ongoing, it isn't a concern for us at the moment at all. In fact, I think we're well positioned to recapture the foregone revenues from the first half of April as in the balance of the quarter. In fairness, we're actually up year on year still in April. So we look at this with a relaxed view. Naturally, in markets that are as turbulent as the ones we experienced in the first couple of weeks of April, you're going to see some correlations breakdown, some impact on the books. But we were reasonably happy. So there was, of course, a slowdown a few weak days, but we were happy with how the desks performed in that environment. The way we were able to stand in, to provide liquidity for clients, pricing, what have you. In terms of the products, it was a little varied around the world. But to your point, credit struggled more, and there were elements in the Rates and FX complexes 19 where, again, correlations moving created some disturbance. What's interesting is how quickly and almost fully the markets have recovered over the course of April. Again, going to your question about, is it an ongoing concern? As we sit here today, really, it's not. And actually, I've been positively impressed by the way in which investors have continued to be engaged in the environment that we have, which is reasonably fast moving. In terms of the outlook, lots of our assumptions are driven by macroeconomic variables. And I'll focus on revenues and expenses. And naturally, we look at downside scenarios. And that was the principal driver, of course, of the overlay that we took in provisions in Q1. We think that overlay was prudent and appropriate and actually reflects how the macroeconomic consensus has moved since the end of March. So we feel quite comfortable with how, if you like, first quarter reporting reflects our outlook, as well as the consensus environment today. The other thing, just more broadly to the question you asked and really Christian\\u2019s response to Chris's question. We see a lot of what I'll call portfolio effects in our businesses. So businesses that are maybe negatively affected by certain elements of the macro environment will be offset by others that are benefited. And so it isn't at all linear. And we feel like the balance of risks and opportunities that we see in the market really underscores our outlook, as Christian just mentioned. And hence, we're feeling pretty good about the overall macro environment, even as it's changed since the beginning of the year when we last spoke.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flag_question\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12216254995858825,\n        \"min\": 0.4816,\n        \"max\": 1.0,\n        \"num_unique_values\": 115,\n        \"samples\": [\n          0.5549\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 174,\n        \"samples\": [\n          \"that book, provisions, the stage, James von Moltke   Stock, the 1.6 billion euro, total, probably 50 million euro, the stock\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metric1\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metric2\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metric3\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "final_df_qa_expanded"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a9f756ff-b3a6-404f-bc2f-447e2576945c\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Bank Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Speaker name</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Question Number</th>\n",
       "      <th>Text</th>\n",
       "      <th>flag_question</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "      <th>Topics</th>\n",
       "      <th>metric1</th>\n",
       "      <th>metric2</th>\n",
       "      <th>metric3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Nicolas Payen</td>\n",
       "      <td>Kepler Cheuvreux</td>\n",
       "      <td>1</td>\n",
       "      <td>Good morning. I have two questions, please. Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>the year, a share buyback annual growth, ‚Ç¨ 750...</td>\n",
       "      <td>{'metric': 'revenue', 'value': '‚Ç¨ 32 billion'}</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Christian Sewing</td>\n",
       "      <td>EU</td>\n",
       "      <td>2</td>\n",
       "      <td>Thank you, Nicolas, it's Christian. Let me let...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>US, a chance, those years, the discussions, ou...</td>\n",
       "      <td>{'metric': 'net interest income', 'value': '‚Ç¨ ...</td>\n",
       "      <td>{'metric': 'distribution', 'value': '‚Ç¨ 2.1 bil...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Anke Reingen</td>\n",
       "      <td>RBC</td>\n",
       "      <td>3</td>\n",
       "      <td>Thank you very much for taking my question. I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>FX, technology, the divisional level, a great ...</td>\n",
       "      <td>{'metric': 'capital ratio', 'value': '62.5%'}</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Christian Sewing</td>\n",
       "      <td>EU</td>\n",
       "      <td>3</td>\n",
       "      <td>Anke, I 100% support what James is saying. Jus...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9887</td>\n",
       "      <td>our prepared remarks, that, Rebecca, the outco...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Kian Abouhoussein</td>\n",
       "      <td>JP Morgan</td>\n",
       "      <td>4</td>\n",
       "      <td>Thanks for taking my questions. I just wanted ...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>the expense side, the opportunity, FX, risk-we...</td>\n",
       "      <td>{'metric': 'revenue', 'value': '‚Ç¨ 32 billion'}</td>\n",
       "      <td>{'metric': 'expense', 'value': '‚Ç¨ 20.8 billion'}</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9f756ff-b3a6-404f-bc2f-447e2576945c')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a9f756ff-b3a6-404f-bc2f-447e2576945c button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a9f756ff-b3a6-404f-bc2f-447e2576945c');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-39a4983d-9e05-4a37-b5d8-a7f2a45e2b5d\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-39a4983d-9e05-4a37-b5d8-a7f2a45e2b5d')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-39a4983d-9e05-4a37-b5d8-a7f2a45e2b5d button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                  File      Bank Name  Year  Quarter  \\\n",
       "0  Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "1  Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "2  Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "3  Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "4  Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "\n",
       "        Speaker name       Institution  Question Number  \\\n",
       "0      Nicolas Payen  Kepler Cheuvreux                1   \n",
       "1   Christian Sewing                EU                2   \n",
       "2       Anke Reingen               RBC                3   \n",
       "3   Christian Sewing                EU                3   \n",
       "4  Kian Abouhoussein         JP Morgan                4   \n",
       "\n",
       "                                                Text  flag_question Sentiment  \\\n",
       "0  Good morning. I have two questions, please. Th...              1   neutral   \n",
       "1  Thank you, Nicolas, it's Christian. Let me let...              1  positive   \n",
       "2  Thank you very much for taking my question. I ...              1   neutral   \n",
       "3  Anke, I 100% support what James is saying. Jus...              0   neutral   \n",
       "4  Thanks for taking my questions. I just wanted ...              1   neutral   \n",
       "\n",
       "    Score                                             Topics  \\\n",
       "0  0.9994  the year, a share buyback annual growth, ‚Ç¨ 750...   \n",
       "1  1.0000  US, a chance, those years, the discussions, ou...   \n",
       "2  0.9983  FX, technology, the divisional level, a great ...   \n",
       "3  0.9887  our prepared remarks, that, Rebecca, the outco...   \n",
       "4  0.9986  the expense side, the opportunity, FX, risk-we...   \n",
       "\n",
       "                                             metric1  \\\n",
       "0     {'metric': 'revenue', 'value': '‚Ç¨ 32 billion'}   \n",
       "1  {'metric': 'net interest income', 'value': '‚Ç¨ ...   \n",
       "2      {'metric': 'capital ratio', 'value': '62.5%'}   \n",
       "3                                                      \n",
       "4     {'metric': 'revenue', 'value': '‚Ç¨ 32 billion'}   \n",
       "\n",
       "                                             metric2 metric3  \n",
       "0                                                             \n",
       "1  {'metric': 'distribution', 'value': '‚Ç¨ 2.1 bil...          \n",
       "2                                                             \n",
       "3                                                             \n",
       "4   {'metric': 'expense', 'value': '‚Ç¨ 20.8 billion'}          "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_qa_expanded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61341f4c",
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1749925689492,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "cSqlALpIMkDz"
   },
   "outputs": [],
   "source": [
    "output_excel_qa_sentiment = \"qa_speaker_blocks_with_sentiments.xlsx\"\n",
    "final_df_qa_expanded.to_excel(output_excel_qa_sentiment, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f25ec",
   "metadata": {
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1749925691376,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "YdCVcqAiQEmN"
   },
   "outputs": [],
   "source": [
    "# Apply extraction and expand into new columns for presentation part\n",
    "metrics_df = final_df.apply(extract_to_columns, axis=1)\n",
    "\n",
    "# Concatenate with the original DataFrame\n",
    "cols_to_fill_str = metrics_df.columns.tolist()\n",
    "final_df_expanded = pd.concat([final_df, metrics_df], axis=1)\n",
    "final_df_expanded[cols_to_fill_str] = final_df_expanded[cols_to_fill_str].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc666a84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1749925693759,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "PycIcb5pQEh7",
    "outputId": "f5dd6f90-561d-4169-e877-33e77d83e3e8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"final_df_expanded\",\n  \"rows\": 166,\n  \"fields\": [\n    {\n      \"column\": \"File\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Q1-2024-Analyst-Call-Transcript.pdf\",\n          \"Q4-2023-Analyst-Call-Transcript.pdf\",\n          \"Q2-2023-Analyst-Call-Transcript.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bank Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Deutsche Bank\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2023,\n        \"max\": 2025,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quarter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Slide_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 131,\n        \"samples\": [\n          \"Slide 1 \\u2013 Business momentum reflecting strategy execution\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 166,\n        \"samples\": [\n          \"- We  aim to accelerate delivery on three dimensions: operational efficiency, capital efficiency, and revenue growth, where we aim to outperform our original targets. We have already made progress in all of these\\n- Turning first to operational efficiencies:\\n- We raised our ambition for incremental efficiencies from 2 billion euros to 2.5 billion euros, as we said\\n- We have already delivered more than 600 million euros, through a range of measures such as branch closures in the Private Bank, standardizing loan processing in the Corporate Bank and Investment Bank and simplifying our technology infrastructure\\n- We anticipate 300 million euros of savings by 2025 from the successfully completed migration of 12 million Postbank clients onto the Deutsche Bank technology platform\\n- And we  expect more than 100 million euros from the announced redundancies in senior non-client facing roles as more than 80% of affected staff have either been informed or left the platform\\n- In other words, a total of around 1 billion euros in savings are either already achieved, or are expected from measures now implemented\\n- We have a series of other measures in flight- for example, streamlining our mortgage business and further branch closures in the Private Bank; re-engineering more front-to-back processes in the Corporate Bank and Investment Bank; further application de-commissioning; and additional workforce measures\\n- These are some examples of a wider programme of initiatives underway. Based on our progress on these, and realized achievements so far, we reaffirm our 2.5-billion-euro goal\\n- In respect of capital efficiencies: as you know, our aim is to reduce risk weighted assets by 15-20 billion euros by 2025 relative to our baseline assumptions with a modest revenue impact\\n- In the second quarter we accelerated securitisation transactions which delivered RWA relief of around 3 billion euros\\n- In addition, credit risk RWAs were reduced as part of the Trade Finance and Lending optimization efforts\\n- Overall, we proved our revenue strength with the business delivering revenue growth while our FX adjusted RWAs decreased by 5 billion euros compared to the prior year quarter\\n- We have further optimization measures in preparation for the second half of 2023 including securitisation of consumer finance loans and reductions in sub-hurdle lending\\n- All this gives us confidence that we will deliver on our capital optimisation goals\\n- Turning finally to revenue growth: we are fully on track to outperform on our revenue growth targets, of 3.5 to 4.5% compound annual growth against 2021 levels\\n- On a last-twelve-month basis, we delivered compound annual revenue growth versus 2021 of 7.5%, well ahead of that target, with revenue growth of 8% in the first half of this year\\n- We expect the interest rate environment to continue to drive sustainable performance in our stable businesses\\n- We  anticipate added momentum from our organic and inorganic investments, including the Numis acquisition or the new partnership with Lufthansa and Miles & More, and from hiring of some 50 senior O&A bankers. This enables us to take advantage of an expected pickup in corporate finance activity \\u2013 we are already seeing signs of this in our backlog. We have also hired around 30 wealth managers\\n- And we expect the growth in our assets under management, and net asset inflows, to drive fee income in future quarters\\n- To sum up:\\n- We are delivering revenue and business growth off a strong franchise; our well-balanced, complementary business mix enables us to drive continued revenue momentum; we are increasing our earnings power year by year, and we see a clear path to achieving our 2025 profitability targets, amongst others an RoTE of larger than 10% in 2025\\n- And we are delivering on two key promises: distributing 8 billion euros to shareholders, and accelerating execution of our Global Hausbank strategy\\n- With that: let me hand over to James JAMES VON MOLTKE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10176992838493962,\n        \"min\": 0.5019,\n        \"max\": 1.0,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          0.9963\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 166,\n        \"samples\": [\n          \"our ambition, a total, the Corporate Bank and Investment Bank, a series, more than 600 million euros, These, track, FX, advantage, consumer finance loans, others, quarter, our original targets, added momentum, loan processing, Numis, management, 3.5 to 4.5% compound annual growth, confidence, compound annual revenue growth, our assets, measures, our well-balanced, complementary business mix, capital efficiency, our Global Hausbank strategy, the Trade Finance, 7.5%, an RoTE, risk, sustainable performance, other measures, a range, securitisation, back, 8 billion euros, flight-, sub-hurdle lending, our capital optimisation goals, fee income, around 3 billion euros, net asset inflows, revenue and business growth, the growth, our aim, our revenue strength, larger than 10%, that target, the first half, our mortgage business, Lufthansa, further branch closures, a modest revenue impact, three dimensions, savings, 2 billion euros, the Deutsche Bank technology platform, our baseline assumptions, the business, around 1 billion, RoTE, Investment Bank, the announced redundancies, execution, example, our progress, 2.5 billion euros, our earnings power year, RWA relief, corporate finance activity, more than 80%, delivery, some 50 senior O&A bankers, a strong franchise, 2021 levels, operational efficiency, our 2025 profitability targets, initiatives, James JAMES VON, our technology infrastructure, two key promises, year, a last-twelve-month basis, This, more than 100 million euros, further application, incremental efficiencies, reductions, 12 million Postbank clients, capital efficiencies, our organic and inorganic investments, affected staff, the prior year, revenue growth, Miles, this year, the Private Bank, respect, relative, around 30 wealth managers, 5 billion euros, the interest rate environment, achievements, further optimization measures, future quarters, some examples, our backlog, our revenue growth targets, our stable businesses, a clear path, the successfully completed migration, preparation, these, progress, addition, Deutsche Bank, around 1 billion euros, our FX adjusted RWAs, operational efficiencies, credit risk RWAs, the Numis acquisition, the new partnership, other words, signs, the Trade Finance and Lending optimization efforts, assets, part, the second quarter, that, 2.5-billion-euro, the Corporate Bank, a wider programme, an expected pickup, All this, senior non-client facing roles, continued revenue momentum, this, Miles & More, our 2.5-billion-euro goal, O&A, 15-20 billion, 15-20 billion euros, the second half, shareholders, 300 million euros, around 3 billion euros -, the platform, securitisation transactions, branch closures\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metric1\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metric2\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metric3\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metric4\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metric5\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "final_df_expanded"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-3b47efb3-3ade-430d-b386-ca1a8492bf5c\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Bank Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Slide_title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "      <th>Topics</th>\n",
       "      <th>metric1</th>\n",
       "      <th>metric2</th>\n",
       "      <th>metric3</th>\n",
       "      <th>metric4</th>\n",
       "      <th>metric5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Slide 2 ‚Äì Actions taken in 2024 position Deuts...</td>\n",
       "      <td>target in 2025 and beyond\\n- Thank you Ioana, ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>2 billion euros year, capital returns, a total...</td>\n",
       "      <td>{'metric': 'profit', 'value': '19%'}</td>\n",
       "      <td>{'metric': 'income', 'value': '65%'}</td>\n",
       "      <td>{'metric': 'capital ratio', 'value': '13.8%'}</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Slide 3 ‚Äì Resilient full-year results reflecti...</td>\n",
       "      <td>performance\\n- We increased 2024 pre-provision...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>our efficiency program, FX, the Postbank takeo...</td>\n",
       "      <td>{'metric': 'profit', 'value': '19%'}</td>\n",
       "      <td>{'metric': 'revenue', 'value': '4%'}</td>\n",
       "      <td>{'metric': 'income', 'value': '13%'}</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Slide 4 ‚Äì Clear traction across divisions set ...</td>\n",
       "      <td>higher profitability\\n- At our investor day in...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>March, the commercial focus, substantially bet...</td>\n",
       "      <td>{'metric': 'revenue', 'value': '9%'}</td>\n",
       "      <td>{'metric': 'revenue', 'value': '5%'}</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Slide 5 ‚Äì Strong execution and positioning und...</td>\n",
       "      <td>trajectory\\n- Since 2021, we have delivered a ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>US, these trends, FX, this substantial growth,...</td>\n",
       "      <td>{'metric': 'revenue', 'value': '5.9%'}</td>\n",
       "      <td>{'metric': 'revenue', 'value': '4%'}</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q4-2024-Analyst-Call-Transcript.pdf</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Slide 6 ‚Äì Significantly lower expenses in 2025...</td>\n",
       "      <td>execution of efficiency measures\\n- In 2025, o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>our initially-planned mandatory and strategic ...</td>\n",
       "      <td>{'metric': 'income', 'value': '65%'}</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b47efb3-3ade-430d-b386-ca1a8492bf5c')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3b47efb3-3ade-430d-b386-ca1a8492bf5c button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3b47efb3-3ade-430d-b386-ca1a8492bf5c');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-ebfc07d8-dd22-443e-b993-71927d8d9e2b\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ebfc07d8-dd22-443e-b993-71927d8d9e2b')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-ebfc07d8-dd22-443e-b993-71927d8d9e2b button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                  File      Bank Name  Year  Quarter  \\\n",
       "0  Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "1  Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "2  Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "3  Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "4  Q4-2024-Analyst-Call-Transcript.pdf  Deutsche Bank  2024        4   \n",
       "\n",
       "                                         Slide_title  \\\n",
       "0  Slide 2 ‚Äì Actions taken in 2024 position Deuts...   \n",
       "1  Slide 3 ‚Äì Resilient full-year results reflecti...   \n",
       "2  Slide 4 ‚Äì Clear traction across divisions set ...   \n",
       "3  Slide 5 ‚Äì Strong execution and positioning und...   \n",
       "4  Slide 6 ‚Äì Significantly lower expenses in 2025...   \n",
       "\n",
       "                                                Text Sentiment   Score  \\\n",
       "0  target in 2025 and beyond\\n- Thank you Ioana, ...  negative  0.9975   \n",
       "1  performance\\n- We increased 2024 pre-provision...  positive  0.9999   \n",
       "2  higher profitability\\n- At our investor day in...  positive  1.0000   \n",
       "3  trajectory\\n- Since 2021, we have delivered a ...  positive  1.0000   \n",
       "4  execution of efficiency measures\\n- In 2025, o...  positive  0.8964   \n",
       "\n",
       "                                              Topics  \\\n",
       "0  2 billion euros year, capital returns, a total...   \n",
       "1  our efficiency program, FX, the Postbank takeo...   \n",
       "2  March, the commercial focus, substantially bet...   \n",
       "3  US, these trends, FX, this substantial growth,...   \n",
       "4  our initially-planned mandatory and strategic ...   \n",
       "\n",
       "                                  metric1  \\\n",
       "0    {'metric': 'profit', 'value': '19%'}   \n",
       "1    {'metric': 'profit', 'value': '19%'}   \n",
       "2    {'metric': 'revenue', 'value': '9%'}   \n",
       "3  {'metric': 'revenue', 'value': '5.9%'}   \n",
       "4    {'metric': 'income', 'value': '65%'}   \n",
       "\n",
       "                                metric2  \\\n",
       "0  {'metric': 'income', 'value': '65%'}   \n",
       "1  {'metric': 'revenue', 'value': '4%'}   \n",
       "2  {'metric': 'revenue', 'value': '5%'}   \n",
       "3  {'metric': 'revenue', 'value': '4%'}   \n",
       "4                                         \n",
       "\n",
       "                                         metric3 metric4 metric5  \n",
       "0  {'metric': 'capital ratio', 'value': '13.8%'}                  \n",
       "1           {'metric': 'income', 'value': '13%'}                  \n",
       "2                                                                 \n",
       "3                                                                 \n",
       "4                                                                 "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_expanded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e0f7d2",
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1749925697366,
     "user": {
      "displayName": "Mircea Guinea",
      "userId": "01968039513176187637"
     },
     "user_tz": -120
    },
    "id": "4Rx-gT2EMp_z"
   },
   "outputs": [],
   "source": [
    "output_excel_presentations_sentiment = \"presentation_slides_with_sentiment.xlsx\"\n",
    "final_df_expanded.to_excel(output_excel_presentations_sentiment, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f8b38",
   "metadata": {
    "id": "fjlFpuc_LI3K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b035fb22",
   "metadata": {
    "id": "E1ZJfFomM15O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43a53cb3",
   "metadata": {},
   "source": [
    "# üèõÔ∏è UniCredit - Data Extraction\n",
    "This section deals with UniCredit-specific data extraction tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25cecf9",
   "metadata": {
    "id": "9PWfkZgtCql6"
   },
   "source": [
    "## Import PDFs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7941328d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1201,
     "status": "ok",
     "timestamp": 1750195031992,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "qVzhmgljDFKj",
    "outputId": "49cd5ae4-4b6a-41ae-e604-cb25ada2b6a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      " Codes\t\t\t\t'Presentation Documents'\n",
      " Data\t\t\t\t Project_Plan\n",
      "'Ideas and Research Documents'\t'Russell Hunter Notebooks'\n",
      " Meetings\t\t\t Video_presentation\n",
      "'Other Documents'\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')\n",
    "!ls '/content/drive/My Drive/BoE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188899b9",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1750195031998,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "nPVn1fsFL9EJ"
   },
   "outputs": [],
   "source": [
    "rec = '/content/drive/My Drive/BoE/Data/Unicredit/recordings/'\n",
    "\n",
    "transcript_folder = '/content/drive/My Drive/BoE/Data/Unicredit/transcripts/'\n",
    "\n",
    "output_folder = '/content/drive/My Drive/BoE/Data/Unicredit/extracted_outputs/'\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047157dc",
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1750195032042,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "2Hj0-MEaEecT"
   },
   "outputs": [],
   "source": [
    "# q123 = os.path.join(rec, '1Q23-UniCredit-Conference-Call.mp3')\n",
    "# q223 = os.path.join(rec, '2Q23-UniCredit-Conference-Call.mp3')\n",
    "# q323 = os.path.join(rec, '3Q23-UniCredit-Conference-Call.mp3')\n",
    "# q423 = os.path.join(rec, '4Q23-UniCredit-Conference-Call.mp3')\n",
    "\n",
    "# q124 = os.path.join(rec, '1Q24-UniCredit-Conference-Call.mp3')\n",
    "# q224 = os.path.join(rec, '2Q24-UniCredit-Conference-Call.mp4')\n",
    "# q324 = os.path.join(rec, '3Q24-UniCredit-Conference-Call.mp3')\n",
    "# q424 = os.path.join(rec, '4Q24-UniCredit-Conference-Call.mp4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c543f1ee",
   "metadata": {
    "id": "VX5XX6RxiLYX"
   },
   "source": [
    "## Extract info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85455852",
   "metadata": {
    "id": "l7tTaHoCNIO8"
   },
   "source": [
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a1092f",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1750195032680,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "Za9v5x_ENJUA"
   },
   "outputs": [],
   "source": [
    "# model_name = \"yiyanghkust/finbert-tone\"\n",
    "# tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "# finbert_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "# def add_finbert_sentiment(df, text_column=\"text\"):\n",
    "#     sentiments = []\n",
    "#     scores = []\n",
    "#     for text in df[text_column].fillna(\"\").tolist():\n",
    "#         try:\n",
    "#             result = finbert_pipeline(text[:512])[0]  # Truncate if needed\n",
    "#             sentiments.append(result[\"label\"].upper())\n",
    "#             scores.append(round(result[\"score\"], 3))  # Confidence score\n",
    "#         except Exception:\n",
    "#             sentiments.append(\"ERROR\")\n",
    "#             scores.append(0.0)\n",
    "#     df[\"finbert_sentiment\"] = sentiments\n",
    "#     df[\"finbert_confidence\"] = scores\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab6b206",
   "metadata": {
    "id": "yk8d2hjh6GYg"
   },
   "source": [
    "both Finbert and Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b4739",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373,
     "referenced_widgets": [
      "705e7834b7234fafa5f5c0f39afca2f7",
      "6354e7bdbc944fa4b0a554cca36c485b",
      "73abd81672e34e218f1d4eed9bf40b63",
      "5bb8d09d3ee04e1785413927d105596f",
      "c68f01c9e842411482ba9cf4d423eff0",
      "14e5c8d9ac7f496cafd136333136b9d3",
      "784e404e5c25405983b097bf244e1540",
      "22decdf487cb41e7a1ae1778b7df45ce",
      "c41d157a16e9499d9cc6cb15b7dc10d9",
      "f8ef77140e024cc783718e2bd3c823f0",
      "38fd8acba158412f8626b6a58950c6bd",
      "2a788a2b7fdb4ed79fbe60552b884d0b",
      "796d9ef2e694462cbceebc5ed66b37a5",
      "068cdeb7448d4d2c8706761ef57efb89",
      "e2f82406563c4a0a8f88d79a38264448",
      "35b2deb9e14148daa7e1555bbc1da4aa",
      "23bb07adc1ce41ac965844b43940e854",
      "dee8d16da716450b82685ae503dcdfe2",
      "3a9577a0f0d74871be8d9f1e650b15f7",
      "2dd72e1c970844329f4f921914b45605",
      "b1e0dc84d48342e5a26ed136c95c0c8c",
      "a54cbeaaefa540d684aa35a24a66dcb0",
      "0a47f8b72e64476f83149080f8172f81",
      "024089fc8c344acda6a6172b3500a7c9",
      "49fe513eddcd4ac88889e86ed9b94d20",
      "42348db637ee4d95bcc35ce57bf245e2",
      "e8fe0f0f83604297b942233906696679",
      "539f312b9d174e05ae77179b5565e776",
      "d5eb1f14b34e4220bcb0cb72671c0aa7",
      "d89104ad595349a3b724923cf74344b0",
      "7e2f511dd4fa47d981c65059cd70943b",
      "e7f4d8d5113c42288330adf0337b5c74",
      "8fe8d058309b4f85bdcb85f77439de4a",
      "9771626b169646169b1433bd980d9b6e",
      "d6af5c1f77154ea795e0d8bcd8ad20d3",
      "9bfdf3667a6c49418099253b06490bdb",
      "26b0e1e3f93643f796136d9e281e53ab",
      "9ab8e964fef744079be11acae34a7daf",
      "030508e23410453d93fef904b79c41cd",
      "b3960fcb54c440ec992e180df4cdac20",
      "cd168a3d81834cad8293c0d1afced072",
      "bc2c201f1a1b44b68f82e863aeda2e0a",
      "f403c2b3940b4e9ba53e08593cc41afd",
      "98756bcee73d4fa4b73e7d9a26547b68",
      "9e2e046469a54172bd6f16397ac997d3",
      "13436f61c776408e82adba070e52420f",
      "dadc453ebf3d473bac167d419a01d5a4",
      "6051412f34344d2bba2685b06273d13a",
      "d66542e90fc8464888b937ef17e1253f",
      "366c7103848747b5b7c033a87ea9e775",
      "570d1b7d276242fd9b13a81c02531906",
      "6d94b108c22f4f20ad95954f3489346f",
      "f90993b1849c4939b0041b3078b398c9",
      "9d2ac14200864997b1980ec31e40969e",
      "6796581617cd48b2b1443c0b00ebd045",
      "f7c0c656045b412a91213c7257bb0865",
      "cc5727ba06e9420a9638d0abbb3551b2",
      "ee866106d3344cbd8dc18ebde69a1731",
      "b096aab7bee5496b9a1f7d753664e113",
      "bfdc343021aa439895796713b2d5450e",
      "85ccbcd6a69b498d9321f33c6f9e01a3",
      "ac51ce2ea13544d58a50f6ed419dbdcb",
      "d81b11ce092940b39e6e0d21ab2e071c",
      "8e89352c9716487fba272f8b55b7d082",
      "64db6a97e4fc44f9a6adc7ce382969aa",
      "efc1b981150e4dfbae442f3631146222",
      "926fb8869226460db678e34e79e67c5b",
      "9afec28ba0664d83811816bb73b74ca2",
      "357ccf2def74492da68deb4eae67da2d",
      "78a4694ddb114fb9bc2d5929b63fdce5",
      "6cff811ccf3b4e3f8330eaeae8335673",
      "4f46a8c1c0804664ba40641e36e3e124",
      "dfe1113370224f1187de7fe6c3f70471",
      "e1ac4c66f01a4572bab3b28263cdbc2b",
      "52e5bf51a99649328aff9abb3e9cc7de",
      "4478688985b14e8d974878849a135083",
      "06a7483d496143fbbec612b486655992",
      "25826d36d3c84986aef8a5d5540bc55d",
      "96b18376fec245f9a0564851a4d9db11",
      "6c46983cc9f64df798904aab60c3d486",
      "619623d5ac00438f8bf9115351a9eafe",
      "66d177ad978741afa521a35d67bc5163",
      "200eb1a41f864d8b9a1dd1fec5e76c8c",
      "d63f85a2ad104bf6877b149bcc423d0f",
      "fe63a80bb5214b77b9bafdb8b5697c4b",
      "212cbf3dbbd84cd5aeda94af9fe773ba",
      "3160842666b740f6b1076232d1f2f46c",
      "f330f8382f4747d6bfef9de39f7f20ee",
      "59831fd359e746618926b258a16de6cc",
      "e321054ed28645ce8f6cc93289696cd7",
      "1f6f15c7768d4afa94bb13bf8f760235",
      "98edb8974b354badb8e62f24907e1908",
      "3217a6a3911e4fc2894e933d45bb1d51",
      "491fbd8da0904d318a5ef75bf3e6ffc8",
      "7f27e64ffe234a0193e09dd8f5554219",
      "98922a4f1a124a389ba85a0442d2f53d",
      "6d95173192ee48e589e95aa2aa63d316",
      "379a3be8b6594d279b059984e3245c3e",
      "8d6b818bad9543d49fb97626f0dadfea",
      "e630669d155249f7adaf2ee31e6f657a",
      "2f5cf0f9bc9746488e2e331bcda236a4",
      "83ef100ed08c49e79a0a3a7c0defb5af",
      "50d2bbbc6ef84f708e70d7167fb8dd74",
      "f41933b208eb44baa2f5ef5df5e8bb57",
      "2240c1d14985421ca44e814fdc4c8ed8",
      "335d356ff2034d0ca452bb7e7cf84221",
      "7bf7938a96bf4ff0b1918439124a856b",
      "2fa2d92ef6024bcab41f44f04ad7994a",
      "d7990da556354539823649f8df0b6733",
      "77973365c03e4a5fa660435bba590cf3"
     ]
    },
    "executionInfo": {
     "elapsed": 32850,
     "status": "ok",
     "timestamp": 1750195065546,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "E2SP0oj96Ioo",
    "outputId": "7c2c9cf0-8d1b-4b9a-b477-577b2d90c9bd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705e7834b7234fafa5f5c0f39afca2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a788a2b7fdb4ed79fbe60552b884d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/533 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a47f8b72e64476f83149080f8172f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9771626b169646169b1433bd980d9b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2e046469a54172bd6f16397ac997d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c0c656045b412a91213c7257bb0865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926fb8869226460db678e34e79e67c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25826d36d3c84986aef8a5d5540bc55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59831fd359e746618926b258a16de6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e630669d155249f7adaf2ee31e6f657a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load FinBERT\n",
    "finbert_model_name = \"yiyanghkust/finbert-tone\"\n",
    "finbert_tokenizer = BertTokenizer.from_pretrained(finbert_model_name)\n",
    "finbert_model = BertForSequenceClassification.from_pretrained(finbert_model_name)\n",
    "finbert_pipeline = pipeline(\"sentiment-analysis\", model=finbert_model, tokenizer=finbert_tokenizer)\n",
    "\n",
    "# Load RoBERTa\n",
    "roberta_model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_model_name)\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(roberta_model_name)\n",
    "roberta_pipeline = pipeline(\"sentiment-analysis\", model=roberta_model, tokenizer=roberta_tokenizer)\n",
    "\n",
    "# Combined function\n",
    "def add_dual_sentiment_models(df, text_column=\"text\"):\n",
    "    finbert_sentiments = []\n",
    "    finbert_scores = []\n",
    "    roberta_sentiments = []\n",
    "    roberta_scores = []\n",
    "\n",
    "    for text in df[text_column].fillna(\"\").tolist():\n",
    "        try:\n",
    "            fin_result = finbert_pipeline(text[:512])[0]\n",
    "            finbert_sentiments.append(fin_result[\"label\"].upper())\n",
    "            finbert_scores.append(round(fin_result[\"score\"], 3))\n",
    "        except Exception:\n",
    "            finbert_sentiments.append(\"ERROR\")\n",
    "            finbert_scores.append(0.0)\n",
    "\n",
    "        # try:\n",
    "        #     rob_result = roberta_pipeline(text[:512])[0]\n",
    "        #     roberta_sentiments.append(rob_result[\"label\"].upper())\n",
    "        #     roberta_scores.append(round(rob_result[\"score\"], 3))\n",
    "        # except Exception:\n",
    "        #     roberta_sentiments.append(\"ERROR\")\n",
    "        #     roberta_scores.append(0.0)\n",
    "\n",
    "    df[\"finbert_sentiment\"] = finbert_sentiments\n",
    "    df[\"finbert_confidence\"] = finbert_scores\n",
    "    # df[\"roberta_sentiment\"] = roberta_sentiments\n",
    "    # df[\"roberta_confidence\"] = roberta_scores\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ebba4",
   "metadata": {
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1750195065965,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "Vzjpgtz1iKSm"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Use lightweight spaCy\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "KEY_METRICS = {\n",
    "    \"EPS\": [\"eps\", \"earnings per share\"],\n",
    "    \"NII\": [\"nii\", \"net interest income\"],\n",
    "    \"ROE\": [\"roe\", \"return on equity\"],\n",
    "    \"ROA\": [\"roa\", \"return on assets\"],\n",
    "    \"NIM\": [\"nim\", \"net interest margin\"],\n",
    "    \"LIQUIDITY\": [\"liquidity\", \"lcr\", \"liquidity coverage ratio\", \"wholesale funding\"],\n",
    "    \"CAPITAL\": [\"capital\", \"cet1\", \"tcr\", \"total capital ratio\"],\n",
    "    \"PROFITABILITY\": [\"profitability\"],\n",
    "    \"PROVISIONS\": [\"provisions\", \"pll\", \"loan loss\", \"provision for losses\"],\n",
    "    \"NET INCOME\": [\"net income\"],\n",
    "    \"ASSET QUALITY\": [\"asset quality\", \"npl\", \"non performing loan\"]\n",
    "}\n",
    "\n",
    "# Words that imply performance movement or quantification\n",
    "QUALIFIERS = [\n",
    "    \"increase\", \"increased\", \"decrease\", \"decreased\", \"decline\", \"declined\",\n",
    "    \"improve\", \"improved\", \"growth\", \"grew\", \"dropped\", \"fell\", \"stable\",\n",
    "    \"stabilized\", \"unchanged\", \"flat\", \"rose\", \"risen\", \"higher\", \"lower\",\n",
    "    \"million\", \"billion\", \"%\"\n",
    "]\n",
    "\n",
    "\n",
    "# === Combined Metric + % Value Extraction Function ===\n",
    "def extract_structured_financials(pdf_path):\n",
    "    results = []\n",
    "\n",
    "    fname = os.path.basename(pdf_path)\n",
    "    match = re.search(r\"Q(\\d)[_\\s-]?(\\d{4})\", fname)\n",
    "    quarter, year = (int(match.group(1)), int(match.group(2))) if match else (None, None)\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            lines = text.split('\\n')\n",
    "            for i, line in enumerate(lines):\n",
    "                line_clean = line.strip()\n",
    "                line_lower = f\" {line_clean.lower()} \"\n",
    "                words_set = set(re.sub(r\"[^\\w\\s]\", \"\", line_lower).split())\n",
    "\n",
    "                # === 1. Extract % values with sentence context ===\n",
    "                percent_matches = re.findall(r\"\\d+[.,]?\\d*\\s?%\", line)\n",
    "                if percent_matches:\n",
    "                    before = lines[i - 1] if i > 0 else \"\"\n",
    "                    after = lines[i + 1] if i + 1 < len(lines) else \"\"\n",
    "                    context = f\"{before.strip()} {line_clean} {after.strip()}\"\n",
    "                    for match in percent_matches:\n",
    "                        results.append({\n",
    "                            \"quarter\": quarter,\n",
    "                            \"year\": year,\n",
    "                            \"metric\": \"PERCENT VALUE\",\n",
    "                            \"value\": match.strip(),\n",
    "                            \"text\": context.strip(),\n",
    "                            \"source_file\": fname\n",
    "                        })\n",
    "\n",
    "                # === 2. Extract metric-related values with number or qualifier ===\n",
    "                for metric_group, aliases in KEY_METRICS.items():\n",
    "                    if any(f\" {alias} \" in line_lower for alias in aliases):  # enforce word boundary\n",
    "                        has_number = bool(re.search(r\"\\d+[.,]?\\d*\", line))\n",
    "                        has_qualifier = any(q in line_lower for q in QUALIFIERS)\n",
    "\n",
    "                        if not has_number and not has_qualifier:\n",
    "                            continue  # skip vague mentions\n",
    "\n",
    "                        match = re.search(r\"(\\d+[.,]?\\d*)\\s?(million|billion|%)?\", line, re.IGNORECASE)\n",
    "                        value = match.group(0).strip() if match else None\n",
    "\n",
    "                        results.append({\n",
    "                            \"quarter\": quarter,\n",
    "                            \"year\": year,\n",
    "                            \"metric\": metric_group,\n",
    "                            \"value\": value,\n",
    "                            \"text\": line_clean,\n",
    "                            \"source_file\": fname\n",
    "                        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    if not df.empty:\n",
    "        # df = add_finbert_sentiment(df)\n",
    "        df = add_dual_sentiment_models(df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57285d0",
   "metadata": {
    "executionInfo": {
     "elapsed": 3177,
     "status": "ok",
     "timestamp": 1750195069140,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "HHOUCglzEWM8"
   },
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add known banks ‚Äî extend as needed\n",
    "org_patterns = [\n",
    "    {\"label\": \"ORG\", \"pattern\": \"Bank of America\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"Goldman Sachs\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"JPMorgan\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"Morgan Stanley\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"UniCredit\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"Deutsche Bank\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"HSBC\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"UBS\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"Citi\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"BNP Paribas\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"ING\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"Credit Suisse\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"Barclays\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"Mediobanca\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"Credit Agricole\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"Autonomous Research\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"BNP\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"Citi\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"UBS\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"Jefferies\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"KBW\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"Bank of America\"},\n",
    "    {\"label\": \"ORG\", \"pattern\": \"Morgan Stanley\"},\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def extract_person_and_org_from_operator(text):\n",
    "    doc = nlp(text)\n",
    "    person = None\n",
    "    org = None\n",
    "\n",
    "    # Try spaCy NER first\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\" and not person:\n",
    "            person = ent.text\n",
    "        elif ent.label_ == \"ORG\" and not org:\n",
    "            org = ent.text\n",
    "\n",
    "    # Fallback regex: e.g. \"from John Smith of Goldman Sachs\"\n",
    "    if not person or not org:\n",
    "        match = re.search(r\"from\\s+(.*?)\\s+of\\s+([A-Za-z\\s&]+)\", text, re.IGNORECASE)\n",
    "        if match:\n",
    "            if not person:\n",
    "                person = match.group(1).strip()\n",
    "            if not org:\n",
    "                org = match.group(2).strip()\n",
    "\n",
    "    return person, org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680cbc8a",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1750195069182,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "PYIWFvPGjVE-"
   },
   "outputs": [],
   "source": [
    "def extract_qna_long_format(pdf_path):\n",
    "    MANAGEMENT_NAMES = [\"Andrea Orcel\", \"Stefano Porro\"]\n",
    "\n",
    "    def is_speaker_line(line):\n",
    "        return bool(re.match(r\"^[A-Z][a-z]+(\\s[A-Z][a-z]+)?$\", line.strip())) or line.strip() in MANAGEMENT_NAMES or line.strip() == \"Operator\"\n",
    "\n",
    "    fname = os.path.basename(pdf_path)\n",
    "    match = re.search(r\"Q(\\d)[_\\s-]?(\\d{4})\", fname)\n",
    "    quarter, year = (int(match.group(1)), int(match.group(2))) if match else (None, None)\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        full_text = \"\\n\".join(p.extract_text() for p in pdf.pages if p.extract_text())\n",
    "\n",
    "    if \"Question-and-Answer Session\" not in full_text:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    qa_text = full_text.split(\"Question-and-Answer Session\", 1)[1]\n",
    "    lines = qa_text.split(\"\\n\")\n",
    "\n",
    "    blocks = []\n",
    "    current_speaker = None\n",
    "    current_block = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if is_speaker_line(line):\n",
    "            if current_speaker and current_block:\n",
    "                blocks.append({\"speaker\": current_speaker, \"text\": \" \".join(current_block).strip()})\n",
    "            current_speaker = line\n",
    "            current_block = []\n",
    "        else:\n",
    "            current_block.append(line)\n",
    "\n",
    "    if current_speaker and current_block:\n",
    "        blocks.append({\"speaker\": current_speaker, \"text\": \" \".join(current_block).strip()})\n",
    "\n",
    "    entries = []\n",
    "    speaker_to_org = {}\n",
    "    current_question = None\n",
    "    question_number = 0\n",
    "\n",
    "    for i in range(len(blocks)):\n",
    "        block = blocks[i]\n",
    "        speaker = block[\"speaker\"]\n",
    "\n",
    "        if speaker == \"Operator\":\n",
    "            # Try to extract person/org from the operator‚Äôs introduction\n",
    "            person, org = extract_person_and_org_from_operator(block[\"text\"])\n",
    "            if person and org:\n",
    "                speaker_to_org[person] = org\n",
    "\n",
    "            # Look ahead to find the actual question\n",
    "            if i + 1 < len(blocks):\n",
    "                next_block = blocks[i + 1]\n",
    "                if next_block[\"speaker\"] not in MANAGEMENT_NAMES and next_block[\"speaker\"] != \"Operator\":\n",
    "                    question_number += 1\n",
    "                    current_question = next_block[\"speaker\"]\n",
    "                    entries.append({\n",
    "                        \"quarter\": quarter,\n",
    "                        \"year\": year,\n",
    "                        \"question_number\": question_number,\n",
    "                        \"speaker\": current_question,\n",
    "                        \"institution\": speaker_to_org.get(current_question),\n",
    "                        \"type\": \"Question\",\n",
    "                        \"text\": next_block[\"text\"],\n",
    "                        \"source_file\": fname\n",
    "                    })\n",
    "\n",
    "        elif speaker in MANAGEMENT_NAMES and current_question is not None:\n",
    "            entries.append({\n",
    "                \"quarter\": quarter,\n",
    "                \"year\": year,\n",
    "                \"question_number\": question_number,\n",
    "                \"speaker\": speaker,\n",
    "                \"institution\": \"UniCredit\",  # known from context\n",
    "                \"type\": \"Answer\",\n",
    "                \"text\": block[\"text\"],\n",
    "                \"source_file\": fname\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e1f57d",
   "metadata": {
    "id": "0ARte1Yw0avS"
   },
   "source": [
    "Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b7abcf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 770669,
     "status": "ok",
     "timestamp": 1750195839855,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "TEWpPRNZvfkz",
    "outputId": "3fc74dac-a499-4713-ccc2-2d394dd0ce16"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing transcripts:   0%|          | 0/9 [00:00<?, ?file/s]\u001b[A\n",
      "Processing transcripts:  11%|‚ñà         | 1/9 [01:11<09:33, 71.73s/file]\u001b[A\n",
      "Processing transcripts:  22%|‚ñà‚ñà‚ñè       | 2/9 [02:31<08:53, 76.22s/file]\u001b[A\n",
      "Processing transcripts:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [04:14<08:50, 88.44s/file]\u001b[A\n",
      "Processing transcripts:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [05:52<07:41, 92.26s/file]\u001b[A\n",
      "Processing transcripts:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [07:25<06:11, 92.76s/file]\u001b[A\n",
      "Processing transcripts:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [08:41<04:20, 86.85s/file]\u001b[A\n",
      "Processing transcripts:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [10:07<02:53, 86.60s/file]\u001b[A\n",
      "Processing transcripts:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [11:27<01:24, 84.45s/file]\u001b[A\n",
      "Processing transcripts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [12:49<00:00, 85.46s/file]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Financial data saved to:\n",
      "- /content/drive/My Drive/BoE/Data/Unicredit/extracted_outputs/merged_financial_sentences_finbertonly.xlsx\n",
      "- /content/drive/My Drive/BoE/Data/Unicredit/extracted_outputs/merged_financial_sentences_finbertonly.pkl\n",
      "Q&A data saved to:\n",
      "- /content/drive/My Drive/BoE/Data/Unicredit/extracted_outputs/merged_qna_long_finbertonly.xlsx\n",
      "- /content/drive/My Drive/BoE/Data/Unicredit/extracted_outputs/merged_qna_long_finbertonly.pkl\n"
     ]
    }
   ],
   "source": [
    "all_financial_dfs = []\n",
    "all_qna_long_dfs = []\n",
    "\n",
    "pdf_files = [f for f in os.listdir(transcript_folder) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "for filename in tqdm(pdf_files, desc=\"Processing transcripts\", unit=\"file\"):\n",
    "    full_path = os.path.join(transcript_folder, filename)\n",
    "\n",
    "    try:\n",
    "        # === Financial Extraction ===\n",
    "        df_fin = extract_structured_financials(full_path)\n",
    "        if not df_fin.empty:\n",
    "            all_financial_dfs.append(df_fin)\n",
    "\n",
    "        # === Q&A Extraction + Sentiment ===\n",
    "        df_qna = extract_qna_long_format(full_path)\n",
    "        if not df_qna.empty:\n",
    "            # df_qna = add_finbert_sentiment(df_qna)\n",
    "            df_qna = add_dual_sentiment_models(df_qna)\n",
    "\n",
    "            all_qna_long_dfs.append(df_qna)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {filename}: {e}\")\n",
    "\n",
    "# === MERGE AND SAVE FINANCIAL DATA ===\n",
    "if all_financial_dfs:\n",
    "    df_fin_merged = pd.concat(all_financial_dfs, ignore_index=True)\n",
    "    fin_excel = os.path.join(output_folder, \"merged_financial_sentences_finbertonly.xlsx\")\n",
    "    fin_pickle = os.path.join(output_folder, \"merged_financial_sentences_finbertonly.pkl\")\n",
    "    df_fin_merged.to_excel(fin_excel, index=False)\n",
    "    df_fin_merged.to_pickle(fin_pickle)\n",
    "    print(f\"‚úÖ Financial data saved to:\\n- {fin_excel}\\n- {fin_pickle}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No financial sentences were extracted.\")\n",
    "\n",
    "# === MERGE AND SAVE Q&A DATA ===\n",
    "if all_qna_long_dfs:\n",
    "    df_qna_merged = pd.concat(all_qna_long_dfs, ignore_index=True)\n",
    "    qna_excel = os.path.join(output_folder, \"merged_qna_long_finbertonly.xlsx\")\n",
    "    qna_pickle = os.path.join(output_folder, \"merged_qna_long_finbertonly.pkl\")\n",
    "    df_qna_merged.to_excel(qna_excel, index=False)\n",
    "    df_qna_merged.to_pickle(qna_pickle)\n",
    "    print(f\"Q&A data saved to:\\n- {qna_excel}\\n- {qna_pickle}\")\n",
    "else:\n",
    "    print(\"No Q&A data extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56182246",
   "metadata": {
    "id": "g-p6-ylaFLPE"
   },
   "source": [
    "update ROBERTA labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856965b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1976,
     "status": "ok",
     "timestamp": 1750195841822,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "RxrBKYxwMYPm",
    "outputId": "07ccb2a6-5a0a-4d6b-e647-3423fbb12a4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Q&A sentiment labels updated.\n",
      "‚úÖ Financial sentiment labels updated.\n"
     ]
    }
   ],
   "source": [
    "# qna_excel = os.path.join(output_folder, \"merged_qna_long.xlsx\")\n",
    "# fin_excel = os.path.join(output_folder, \"merged_financial_sentences.xlsx\")\n",
    "\n",
    "# # Label map for RoBERTa\n",
    "# label_map = {\n",
    "#     \"LABEL_0\": \"NEGATIVE\",\n",
    "#     \"LABEL_1\": \"NEUTRAL\",\n",
    "#     \"LABEL_2\": \"POSITIVE\"\n",
    "# }\n",
    "\n",
    "# # === Q&A file update ===\n",
    "# df_qna = pd.read_excel(qna_excel)\n",
    "# if \"roberta_sentiment\" in df_qna.columns:\n",
    "#     df_qna[\"roberta_sentiment\"] = df_qna[\"roberta_sentiment\"].map(label_map).fillna(df_qna[\"roberta_sentiment\"])\n",
    "#     df_qna.to_excel(qna_excel, index=False)\n",
    "#     print(\"‚úÖ Q&A sentiment labels updated.\")\n",
    "\n",
    "# # === Financial file update ===\n",
    "# df_fin = pd.read_excel(fin_excel)\n",
    "# if \"roberta_sentiment\" in df_fin.columns:\n",
    "#     df_fin[\"roberta_sentiment\"] = df_fin[\"roberta_sentiment\"].map(label_map).fillna(df_fin[\"roberta_sentiment\"])\n",
    "#     df_fin.to_excel(fin_excel, index=False)\n",
    "#     print(\"‚úÖ Financial sentiment labels updated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03940979",
   "metadata": {
    "id": "s_3Szb0H1A-w"
   },
   "source": [
    "## Topic extraction installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14064d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1043,
     "status": "ok",
     "timestamp": 1750197218000,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "kfrRjOZF1ocl",
    "outputId": "fdf72005-727d-4afd-abc2-2a78dade4438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      " Codes\t\t\t\t'Presentation Documents'\n",
      " Data\t\t\t\t Project_Plan\n",
      "'Ideas and Research Documents'\t'Russell Hunter Notebooks'\n",
      " Meetings\t\t\t Video_presentation\n",
      "'Other Documents'\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')\n",
    "!ls '/content/drive/My Drive/BoE'\n",
    "\n",
    "output_folder = '/content/drive/My Drive/BoE/Data/Unicredit/extracted_outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c9901",
   "metadata": {
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1750197219921,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "iFmv7pk91uK0"
   },
   "outputs": [],
   "source": [
    "df_fin_merged = pd.read_excel(output_folder + \"merged_financial_sentences_finbertonly.xlsx\")\n",
    "df_qna_merged = pd.read_excel(output_folder + \"merged_qna_long_finbertonly.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9a2e51",
   "metadata": {
    "id": "FM9k-3t_1GLk"
   },
   "source": [
    "import more packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbc43e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7027,
     "status": "ok",
     "timestamp": 1750197228114,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "9MdbJ-MHMgcN",
    "outputId": "f4dee4d9-0dd4-4e60-b10e-d61306edd3a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keybert in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from keybert) (2.0.2)\n",
      "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.11/dist-packages (from keybert) (13.9.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.11/dist-packages (from keybert) (1.6.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (2.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (3.6.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert sentence-transformers nltk openpyxl\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b319a",
   "metadata": {
    "id": "yln2LepB1Jk_"
   },
   "source": [
    "## Topic extraction code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7294512",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317,
     "referenced_widgets": [
      "111f12b1d6994ea2aeae64f2d4814500",
      "a14fe5ecbe5e492584ba72b183ed3451",
      "65e87448f5524a4a937caf5b88b29325",
      "12e2de6362e0468d8e71616a6ef4b59d",
      "f3a14265af454088b6f0b4eef4b98de1",
      "854e0e0ef00345649af36450616c69a0",
      "873bd395ed2d4e32b33fce79a7e6b2c2",
      "a8311646d1814f45b89a35cf6753572b",
      "8528f2916aad4a18989220371485a0b1",
      "2e48d0c840874c24a3c95a9ad36a1de2",
      "db5dbf11c66a4c12a86f2d277db36cb3",
      "6a0367a975f74d889d62f94dbded0a7a",
      "53d4dbbb24d248a0aa760d8562dc159e",
      "fd702440568f499ea2dc3e3293094016",
      "9b4b1b2160874c1690de462fc084c809",
      "ae424350c5104ae8b3068aa2165ffd3c",
      "ad98a60e04b141fe87da35a3dc6831cc",
      "0c9e539dc27747c2bc4ac76c6065f471",
      "1351610d53b946de86faa26d6d961449",
      "51c8f9c31f7d42c08ef977ae65b91e40",
      "5d3e30772f094ffd8dd08917a353237b",
      "6c963754bbae44508eccbf88b6262687",
      "c4de2b5f241e406ab95eeb9f6b68098a",
      "475c8edcea1f42db98c325847220ce28",
      "6cd2e58d4bc7497bbe43a4778919de51",
      "02182811ab5f4b09bf640ed8b1bed83d",
      "2c2134d2a82d4356b9292aa4f4c5a71a",
      "b2b63786c9db422f8c4d3272ef7da679",
      "d74bf96517d448d58eec16d287729a17",
      "100e928ab597439c96a51bc3dd47d8de",
      "7527e18654874a8ab88bf74b4e0a84de",
      "d76af0c131184cd2ba26a763c02ea364",
      "8a89fc9d125647ef8870ddb630e6a3d6",
      "b78f20e08efd463cacb4ab329046be65",
      "fb33371fc075420eaad1f764df5ffedd",
      "f5fe2fa700b54e3791d54d9706de2387",
      "c586965593034dad9a91fd4db1757f07",
      "68633cc7f17945109604e5f1678b8c3f",
      "57f2f1a03f63495facc1a40f3538f561",
      "366d102908d541dc9de7341e69e3247f",
      "e1c290d70c4b4875bb177b810be6c472",
      "681014a6b4a4447797c51875412d8bfe",
      "92a40d69c87c42c0adf877617385c8bf",
      "192fde28d95a4271aa3bdf3934c15381",
      "9ba170b9845a40b6a0878f105366e84c",
      "3bc8cd92f53c46dd9304e70863e0b134",
      "7f82f2654e584eca8a64b352060510e6",
      "4817975f82ea4907a53e9161f1f7bb8e",
      "733e8ae9f28a4ad3a80d5e312d9cbc6e",
      "449c24e0c6dc4c59a7b2eae15f98ba2d",
      "4f8da2d66dfe41ff9fa6d90b137f2f72",
      "e3c226ad353d408aa108caa4ace3c8bc",
      "3b52bf73a1c34d54a07dbc0e100737e9",
      "7b20fc7541804490be8f8f198ca2dc5b",
      "23046cada3f048238a602af37a3ea30b",
      "046735c00b9842d5a9dcbabbca252972",
      "d26aad7087534ba0a75cfcf31b6e3202",
      "91e62df2bb724137a694947c058a3c8b",
      "62c343c14b9b4c2cbd8190c6c13d12b3",
      "5fa485841fda493885639a16e8481a74",
      "e0b0d4d7faed40d29e158ab295ccfc10",
      "e769aa3464bb43b7b4309addc8cfd6fc",
      "10d4bf1ac2014dd4adce7b21fdd25ca0",
      "5e7b9f105b5d40a393f23275f2885551",
      "6c27f4683db2434ab69b1dc985456539",
      "24a3c2e4238241ab96b25c46fc4f3b0f"
     ]
    },
    "executionInfo": {
     "elapsed": 4900,
     "status": "ok",
     "timestamp": 1750199556764,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "gt1saXs33JjP",
    "outputId": "ae87257b-d40f-487f-ddfa-0f4139a7e217"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111f12b1d6994ea2aeae64f2d4814500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0367a975f74d889d62f94dbded0a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4de2b5f241e406ab95eeb9f6b68098a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78f20e08efd463cacb4ab329046be65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba170b9845a40b6a0878f105366e84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046735c00b9842d5a9dcbabbca252972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download required resources\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Load custom embedding model\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "kw_model = KeyBERT(model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d559f99b",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1750199559250,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "7gcdEXt91REl"
   },
   "outputs": [],
   "source": [
    "# Function words\n",
    "function_stopwords = [\n",
    "    \"we\", \"have\", \"has\", \"had\", \"were\", \"was\", \"are\", \"is\", \"it's\", \"its\", \"being\", \"been\",\n",
    "    \"do\", \"does\", \"doing\", \"did\", \"can\", \"may\", \"might\", \"come\", \"comes\", \"going\"\n",
    "]\n",
    "\n",
    "qa_filler_phrases = [\n",
    "    \"thanks\", \"thank you\", \"appreciate\", \"question\", \"questions\", \"ask\", \"asking\", \"follow-up\",\n",
    "    \"couple of questions\", \"good morning\", \"good afternoon\", \"hello\", \"thanks for taking my question\",\n",
    "    \"thanks for the call\", \"thank you for your time\", \"joining us\", \"line is open\", \"line\",\n",
    "    \"hand over\", \"presentation\", \"prepared remarks\", \"pick up with team\", \"management remarks\",\n",
    "    \"closing remarks\", \"just wondering\", \"can you talk a bit more about\", \"could you elaborate\",\n",
    "    \"as you mentioned\", \"as you said\", \"i guess\", \"i wonder if\", \"may i ask\", \"i was going to ask\",\n",
    "    \"one more question\", \"a quick clarification\", \"sorry to go on\", \"very helpful\", \"hope that makes sense\", \"indiscernible\",\n",
    "    \"Andrea\", \"Stefano\", \"yes\", \"discussed\", \"tkank you\", \"very much\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Combine all stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "base_stopwords = set(stopwords.words(\"english\"))\n",
    "domain_stopwords = set(qa_filler_phrases  + function_stopwords)\n",
    "all_stopwords = base_stopwords.union(domain_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f23a4e",
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1750199560883,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "3YiMqWvd2FU2"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Lowercase and remove special characters\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text.lower())\n",
    "    words = text.split()\n",
    "    # Lemmatize and remove stopwords\n",
    "    clean_words = [\n",
    "        lemmatizer.lemmatize(w)\n",
    "        for w in words\n",
    "        if w not in all_stopwords and len(w) > 2\n",
    "    ]\n",
    "    return \" \".join(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a0e16c",
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1750199640215,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "eJuw87091i2X"
   },
   "outputs": [],
   "source": [
    "def add_topic_keywords(df, text_column=\"text\", top_n=3):\n",
    "    cleaned_texts = df[text_column].fillna(\"\").astype(str).apply(clean_text)\n",
    "    topics = []\n",
    "\n",
    "    for text in tqdm(cleaned_texts, desc=f\"Extracting topics for '{text_column}'\", unit=\"row\"):\n",
    "        try:\n",
    "            keywords = kw_model.extract_keywords(\n",
    "                text,\n",
    "                keyphrase_ngram_range=(1, 2),\n",
    "                stop_words=None,\n",
    "                top_n=top_n\n",
    "            )\n",
    "            topic_list = [kw[0] for kw in keywords]\n",
    "            topics.append(\", \".join(topic_list))\n",
    "        except Exception:\n",
    "            topics.append(\"ERROR\")\n",
    "\n",
    "    df[\"topics\"] = topics\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee6dc14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 544771,
     "status": "ok",
     "timestamp": 1750200204171,
     "user": {
      "displayName": "Daniela M",
      "userId": "02301051653591946910"
     },
     "user_tz": -60
    },
    "id": "vku_DJ2N3Yc9",
    "outputId": "456d0e4b-c222-4ddf-8257-5bf518b377b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting topics for 'text': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1815/1815 [06:01<00:00,  5.03row/s]\n",
      "Extracting topics for 'text': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 205/205 [03:02<00:00,  1.12row/s]\n"
     ]
    }
   ],
   "source": [
    "df_fin_topic= add_topic_keywords(df_fin_merged, text_column=\"text\")\n",
    "df_qna_topic = add_topic_keywords(df_qna_merged, text_column=\"text\")\n",
    "\n",
    "\n",
    "df_qna_topic.to_excel(output_folder + 'qna_topics.xlsx', index=False)\n",
    "df_qna_topic.to_pickle(output_folder +  'qna_topics.pkl')\n",
    "\n",
    "df_fin_topic.to_excel(output_folder + 'financial_topics.xlsx', index=False)\n",
    "df_fin_topic.to_pickle(output_folder + 'financial_topics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e6805",
   "metadata": {
    "id": "xq1CS6fgE_Cl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
