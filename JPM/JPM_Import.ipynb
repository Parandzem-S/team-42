{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-KxU_mSrHsp"
      },
      "source": [
        "Input JP Morgan files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "W41v4OtHrAm7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PyPDF2 import PdfReader\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "#import openai\n",
        "#from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import re, json, time, os, sys, glob\n",
        "from typing import Dict, List, Tuple\n",
        "from dataclasses import dataclass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Ys2qNakDrgkU"
      },
      "outputs": [],
      "source": [
        "# Configuration\n",
        "@dataclass\n",
        "class Config:\n",
        "    openai_api_key: str = os.environ[\"OPENAI_API_KEY\"]\n",
        "    ticker: str = \"JPM\"\n",
        "    quarters: List[str] = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.quarters is None:\n",
        "            self.quarters = [\"2024Q4\", \"2025Q1\"]\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "U7xHlcu33AFc"
      },
      "outputs": [],
      "source": [
        "# get the pdf file https://drive.google.com/drive/folders/1fzSQl9zgYXVGVVNEJjW0UZkqS7PtJ3Tm\n",
        "def extract_pdf_text(file_name, base_path='JPM Presentation texts/2025/Q1'):\n",
        "    \"\"\"\n",
        "    Extract text from a PDF file in Google Drive\n",
        "\n",
        "    Args:\n",
        "        file_name (str): Name of the PDF file\n",
        "        base_path (str): Base path to the file location\n",
        "\n",
        "    Returns:\n",
        "        str: Extracted text from the PDF\n",
        "    \"\"\"\n",
        "\n",
        "    # Construct full file path\n",
        "    pdf_path = os.path.join(base_path, file_name)\n",
        "\n",
        "    # Check if file exists\n",
        "    if not os.path.exists(pdf_path):\n",
        "        print(f\"Error: File not found at {pdf_path}\")\n",
        "        print(\"Available files in directory:\")\n",
        "        try:\n",
        "            print(os.listdir(base_path))\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Directory {base_path} not found\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as f:\n",
        "            pdf_reader = PdfReader(f)\n",
        "\n",
        "            # Get number of pages\n",
        "            num_pages = len(pdf_reader.pages)\n",
        "            print(f\"Successfully loaded PDF: {file_name}\")\n",
        "            print(f\"Number of pages: {num_pages}\")\n",
        "\n",
        "            # Extract text from all pages more efficiently\n",
        "            full_text = \"\\n\".join(\n",
        "                page.extract_text()\n",
        "                for page in pdf_reader.pages\n",
        "            )\n",
        "\n",
        "            return full_text\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Could not find file {pdf_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDF: {str(e)}\")\n",
        "        return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "JinoSujvB8gi"
      },
      "outputs": [],
      "source": [
        "def separate_presentation_and_qa(text):\n",
        "    \"\"\"\n",
        "    Separate the presentation text from Q&A section in earnings transcript\n",
        "\n",
        "    Args:\n",
        "        text (str): Full transcript text\n",
        "\n",
        "    Returns:\n",
        "        tuple: (presentation_text, qa_text)\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return None, None\n",
        "\n",
        "    # Common patterns that indicate start of Q&A section\n",
        "    qa_patterns = [\n",
        "        r\"(?i)questions?\\s*(?:and|&)\\s*answers?\",\n",
        "        r\"(?i)q\\s*(?:and|&)\\s*a\",\n",
        "        r\"(?i)question\\s*(?:and|&)\\s*answer\\s*session\",\n",
        "        r\"(?i)we\\s*(?:will\\s*)?now\\s*(?:begin|start|open)\\s*(?:the\\s*)?(?:question|q)\",\n",
        "        r\"(?i)(?:now\\s*)?(?:let'?s\\s*)?(?:begin|start|open)\\s*(?:the\\s*)?(?:question|qa)\",\n",
        "        r\"(?i)(?:we\\s*)?(?:will\\s*)?now\\s*take\\s*questions?\",\n",
        "        r\"(?i)(?:let'?s\\s*)?(?:begin|start|open)\\s*(?:with\\s*)?(?:the\\s*)?(?:first\\s*)?question\",\n",
        "        r\"(?i)analyst\\s*questions?\",\n",
        "        r\"(?i)thank\\s*you.*(?:question|qa)\",\n",
        "        #r\"(?i)(?:first\\s*)?(?:question\\s*)?(?:is\\s*)?from\\s*\\w+\",\n",
        "        r\"(?i)our\\s*first\\s*(?:question|analyst)\"\n",
        "    ]\n",
        "\n",
        "    # Find the earliest Q&A indicator\n",
        "    qa_start_pos = len(text)  # Start with end of text\n",
        "    matched_pattern = None\n",
        "\n",
        "    for pattern in qa_patterns:\n",
        "        matches = list(re.finditer(pattern, text))\n",
        "        if matches:\n",
        "            # Take the first match for this pattern\n",
        "            first_match_pos = matches[0].start()\n",
        "            if first_match_pos < qa_start_pos:\n",
        "                qa_start_pos = first_match_pos\n",
        "                matched_pattern = pattern\n",
        "\n",
        "    # If no Q&A section found, return entire text as presentation\n",
        "    if qa_start_pos == len(text):\n",
        "        print(\"No Q&A section found. Entire text treated as presentation.\")\n",
        "        return text.strip(), \"\"\n",
        "\n",
        "    # Split the text\n",
        "    presentation_text = text[:qa_start_pos].strip()\n",
        "    qa_text = text[qa_start_pos:].strip()\n",
        "\n",
        "    print(f\"Q&A section detected using pattern: {matched_pattern}\")\n",
        "    print(f\"Presentation text: {len(presentation_text):,} characters\")\n",
        "    print(f\"Q&A text: {len(qa_text):,} characters\")\n",
        "\n",
        "    return presentation_text, qa_text\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Clean up extracted text by removing extra whitespace and formatting issues\n",
        "\n",
        "    Args:\n",
        "        text (str): Raw text to clean\n",
        "\n",
        "    Returns:\n",
        "        str: Cleaned text\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "\n",
        "    # Remove excessive whitespace\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)  # Multiple newlines to double newline\n",
        "    text = re.sub(r' {2,}', ' ', text)  # Multiple spaces to single space\n",
        "    text = re.sub(r'\\t', ' ', text)  # Tabs to spaces\n",
        "    text = re.sub(r'\\.{20,}', '', text) # Remove the dotted line separators\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "jVVZVhoAxaJ4"
      },
      "outputs": [],
      "source": [
        "def clean_speaker_name(name):\n",
        "    \"\"\"Clean and standardize speaker names\"\"\"\n",
        "    if not name:\n",
        "        return \"\"\n",
        "\n",
        "    # Remove common prefixes and suffixes\n",
        "    name = re.sub(r'^(Mr\\.?|Ms\\.?|Mrs\\.?|Dr\\.?)\\s*', '', name, flags=re.IGNORECASE)\n",
        "    name = re.sub(r'\\s*[-–—]\\s*.*$', '', name)  # Remove everything after dash\n",
        "    name = re.sub(r'\\s*,.*$', '', name)  # Remove everything after comma\n",
        "    name = re.sub(r'\\s+', ' ', name).strip()  # Clean whitespace\n",
        "\n",
        "    return name\n",
        "\n",
        "def identify_questioner(question_text):\n",
        "    \"\"\"Extract questioner name from question text\"\"\"\n",
        "    # Common patterns for questioner identification\n",
        "    patterns = [\n",
        "        r'(?:question\\s+(?:is\\s+)?from\\s+|from\\s+)([A-Za-z\\s\\.]+?)(?:\\s+at\\s+|\\s+with\\s+|\\s+from\\s+|\\.|,|$)',\n",
        "        r'([A-Za-z\\s\\.]+?)(?:\\s+at\\s+|\\s+with\\s+|\\s+from\\s+)([A-Za-z\\s&\\.]+?)(?:\\.|,|:|\\s*$)',\n",
        "        r'^([A-Za-z\\s\\.]+?)(?:\\s*[-–—]\\s*|\\s*:\\s*)',\n",
        "        r'analyst\\s+([A-Za-z\\s\\.]+?)(?:\\s+asks?|\\s*:|\\s*$)',\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, question_text, re.IGNORECASE)\n",
        "        if match:\n",
        "            name = clean_speaker_name(match.group(1))\n",
        "            if len(name) > 2 and len(name.split()) <= 4:  # Reasonable name length\n",
        "                return name\n",
        "\n",
        "    return \"Unknown\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "TxRP37Bbxn_h"
      },
      "outputs": [],
      "source": [
        "def parse_qa_section(qa_text):\n",
        "    \"\"\"\n",
        "    Parse Q&A section into structured data\n",
        "    Returns list of dictionaries with question/answer data\n",
        "    \"\"\"\n",
        "    if not qa_text:\n",
        "        return []\n",
        "\n",
        "    qa_data = []\n",
        "    question_no = 1\n",
        "    # Split by common question indicators\n",
        "    question_splits = re.split(\n",
        "        r'(?i)(?:^|\\n)\\s*(?:'\n",
        "        r'(?:next\\s+|first\\s+)?question\\s+(?:is\\s+)?from\\s+|'\n",
        "        r'(?:our\\s+)?(?:next\\s+)?question\\s+(?:comes\\s+)?from\\s+|'\n",
        "        r'analyst\\s+\\w+|'\n",
        "        r'question\\s*:|'\n",
        "        r'q\\s*:|'\n",
        "        r'Q\\s*:|'\n",
        "        r'unidentified\\s+(?:analyst|participant)'\n",
        "        r')',\n",
        "        qa_text\n",
        "    )\n",
        "\n",
        "    for i, section in enumerate(question_splits[1:], 1):  # Skip first split (usually empty or intro)\n",
        "        if not section.strip():\n",
        "            continue\n",
        "\n",
        "        # Extract questioner name\n",
        "        questioner = identify_questioner(section)\n",
        "\n",
        "        # Split section into question and answer parts\n",
        "        # Look for answer indicators\n",
        "        answer_patterns = [\n",
        "            r'(?i)(?:^|\\n)\\s*([A-Za-z\\s\\.]+?)\\s*[-–—]\\s*',  # Name followed by dash\n",
        "            r'(?i)(?:^|\\n)\\s*([A-Za-z\\s\\.]+?)\\s*:\\s*',      # Name followed by colon\n",
        "            r'(?i)(?:^|\\n)\\s*([A-Za-z\\s\\.]+?)\\s*A\\s*',      # Name followed by A\n",
        "            r'(?i)(?:^|\\n)\\s*(Thank\\s+you|Thanks)',         # Thank you responses\n",
        "        ]\n",
        "\n",
        "        # Find where answers start\n",
        "        answer_start = len(section)\n",
        "        for pattern in answer_patterns:\n",
        "            matches = list(re.finditer(pattern, section))\n",
        "            if matches:\n",
        "                # Take the first answer indicator\n",
        "                first_match = matches[0]\n",
        "                answer_start = min(answer_start, first_match.start())\n",
        "\n",
        "        # Extract question text\n",
        "        question_text = section[:answer_start].strip()\n",
        "\n",
        "        # Clean question text\n",
        "        question_text = re.sub(r'^.*?(?:question\\s+(?:is\\s+)?from\\s+.*?)[.:]?\\s*', '', question_text, flags=re.IGNORECASE)\n",
        "        question_text = re.sub(r'^\\s*[-–—]\\s*', '', question_text)\n",
        "        question_text = question_text.strip()\n",
        "\n",
        "         # Extract answer section\n",
        "        answer_section = section[answer_start:].strip()\n",
        "\n",
        "        # Parse answers and answerers\n",
        "        answerers = []\n",
        "        answers = []\n",
        "        full_answer_parts = []\n",
        "        if answer_section:\n",
        "            # Split by speaker changes\n",
        "            speaker_splits = re.split(\n",
        "                r'(?i)(?:^|\\n)\\s*([A-Za-z\\s\\.]+?)\\s*(?:[-–—]|:)\\s*',\n",
        "                answer_section\n",
        "            )\n",
        "\n",
        "            current_speaker = None\n",
        "            current_answer = \"\"\n",
        "\n",
        "            for j, part in enumerate(speaker_splits):\n",
        "                if j % 2 == 1:  # Odd indices are speaker names\n",
        "                    # Save previous speaker's answer\n",
        "                    if current_speaker and current_answer.strip():\n",
        "                        answerers.append(clean_speaker_name(current_speaker))\n",
        "                        answers.append(current_answer.strip())\n",
        "                        full_answer_parts.append(current_answer.strip())\n",
        "\n",
        "                    current_speaker = part\n",
        "                    current_answer = \"\"\n",
        "                else:  # Even indices are answer content\n",
        "                    current_answer = part.strip()\n",
        "\n",
        "            # Don't forget the last speaker\n",
        "            if current_speaker and current_answer.strip():\n",
        "                answerers.append(clean_speaker_name(current_speaker))\n",
        "                answers.append(current_answer.strip())\n",
        "                full_answer_parts.append(current_answer.strip())\n",
        "\n",
        "            # If no speakers found, treat entire answer section as one answer\n",
        "            if not answerers and answer_section.strip():\n",
        "                answerers.append(\"Unknown\")\n",
        "                answers.append(answer_section.strip())\n",
        "                full_answer_parts.append(answer_section.strip())\n",
        "\n",
        "        # Create JSON structures\n",
        "        answerers_json = json.dumps(answerers) if answerers else \"[]\"\n",
        "        answers_dict = {}\n",
        "        for idx, (answerer, answer) in enumerate(zip(answerers, answers)):\n",
        "            answers_dict[answerer] = answer\n",
        "        answers_json = json.dumps(answers_dict)\n",
        "\n",
        "        full_answer = \" \".join(full_answer_parts)\n",
        "\n",
        "        # Only add if we have a meaningful question\n",
        "        if question_text and len(question_text) > 10:\n",
        "            qa_data.append({\n",
        "                'Question_No': question_no,\n",
        "                'Questioner': questioner,\n",
        "                'Question': question_text,\n",
        "                'Answerers_Json': answerers_json,\n",
        "                'Answers_Json': answers_json,\n",
        "                'Full_Answer': full_answer\n",
        "            })\n",
        "            question_no += 1\n",
        "\n",
        "    return qa_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_jmjNTlbyi1e"
      },
      "outputs": [],
      "source": [
        "def create_qa_dataframe(qa_data):\n",
        "    \"\"\"Create DataFrame from Q&A data\"\"\"\n",
        "    if not qa_data:\n",
        "        print(\"No Q&A data found to create DataFrame\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    df = pd.DataFrame(qa_data)\n",
        "\n",
        "    print(f\"Created DataFrame with {len(df)} questions\")\n",
        "    print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "5va0T7gOy2wh"
      },
      "outputs": [],
      "source": [
        "def save_to_excel(df, base_path='output', filename=\"jpmorgan_qa_analysis.xlsx\"):\n",
        "    \"\"\"Save DataFrame to Excel file with formatting\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"DataFrame is empty, nothing to save\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Create Excel writer object\n",
        "        file = os.path.join(base_path, filename)\n",
        "        with pd.ExcelWriter(file, engine='openpyxl') as writer:\n",
        "            # Write main data\n",
        "            df.to_excel(writer, sheet_name='Q&A Analysis', index=False)\n",
        "\n",
        "            # Get the workbook and worksheet\n",
        "            workbook = writer.book\n",
        "            worksheet = writer.sheets['Q&A Analysis']\n",
        "\n",
        "            # Auto-adjust column widths\n",
        "            for column in worksheet.columns:\n",
        "                max_length = 0\n",
        "                column_letter = column[0].column_letter\n",
        "\n",
        "                for cell in column:\n",
        "                    try:\n",
        "                        if len(str(cell.value)) > max_length:\n",
        "                            max_length = len(str(cell.value))\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                adjusted_width = min(max_length + 2, 50)  # Cap at 50 characters\n",
        "                worksheet.column_dimensions[column_letter].width = adjusted_width\n",
        "\n",
        "            # Create summary sheet\n",
        "            summary_data = {\n",
        "                'Metric': [\n",
        "                    'Total Questions',\n",
        "                    'Unique Questioners',\n",
        "                    'Total Answerers',\n",
        "                    'Average Question Length',\n",
        "                    'Average Answer Length'\n",
        "                ],\n",
        "                'Value': [\n",
        "                    len(df),\n",
        "                    df['Questioner'].nunique(),\n",
        "                    len(set([name for names_json in df['Answerers_Json'] for name in json.loads(names_json)])),\n",
        "                    df['Question'].str.len().mean(),\n",
        "                    df['Full_Answer'].str.len().mean()\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            summary_df = pd.DataFrame(summary_data)\n",
        "            summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "        print(f\"Successfully saved Q&A analysis to: {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving to Excel: {str(e)}\")\n",
        "        # Fallback to CSV\n",
        "        csv_filename = filename.replace('.xlsx', '.csv')\n",
        "        df.to_csv(csv_filename, index=False)\n",
        "        print(f\"Saved as CSV instead: {csv_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ArtgBVTYzSr3"
      },
      "outputs": [],
      "source": [
        "def analyze_qa_dataframe(df):\n",
        "    \"\"\"Provide analysis of the Q&A DataFrame\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"No data to analyze\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Q&A ANALYSIS SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"Total Questions: {len(df)}\")\n",
        "    print(f\"Unique Questioners: {df['Questioner'].nunique()}\")\n",
        "\n",
        "    # Top questioners\n",
        "    top_questioners = df['Questioner'].value_counts().head(5)\n",
        "    print(f\"\\nTop Questioners:\")\n",
        "    for questioner, count in top_questioners.items():\n",
        "        print(f\"  {questioner}: {count} questions\")\n",
        "\n",
        "    # Answer statistics\n",
        "    all_answerers = []\n",
        "    for answerers_json in df['Answerers_Json']:\n",
        "        all_answerers.extend(json.loads(answerers_json))\n",
        "\n",
        "    answerer_counts = pd.Series(all_answerers).value_counts()\n",
        "    print(f\"\\nTop Answerers:\")\n",
        "    for answerer, count in answerer_counts.head(5).items():\n",
        "        print(f\"  {answerer}: {count} answers\")\n",
        "\n",
        "    # Length statistics\n",
        "    print(f\"\\nQuestion Length Statistics:\")\n",
        "    print(f\"  Average: {df['Question'].str.len().mean():.0f} characters\")\n",
        "    print(f\"  Median: {df['Question'].str.len().median():.0f} characters\")\n",
        "\n",
        "    print(f\"\\nAnswer Length Statistics:\")\n",
        "    print(f\"  Average: {df['Full_Answer'].str.len().mean():.0f} characters\")\n",
        "    print(f\"  Median: {df['Full_Answer'].str.len().median():.0f} characters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Nmwz2-AWCIfF"
      },
      "outputs": [],
      "source": [
        "def save_sections_to_files(presentation_text, qa_text, base_path='output', base_filename=\"jpmorgan_earnings\"):\n",
        "    \"\"\"\n",
        "    Save presentation and Q&A sections to separate files\n",
        "\n",
        "    Args:\n",
        "        presentation_text (str): Presentation section text\n",
        "        qa_text (str): Q&A section text\n",
        "        base_filename (str): Base filename for output files\n",
        "    \"\"\"\n",
        "    # Save presentation section\n",
        "    presentation_file_name = f\"{base_filename}_presentation.txt\"\n",
        "    presentation_file = os.path.join(base_path, presentation_file_name)\n",
        "    os.makedirs(os.path.dirname(presentation_file), exist_ok=True)\n",
        "    print(f\"Open presentation file {presentation_file}\")\n",
        "    with open(presentation_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(presentation_text)\n",
        "    print(f\"Presentation section saved to: {presentation_file}\")\n",
        "\n",
        "    # Save Q&A section\n",
        "    qa_file_name = f\"{base_filename}_qa.txt\"\n",
        "    qa_file = os.path.join(base_path, qa_file_name)\n",
        "    with open(qa_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(qa_text)\n",
        "    print(f\"Q&A section saved to: {qa_file}\")\n",
        "\n",
        "    return presentation_file, qa_file\n",
        "\n",
        "def analyze_sections(presentation_text, qa_text):\n",
        "    \"\"\"\n",
        "    Provide basic analysis of the separated sections\n",
        "\n",
        "    Args:\n",
        "        presentation_text (str): Presentation section text\n",
        "        qa_text (str): Q&A section text\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SECTION ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if presentation_text:\n",
        "        print(f\"Presentation Section:\")\n",
        "        print(f\"  - Characters: {len(presentation_text):,}\")\n",
        "        print(f\"  - Words (approx): {len(presentation_text.split()):,}\")\n",
        "        print(f\"  - Lines: {len(presentation_text.splitlines()):,}\")\n",
        "        print(f\"  - Preview: {presentation_text[:100]}...\")\n",
        "\n",
        "    if qa_text:\n",
        "        print(f\"\\nQ&A Section:\")\n",
        "        print(f\"  - Characters: {len(qa_text):,}\")\n",
        "        print(f\"  - Words (approx): {len(qa_text.split()):,}\")\n",
        "        print(f\"  - Lines: {len(qa_text.splitlines()):,}\")\n",
        "\n",
        "        # Count questions (rough estimate)\n",
        "        question_patterns = [r'\\?', r'(?i)question', r'(?i)analyst']\n",
        "        total_questions = sum(len(re.findall(pattern, qa_text)) for pattern in question_patterns)\n",
        "        print(f\"  - Estimated questions: {total_questions}\")\n",
        "\n",
        "        print(f\"  - Preview: {qa_text[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Extracting text from PDF...\n",
            "Successfully loaded PDF: JPM_1q25-earnings-transcript.pdf\n",
            "Number of pages: 21\n"
          ]
        }
      ],
      "source": [
        "# Extract text from PDF\n",
        "print(\"Step 1: Extracting text from PDF...\")\n",
        "file_name = \"JPM_1q25-earnings-transcript.pdf\"\n",
        "full_text = extract_pdf_text(file_name)\n",
        "if not full_text:\n",
        "    print(\"Failed to extract text from PDF\")\n",
        "    sys.exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Extracting text from PDF...\n",
            "Successfully loaded PDF: JPM_1q25-earnings-transcript.pdf\n",
            "Number of pages: 21\n"
          ]
        }
      ],
      "source": [
        "# Extract text from PDF\n",
        "print(\"Step 1: Extracting text from PDF...\")\n",
        "file_name = \"JPM_1q25-earnings-transcript.pdf\"\n",
        "full_text = extract_pdf_text(file_name)\n",
        "if not full_text:\n",
        "    print(\"Failed to extract text from PDF\")\n",
        "    sys.exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Step 2: Separating presentation and Q&A sections...\n",
            "Q&A section detected using pattern: (?i)q\\s*(?:and|&)\\s*a\n",
            "Presentation text: 11,497 characters\n",
            "Q&A text: 90,153 characters\n",
            "\n",
            "Saving sections to files...\n",
            "Open presentation file output\\jpmorgan_earnings_presentation.txt\n",
            "Presentation section saved to: output\\jpmorgan_earnings_presentation.txt\n",
            "Q&A section saved to: output\\jpmorgan_earnings_qa.txt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('output\\\\jpmorgan_earnings_presentation.txt',\n",
              " 'output\\\\jpmorgan_earnings_qa.txt')"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Separate presentation and Q&A\n",
        "print(\"\\nStep 2: Separating presentation and Q&A sections...\")\n",
        "presentation_text, qa_text = separate_presentation_and_qa(full_text)\n",
        "presentation_text = clean_text(presentation_text)\n",
        "qa_text = clean_text(qa_text)\n",
        "# Save to separate files\n",
        "print(\"\\nSaving sections to files...\")\n",
        "save_sections_to_files(presentation_text, qa_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "SECTION ANALYSIS\n",
            "============================================================\n",
            "Presentation Section:\n",
            "  - Characters: 10,871\n",
            "  - Words (approx): 1,706\n",
            "  - Lines: 130\n",
            "  - Preview: 1Q25 FINANCIAL RESULTS \n",
            "EARNINGS CALL TRANSCRIPT \n",
            "April 11, 2025 \n",
            "\n",
            " NOVEMBER 2024 \n",
            "\n",
            " 1 \n",
            "MANAGEMENT D...\n",
            "\n",
            "Q&A Section:\n",
            "  - Characters: 55,486\n",
            "  - Words (approx): 9,512\n",
            "  - Lines: 837\n",
            "  - Estimated questions: 138\n",
            "  - Preview: Q&A. \n",
            " \n",
            "QUESTION AND ANSWER SECTION \n",
            "\n",
            "Operator : Thank you. Please stand by. Our first question come...\n",
            "\n",
            "Step 3: Parsing Q&A section...\n"
          ]
        }
      ],
      "source": [
        "# Analyze the sections\n",
        "analyze_sections(presentation_text, qa_text)\n",
        "\n",
        "# Parse Q&A section\n",
        "print(\"\\nStep 3: Parsing Q&A section...\")\n",
        "qa_data = parse_qa_section(qa_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Step 4: Creating Q&A DataFrame...\n",
            "1 No structured Q&A data could be extracted\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[1;31mSystemExit\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Create DataFrame\n",
        "print(\"\\nStep 4: Creating Q&A DataFrame...\")\n",
        "if len(qa_data) == 0:\n",
        "    print(\"1 No structured Q&A data could be extracted\")\n",
        "    sys.exit() \n",
        "\n",
        "df = create_qa_dataframe(qa_data)\n",
        "\n",
        "if df.empty:\n",
        "    print(\"2 No structured Q&A data could be extracted\")\n",
        "    sys.exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crW8PwdgCKSR",
        "outputId": "66b44a09-5047-4ce2-c1e9-8f8e3b754a33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Extracting text from PDF...\n",
            "Successfully loaded PDF: JPM_1q25-earnings-transcript.pdf\n",
            "Number of pages: 21\n",
            "\n",
            "Step 2: Separating presentation and Q&A sections...\n",
            "Q&A section detected using pattern: (?i)(?:first\\s*)?(?:question\\s*)?(?:is\\s*)?from\\s*\\w+\n",
            "Presentation text: 2,026 characters\n",
            "Q&A text: 99,624 characters\n",
            "\n",
            "Saving sections to files...\n",
            "Open presentation file output\\jpmorgan_earnings_presentation.txt\n",
            "Presentation section saved to: output\\jpmorgan_earnings_presentation.txt\n",
            "Q&A section saved to: output\\jpmorgan_earnings_qa.txt\n",
            "\n",
            "============================================================\n",
            "SECTION ANALYSIS\n",
            "============================================================\n",
            "Presentation Section:\n",
            "  - Characters: 1,993\n",
            "  - Words (approx): 226\n",
            "  - Lines: 24\n",
            "  - Preview: 1Q25 FINANCIAL RESULTS \n",
            "EARNINGS CALL TRANSCRIPT \n",
            "April 11, 2025 \n",
            "\n",
            " NOVEMBER 2024 \n",
            "\n",
            " 1 \n",
            "MANAGEMENT D...\n",
            "\n",
            "Q&A Section:\n",
            "  - Characters: 99,364\n",
            "  - Words (approx): 11,117\n",
            "  - Lines: 943\n",
            "  - Estimated questions: 138\n",
            "  - Preview: from prior quarters, as well \n",
            "as higher wholesale deposits. NIR ex. Markets was up $2.2 billion, or ...\n",
            "\n",
            "Step 3: Parsing Q&A section...\n",
            "\n",
            "Step 4: Creating Q&A DataFrame...\n",
            "No Q&A data found to create DataFrame\n",
            "No structured Q&A data could be extracted\n",
            "\n",
            "Step 5: Analyzing DataFrame...\n",
            "No data to analyze\n",
            "\n",
            "Step 6: Saving to Excel...\n",
            "DataFrame is empty, nothing to save\n",
            "\n",
            "Sample of extracted data:\n",
            "============================================================\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "\n",
        "# Analyze DataFrame\n",
        "print(\"\\nStep 5: Analyzing DataFrame...\")\n",
        "analyze_qa_dataframe(df)\n",
        "\n",
        "# Save to Excel\n",
        "print(\"\\nStep 6: Saving to Excel...\")\n",
        "save_to_excel(df)\n",
        "\n",
        "# Display sample data\n",
        "print(\"\\nSample of extracted data:\")\n",
        "print(\"=\"*60)\n",
        "if len(df) > 0:\n",
        "    sample_row = df.iloc[0]\n",
        "    print(f\"Question 1:\")\n",
        "    print(f\"  Questioner: {sample_row['Questioner']}\")\n",
        "    print(f\"  Question: {sample_row['Question'][:200]}...\")\n",
        "    print(f\"  Answerers: {sample_row['Answerers_Json']}\")\n",
        "    print(f\"  Full Answer: {sample_row['Full_Answer'][:200]}...\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
