{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluate earnings transcipts for signals of financial distress\n",
        "\n",
        "Code by Geoff"
      ],
      "metadata": {
        "id": "SwWuK1ttZYmp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Hs9ZowQIZEkb"
      },
      "outputs": [],
      "source": [
        "install_flag = False\n",
        "if install_flag:\n",
        "  !pip install python-docx\n",
        "  !pip install transformers\n",
        "  !pip install torch\n",
        "  !pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, json, os, re\n",
        "import pandas as pd\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import List, Dict, Any, Optional\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import openai\n",
        "import requests\n",
        "from dataclasses import dataclass\n",
        "import openpyxl\n",
        "from google.colab import userdata, drive\n",
        "# Mount Google Drive (safe to call multiple times)\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU6TFEBTZlW1",
        "outputId": "7aa889bc-b447-44d4-9bf8-0789cd32333e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class AnalysisResult:\n",
        "    \"\"\"Data structure to hold analysis results\"\"\"\n",
        "    prompt_name: str\n",
        "    category: str\n",
        "    keywords_found: List[str]\n",
        "    context_matches: List[str]\n",
        "    confidence_score: float\n",
        "    reasoning: str\n",
        "    source_file: str"
      ],
      "metadata": {
        "id": "ayrzdVLlZtyJ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LLMProvider(ABC):\n",
        "    \"\"\"Abstract base class for LLM providers\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def analyze_text(self, prompt: str, text: str) -> str:\n",
        "        \"\"\"Analyze text using the specific LLM\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_provider_name(self) -> str:\n",
        "        \"\"\"Return the name of the LLM provider\"\"\"\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "m3rPdgbPZveY"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ChatGPTProvider(LLMProvider):\n",
        "    \"\"\"ChatGPT implementation of LLM provider\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str, model: str = \"gpt-4\"):\n",
        "        self.client = openai.OpenAI(api_key=api_key)\n",
        "        self.model = model\n",
        "\n",
        "    def analyze_text(self, prompt: str, text: str) -> str:\n",
        "        \"\"\"Analyze text using ChatGPT\"\"\"\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a financial analyst expert in detecting signs of financial distress in banking institutions.\"},\n",
        "                    {\"role\": \"user\", \"content\": f\"{prompt}\\n\\nText to analyze:\\n{text}\"}\n",
        "                ],\n",
        "                max_tokens=1000,\n",
        "                temperature=0.1\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            return f\"Error analyzing with ChatGPT: {str(e)}\"\n",
        "\n",
        "    def get_provider_name(self) -> str:\n",
        "        return \"ChatGPT\"\n"
      ],
      "metadata": {
        "id": "X121ExjbavQJ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Phi4Provider(LLMProvider):\n",
        "    \"\"\"Phi4 implementation of LLM provider\"\"\"\n",
        "\n",
        "    def __init__(self, method, model_name, device: Optional[str] = None):\n",
        "                # Setup device\n",
        "        if device is None:\n",
        "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        else:\n",
        "            self.device = device\n",
        "\n",
        "        self.method = method\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "        # Load model with appropriate settings\n",
        "        model_kwargs = {\n",
        "            \"trust_remote_code\": True,\n",
        "            \"torch_dtype\": torch.float16 if self.device == \"cuda\" else torch.float32,\n",
        "            \"device_map\": \"auto\" if self.device == \"cuda\" else None,\n",
        "            }\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            self.MODEL_NAME,\n",
        "            **model_kwargs\n",
        "        )\n",
        "        print(f\"Loaded Phi4 model: {model_name}\")\n",
        "\n",
        "    def analyze_text(self, prompt: str, text: str) -> str:\n",
        "        \"\"\"Analyze text using Phi4\"\"\"\n",
        "        full_prompt = f\"{prompt}\\n\\nText to analyze:\\n{text}\"\n",
        "        \"\"\"Analyze using Hugging Face transformers\"\"\"\n",
        "        inputs = self.tokenizer.encode(full_prompt, return_tensors=\"pt\", max_length=2048, truncation=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                inputs,\n",
        "                max_new_tokens=500,\n",
        "                temperature=0.1,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        # Remove the original prompt from the response\n",
        "        return response[len(prompt):].strip()\n",
        "\n",
        "    def get_provider_name(self) -> str:\n",
        "        return f\"Phi4 ({self.method})\"\n",
        ""
      ],
      "metadata": {
        "id": "gYkK-TNUZ0YU"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class FinancialDistressAnalyzer:\n",
        "    \"\"\"Main analyzer class that processes files and detects financial distress signals\"\"\"\n",
        "\n",
        "    def __init__(self, llm_provider: LLMProvider):\n",
        "        self.llm_provider = llm_provider\n",
        "        self.prompts = []\n",
        "        self.results = []\n",
        "\n",
        "    def load_prompts(self, prompts_file_path: str):\n",
        "        \"\"\"Load interrogation prompts from JSON file\"\"\"\n",
        "        try:\n",
        "            with open(prompts_file_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "                self.prompts = data.get('prompts', [])\n",
        "            print(f\"Loaded {len(self.prompts)} prompts successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading prompts: {str(e)}\")\n",
        "\n",
        "    def create_analysis_prompt(self, prompt_data: Dict[str, Any]) -> str:\n",
        "        \"\"\"Create a structured prompt for LLM analysis\"\"\"\n",
        "        prompt_template = f\"\"\"\n",
        "You are analyzing financial documents for signs of distress. Focus on the following financial distress indicator:\n",
        "\n",
        "**Category**: {prompt_data['category']}\n",
        "**Indicator**: {prompt_data['name']}\n",
        "\n",
        "**Keywords to look for**: {', '.join(prompt_data['keywords'])}\n",
        "\n",
        "**Context**: {prompt_data.get('context', 'General financial distress indicator')}\n",
        "\n",
        "**Instructions**:\n",
        "1. Carefully search the provided text for any of the specified keywords or related concepts\n",
        "2. Identify specific phrases, sentences, or passages that suggest this type of financial distress\n",
        "3. Provide a confidence score (0-100) indicating how strongly the text suggests this distress indicator\n",
        "4. Explain your reasoning, citing specific text passages as evidence\n",
        "5. If no clear evidence is found, state this explicitly\n",
        "\n",
        "**Required Response Format**:\n",
        "- KEYWORDS_FOUND: [list any keywords found]\n",
        "- CONFIDENCE_SCORE: [0-100]\n",
        "- EVIDENCE: [specific text passages that support your assessment]\n",
        "- REASONING: [detailed explanation of your analysis]\n",
        "- CONCLUSION: [summary of whether this distress indicator is present]\n",
        "\"\"\"\n",
        "        return prompt_template\n",
        "\n",
        "    def analyze_text_file(self, file_path: str) -> List[AnalysisResult]:\n",
        "        \"\"\"Analyze a text file for financial distress indicators\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                text_content = f.read()\n",
        "\n",
        "            results = []\n",
        "\n",
        "            for i, prompt_data in enumerate(self.prompts):\n",
        "                print(f\"Processing prompt {i+1}/{len(self.prompts)}: {prompt_data['name']}\")\n",
        "\n",
        "                analysis_prompt = self.create_analysis_prompt(prompt_data)\n",
        "                llm_response = self.llm_provider.analyze_text(analysis_prompt, text_content)\n",
        "\n",
        "                # Parse LLM response\n",
        "                result = self._parse_llm_response(llm_response, prompt_data, file_path)\n",
        "                results.append(result)\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing text file: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def analyze_excel_file(self, file_path: str) -> List[AnalysisResult]:\n",
        "        \"\"\"Analyze an Excel file for financial distress indicators\"\"\"\n",
        "        try:\n",
        "            # Read all sheets from Excel file\n",
        "            excel_data = pd.read_excel(file_path)\n",
        "\n",
        "            combined_text = excel_data.to_string(index=False, header=False)\n",
        "            results = []\n",
        "\n",
        "            for i, prompt_data in enumerate(self.prompts):\n",
        "                print(f\"Processing Excel prompt {i+1}/{len(self.prompts)}: {prompt_data['name']}\")\n",
        "\n",
        "                analysis_prompt = self.create_analysis_prompt(prompt_data)\n",
        "                llm_response = self.llm_provider.analyze_text(analysis_prompt, combined_text)\n",
        "\n",
        "                # Parse LLM response\n",
        "                result = self._parse_llm_response(llm_response, prompt_data, file_path)\n",
        "                results.append(result)\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing Excel file: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def _parse_llm_response(self, response: str, prompt_data: Dict[str, Any], source_file: str) -> AnalysisResult:\n",
        "        \"\"\"Parse LLM response into structured result\"\"\"\n",
        "        try:\n",
        "            # Extract information using regex patterns\n",
        "            keywords_found = self._extract_list_from_response(response, \"KEYWORDS_FOUND\")\n",
        "            confidence_score = self._extract_confidence_score(response)\n",
        "            reasoning = self._extract_section_from_response(response, \"REASONING\")\n",
        "\n",
        "            # Find context matches in the response\n",
        "            context_matches = []\n",
        "            for keyword in prompt_data['keywords']:\n",
        "                if keyword.lower() in response.lower():\n",
        "                    context_matches.append(keyword)\n",
        "\n",
        "            return AnalysisResult(\n",
        "                prompt_name=prompt_data['name'],\n",
        "                category=prompt_data['category'],\n",
        "                keywords_found=keywords_found,\n",
        "                context_matches=context_matches,\n",
        "                confidence_score=confidence_score,\n",
        "                reasoning=reasoning,\n",
        "                source_file=source_file\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            return AnalysisResult(\n",
        "                prompt_name=prompt_data['name'],\n",
        "                category=prompt_data['category'],\n",
        "                keywords_found=[],\n",
        "                context_matches=[],\n",
        "                confidence_score=0.0,\n",
        "                reasoning=f\"Error parsing response: {str(e)}\",\n",
        "                source_file=source_file\n",
        "            )\n",
        "\n",
        "    def _extract_list_from_response(self, response: str, section_name: str) -> List[str]:\n",
        "        \"\"\"Extract list items from LLM response\"\"\"\n",
        "        pattern = f\"{section_name}:\\\\s*(.*?)(?=\\\\n[A-Z_]+:|$)\"\n",
        "        match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)\n",
        "        if match:\n",
        "            items_text = match.group(1).strip()\n",
        "            # Parse list items\n",
        "            items = [item.strip().strip('[]') for item in items_text.split(',')]\n",
        "            return [item for item in items if item and item != 'None']\n",
        "        return []\n",
        "\n",
        "    def _extract_confidence_score(self, response: str) -> float:\n",
        "        \"\"\"Extract confidence score from LLM response\"\"\"\n",
        "        pattern = r\"CONFIDENCE_SCORE:\\s*(\\d+(?:\\.\\d+)?)\"\n",
        "        match = re.search(pattern, response, re.IGNORECASE)\n",
        "        if match:\n",
        "            return float(match.group(1))\n",
        "        return 0.0\n",
        "\n",
        "    def _extract_section_from_response(self, response: str, section_name: str) -> str:\n",
        "        \"\"\"Extract a specific section from LLM response\"\"\"\n",
        "        pattern = f\"{section_name}:\\\\s*(.*?)(?=\\\\n[A-Z_]+:|$)\"\n",
        "        match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)\n",
        "        if match:\n",
        "            return match.group(1).strip()\n",
        "        return \"\"\n",
        "\n",
        "    def generate_report(self, results: List[AnalysisResult], output_file: str = \"financial_distress_report.txt\"):\n",
        "        \"\"\"Generate a comprehensive analysis report\"\"\"\n",
        "        output_file = get_file(output_file)\n",
        "        high_risk_indicators = [r for r in results if r.confidence_score >= 70]\n",
        "        medium_risk_indicators = [r for r in results if 30 <= r.confidence_score < 70]\n",
        "\n",
        "        report = f\"\"\"\n",
        "=== FINANCIAL DISTRESS ANALYSIS REPORT ===\n",
        "LLM Provider: {self.llm_provider.get_provider_name()}\n",
        "Total Indicators Analyzed: {len(results)}\n",
        "\n",
        "=== EXECUTIVE SUMMARY ===\n",
        "High Risk Indicators (70-100): {len(high_risk_indicators)}\n",
        "Medium Risk Indicators (30-69): {len(medium_risk_indicators)}\n",
        "Low Risk Indicators (0-29): {len(results) - len(high_risk_indicators) - len(medium_risk_indicators)}\n",
        "\n",
        "=== HIGH RISK INDICATORS ===\n",
        "\"\"\"\n",
        "\n",
        "        for result in high_risk_indicators:\n",
        "            report += f\"\"\"\n",
        "Indicator: {result.prompt_name}\n",
        "Category: {result.category}\n",
        "Confidence Score: {result.confidence_score}\n",
        "Source: {result.source_file}\n",
        "Keywords Found: {', '.join(result.keywords_found) if result.keywords_found else 'None'}\n",
        "Reasoning: {result.reasoning}\n",
        "---\n",
        "\"\"\"\n",
        "\n",
        "        report += \"\\n=== MEDIUM RISK INDICATORS ===\\n\"\n",
        "\n",
        "        for result in medium_risk_indicators:\n",
        "            report += f\"\"\"\n",
        "Indicator: {result.prompt_name}\n",
        "Category: {result.category}\n",
        "Confidence Score: {result.confidence_score}\n",
        "Source: {result.source_file}\n",
        "Keywords Found: {', '.join(result.keywords_found) if result.keywords_found else 'None'}\n",
        "---\n",
        "\"\"\"\n",
        "\n",
        "        # Save report to file\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(report)\n",
        "\n",
        "        print(f\"Report saved to {output_file}\")\n",
        "        return report\n"
      ],
      "metadata": {
        "id": "jx6tRyjhZ5tQ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file(file_name: str, base_path: str = '/content/drive/MyDrive/Geoff output') -> str:\n",
        "\n",
        "    # Construct full file path\n",
        "    file_path = os.path.join(base_path, file_name)\n",
        "\n",
        "    # Check if file exists\n",
        "    if os.path.exists(file_path) == False:\n",
        "        print(f\"Error: File not found at {file_path}\")\n",
        "        print(\"Available files in directory:\")\n",
        "        try:\n",
        "            print(os.listdir(base_path))\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Directory {base_path} not found\")\n",
        "        return None\n",
        "    return file_path"
      ],
      "metadata": {
        "id": "Bi0NksccdPfg"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    print(\"=== Financial Distress Analysis Tool ===\")\n",
        "\n",
        "    # Choose LLM provider\n",
        "    print(\"\\nAvailable LLM Providers:\")\n",
        "    print(\"1. ChatGPT\")\n",
        "    print(\"2. Phi4\")\n",
        "\n",
        "    choice = input(\"Select LLM provider (1 or 2): \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        # Get the api key from secrets\n",
        "        api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "        if not api_key:\n",
        "            api_key = input(\"Enter your OpenAI API key: \").strip()\n",
        "        model = \"gpt-4\"\n",
        "        llm_provider = ChatGPTProvider(api_key, model)\n",
        "    elif choice == \"2\":\n",
        "        model_name = \"microsoft/phi-4\"\n",
        "        method = \"transformers\"\n",
        "        # Fixed: correct parameter order (model_name, method)\n",
        "        llm_provider = Phi4Provider(model_name, method)\n",
        "    else:\n",
        "        print(\"Invalid choice. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Initialize analyzer\n",
        "    analyzer = FinancialDistressAnalyzer(llm_provider)\n",
        "\n",
        "    # Load prompts\n",
        "    prompts_file = \"derived interrogation prompts linked to various qualitative metrics.json\"\n",
        "    prompts_file = get_file(prompts_file)\n",
        "    if prompts_file is None:\n",
        "        print(\"Prompts file not found. Exiting.\")\n",
        "        return\n",
        "\n",
        "    analyzer.load_prompts(prompts_file)\n",
        "\n",
        "    if not analyzer.prompts:\n",
        "        print(\"No prompts loaded. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Analyze files\n",
        "    all_results = []\n",
        "\n",
        "    # Analyze text file\n",
        "    text_file = \"JPM_2025_Q1_presentation.txt\"\n",
        "    text_file_path = get_file(text_file)\n",
        "    if text_file_path:\n",
        "        print(f\"\\nAnalyzing text file: {text_file_path}\")\n",
        "        text_results = analyzer.analyze_text_file(text_file_path)\n",
        "        all_results.extend(text_results)\n",
        "\n",
        "    # Analyze Excel file\n",
        "    excel_file = \"JPM_2025_Q1_qa_data.xlsx\"\n",
        "    excel_file_path = get_file(excel_file)\n",
        "    if excel_file_path:\n",
        "        print(f\"\\nAnalyzing Excel file: {excel_file_path}\")\n",
        "        excel_results = analyzer.analyze_excel_file(excel_file_path)\n",
        "        all_results.extend(excel_results)\n",
        "\n",
        "    # Generate report\n",
        "    if all_results:\n",
        "        print(f\"\\nGenerating analysis report...\")\n",
        "        report = analyzer.generate_report(all_results)\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"ANALYSIS COMPLETE\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"Total indicators analyzed: {len(all_results)}\")\n",
        "        print(f\"High risk indicators found: {len([r for r in all_results if r.confidence_score >= 70])}\")\n",
        "        print(\"Report saved to: financial_distress_report.txt\")\n",
        "    else:\n",
        "        print(\"No results to analyze.\")"
      ],
      "metadata": {
        "id": "qBZweu26Z9KJ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSVFcAjZaBEg",
        "outputId": "3361fd13-fb23-43a7-da84-0aa4ae1ae443"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Financial Distress Analysis Tool ===\n",
            "\n",
            "Available LLM Providers:\n",
            "1. ChatGPT\n",
            "2. Phi4\n",
            "Select LLM provider (1 or 2): 1\n",
            "Loaded 27 prompts successfully\n",
            "\n",
            "Analyzing text file: /content/drive/MyDrive/Geoff output/JPM_2025_Q1_presentation.txt\n",
            "Processing prompt 1/27: Frequent Changes in Auditors\n",
            "Processing prompt 2/27: Nervous, Unresponsive, or Evasive Management\n",
            "Processing prompt 3/27: High Turnover or Loss of Key Staff\n",
            "Processing prompt 4/27: Misrepresentation or Accounting Issues\n",
            "Processing prompt 5/27: Sudden Departure of Key Executives or Board Directors\n",
            "Processing prompt 6/27: Material Weaknesses in Internal Controls\n",
            "Processing prompt 7/27: Adverse Audit Opinions or Disclaimer of Opinion\n",
            "Processing prompt 8/27: Going Concern Warning in Audit Reports\n",
            "Processing prompt 9/27: Negative Publicity\n",
            "Processing prompt 10/27: Credit Rating Downgrade\n",
            "Processing prompt 11/27: Stock Price Declines or Rising Debt Costs\n",
            "Processing prompt 12/27: Widening Debt or Credit-Default-Swap (CDS) Spreads\n",
            "Processing prompt 13/27: Counterparties Requesting Additional Collateral\n",
            "Processing prompt 14/27: Increasing Wholesale or Retail Funding Costs\n",
            "Processing prompt 15/27: Rapid Asset Growth, Especially with Volatile Liabilities\n",
            "Processing prompt 16/27: Growing Concentrations in Assets or Liabilities\n",
            "Processing prompt 17/27: Deviation from Traditional Business Model\n",
            "Processing prompt 18/27: Deterioration in Product/Service Quality\n",
            "Processing prompt 19/27: Increased Reliance on Financing Activities\n",
            "Processing prompt 20/27: Unexplained Movements in \"Other Assets\" or \"Other Liabilities\"\n",
            "Processing prompt 21/27: Fair Value Adjustments on Financial Instruments\n",
            "Processing prompt 22/27: Increased Off-Balance Sheet (OBS) Items and Risks\n",
            "Processing prompt 23/27: Declining Funding and Lending Activities\n",
            "Processing prompt 24/27: Unclear Financial Performance Indicators\n",
            "Processing prompt 25/27: Structural or Operational Risk\n",
            "Processing prompt 26/27: Cross-Border Business Exposure\n",
            "Processing prompt 27/27: Foreign Exchange and Funding Impacts\n",
            "\n",
            "Analyzing Excel file: /content/drive/MyDrive/Geoff output/JPM_2025_Q1_qa_data.xlsx\n",
            "Processing Excel prompt 1/27: Frequent Changes in Auditors\n",
            "Processing Excel prompt 2/27: Nervous, Unresponsive, or Evasive Management\n",
            "Processing Excel prompt 3/27: High Turnover or Loss of Key Staff\n",
            "Processing Excel prompt 4/27: Misrepresentation or Accounting Issues\n",
            "Processing Excel prompt 5/27: Sudden Departure of Key Executives or Board Directors\n",
            "Processing Excel prompt 6/27: Material Weaknesses in Internal Controls\n",
            "Processing Excel prompt 7/27: Adverse Audit Opinions or Disclaimer of Opinion\n",
            "Processing Excel prompt 8/27: Going Concern Warning in Audit Reports\n",
            "Processing Excel prompt 9/27: Negative Publicity\n",
            "Processing Excel prompt 10/27: Credit Rating Downgrade\n",
            "Processing Excel prompt 11/27: Stock Price Declines or Rising Debt Costs\n",
            "Processing Excel prompt 12/27: Widening Debt or Credit-Default-Swap (CDS) Spreads\n",
            "Processing Excel prompt 13/27: Counterparties Requesting Additional Collateral\n",
            "Processing Excel prompt 14/27: Increasing Wholesale or Retail Funding Costs\n",
            "Processing Excel prompt 15/27: Rapid Asset Growth, Especially with Volatile Liabilities\n",
            "Processing Excel prompt 16/27: Growing Concentrations in Assets or Liabilities\n",
            "Processing Excel prompt 17/27: Deviation from Traditional Business Model\n",
            "Processing Excel prompt 18/27: Deterioration in Product/Service Quality\n",
            "Processing Excel prompt 19/27: Increased Reliance on Financing Activities\n",
            "Processing Excel prompt 20/27: Unexplained Movements in \"Other Assets\" or \"Other Liabilities\"\n",
            "Processing Excel prompt 21/27: Fair Value Adjustments on Financial Instruments\n",
            "Processing Excel prompt 22/27: Increased Off-Balance Sheet (OBS) Items and Risks\n",
            "Processing Excel prompt 23/27: Declining Funding and Lending Activities\n",
            "Processing Excel prompt 24/27: Unclear Financial Performance Indicators\n",
            "Processing Excel prompt 25/27: Structural or Operational Risk\n",
            "Processing Excel prompt 26/27: Cross-Border Business Exposure\n",
            "Processing Excel prompt 27/27: Foreign Exchange and Funding Impacts\n",
            "\n",
            "Generating analysis report...\n",
            "Report saved to financial_distress_report.txt\n",
            "\n",
            "==================================================\n",
            "ANALYSIS COMPLETE\n",
            "==================================================\n",
            "Total indicators analyzed: 54\n",
            "High risk indicators found: 0\n",
            "Report saved to: financial_distress_report.txt\n"
          ]
        }
      ]
    }
  ]
}